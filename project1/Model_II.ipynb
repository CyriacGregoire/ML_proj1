{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfce502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Implemented_functions import *\n",
    "from Data_cleaning import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed59d3",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351cd0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "<>:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "C:\\Users\\janfo\\AppData\\Local\\Temp\\ipykernel_2924\\4294577664.py:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "  X_train_data_full, X_test_data, Y_train_data_full, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_data shape: (328135, 321)\n",
      "Y_train_data shape: (328135,)\n",
      "X_test_data shape: (109379, 321)\n"
     ]
    }
   ],
   "source": [
    "X_train_data_full, X_test_data, Y_train_data_full, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n",
    "print(\"X_train_data shape:\", X_train_data_full.shape)\n",
    "print(\"Y_train_data shape:\", Y_train_data_full.shape)\n",
    "print(\"X_test_data shape:\", X_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984377b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of -1 labels in Y_train_data: 299160\n",
      "Number of 1 labels in Y_train_data: 28975\n",
      "Number of -1 labels in Y_train_data_norm: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of -1 labels in Y_train_data:\", np.sum(Y_train_data_full == -1))\n",
    "print(\"Number of 1 labels in Y_train_data:\", np.sum(Y_train_data_full == 1))\n",
    "Y_train_data_norm_full = np.where(Y_train_data_full == -1, 0, Y_train_data_full)\n",
    "print(\"Number of -1 labels in Y_train_data_norm:\", np.sum(Y_train_data_norm_full == -1))\n",
    "\n",
    "X_train_data, Y_train_data = X_train_data_full, Y_train_data_norm_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6938179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced X_train_data shape: (328135, 321)\n",
      "Reduced Y_train_data shape: (328135,)\n"
     ]
    }
   ],
   "source": [
    "\"Run if needed to reduce dataset size for faster testing\"\n",
    "# X_train_data, Y_train_data = X_train_data_full[:10000], Y_train_data_norm_full[:10000]\n",
    "print(\"Reduced X_train_data shape:\", X_train_data.shape)\n",
    "print(\"Reduced Y_train_data shape:\", Y_train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717de70c",
   "metadata": {},
   "source": [
    "# Ridge Regression, Model selection and regularization\n",
    "In this model script, as we already explored some data preprocessing mesures, we will try to find which is the best model to use. Morover, we will dicuss if regularization is needed and, in case it is, the best way to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e8c8b",
   "metadata": {},
   "source": [
    "# Best Logistic Regularization\n",
    "In this section we will explore the different values for the lambda parameter for the logistic model. From now, we will consider the preprocessing data fixed, as we ended the Model_I script: standardize, more than 75% NaN features removed, balancing (turn data into 50 % for each label) and NaN substitution by the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759a1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "def preprocessing(x_train, x_val, y_train, y_val, threshold=0.75): # fix 75%\n",
    "    \n",
    "    # remove features that contain NaN values in the training set\n",
    "    x_train, keep_mask = remove_nan_features(x_train, threshold=threshold) # we remove features with more than 30% NaN values\n",
    "    x_val = x_val[:, keep_mask]\n",
    "    # replace missing values with mean and standardize features\n",
    "    x_train = impute_missing_values(x_train, strategy='mean')\n",
    "    x_val = impute_missing_values(x_val, strategy='mean')\n",
    "    x_train, means, stds = standardize_features(x_train)\n",
    "    x_val = (x_val - means) / stds\n",
    "    # balance data by undersampling, so that both classes have the same number of samples\n",
    "    x_train, y_train = balance_data(x_train, y_train, method='undersample')\n",
    "    print(\"Number of removes features due to NaN values:\", np.sum(~keep_mask))\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1d753",
   "metadata": {},
   "source": [
    "First we try some lambdas and plot the learning curve to capture the behaviour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659fe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocess (262508, 321) (262508,)\n",
      "Number of removes features due to NaN values: 117\n",
      "After preprocess (46564, 204) (46564,)\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480552\n",
      "Iteration   200, loss = 0.479520\n",
      "Iteration   300, loss = 0.479194\n",
      "Iteration   400, loss = 0.479010\n",
      "Iteration   500, loss = 0.478884\n",
      "Iteration   600, loss = 0.478790\n",
      "Iteration   700, loss = 0.478714\n",
      "Iteration   800, loss = 0.478651\n",
      "Iteration   900, loss = 0.478597\n",
      "Iteration  1000, loss = 0.478550\n",
      "Iteration  1100, loss = 0.478507\n",
      "Iteration  1200, loss = 0.478469\n",
      "Iteration  1300, loss = 0.478435\n",
      "Iteration  1400, loss = 0.478403\n",
      "Iteration  1500, loss = 0.478374\n",
      "Iteration  1600, loss = 0.478348\n",
      "Iteration  1700, loss = 0.478323\n",
      "Iteration  1800, loss = 0.478300\n",
      "Iteration  1900, loss = 0.478278\n",
      "Iteration  2000, loss = 0.478258\n",
      "Iteration  2100, loss = 0.478239\n",
      "Iteration  2200, loss = 0.478221\n",
      "Iteration  2300, loss = 0.478204\n",
      "Iteration  2400, loss = 0.478189\n",
      "Iteration  2500, loss = 0.478174\n",
      "Iteration  2600, loss = 0.478159\n",
      "Iteration  2700, loss = 0.478146\n",
      "Iteration  2800, loss = 0.478133\n",
      "Iteration  2900, loss = 0.478121\n",
      "Iteration  3000, loss = 0.478110\n",
      "Iteration  3100, loss = 0.478099\n",
      "Iteration  3200, loss = 0.478088\n",
      "Iteration  3300, loss = 0.478078\n",
      "Iteration  3400, loss = 0.478069\n",
      "Iteration  3500, loss = 0.478059\n",
      "Iteration  3600, loss = 0.478051\n",
      "Iteration  3700, loss = 0.478042\n",
      "Iteration  3800, loss = 0.478034\n",
      "Iteration  3900, loss = 0.478027\n",
      "Iteration  4000, loss = 0.478019\n",
      "Iteration  4100, loss = 0.478012\n",
      "Iteration  4200, loss = 0.478005\n",
      "Iteration  4300, loss = 0.477999\n",
      "Iteration  4400, loss = 0.477992\n",
      "Iteration  4500, loss = 0.477986\n",
      "Iteration  4600, loss = 0.477981\n",
      "Iteration  4700, loss = 0.477975\n",
      "Iteration  4800, loss = 0.477970\n",
      "Iteration  4900, loss = 0.477964\n",
      "Iteration  5000, loss = 0.477959\n",
      "Iteration  5100, loss = 0.477954\n",
      "Iteration  5200, loss = 0.477950\n",
      "Iteration  5300, loss = 0.477945\n",
      "Iteration  5400, loss = 0.477941\n",
      "Iteration  5500, loss = 0.477936\n",
      "Iteration  5600, loss = 0.477932\n",
      "Iteration  5700, loss = 0.477928\n",
      "Iteration  5800, loss = 0.477924\n",
      "Iteration  5900, loss = 0.477920\n",
      "Iteration  6000, loss = 0.477917\n",
      "Iteration  6100, loss = 0.477913\n",
      "Iteration  6200, loss = 0.477910\n",
      "Iteration  6300, loss = 0.477906\n",
      "Iteration  6400, loss = 0.477903\n",
      "Iteration  6500, loss = 0.477900\n",
      "Iteration  6600, loss = 0.477897\n",
      "Iteration  6700, loss = 0.477894\n",
      "Iteration  6800, loss = 0.477891\n",
      "Iteration  6900, loss = 0.477888\n",
      "Iteration  7000, loss = 0.477885\n",
      "Iteration  7100, loss = 0.477882\n",
      "Iteration  7200, loss = 0.477880\n",
      "Iteration  7300, loss = 0.477877\n",
      "Iteration  7400, loss = 0.477874\n",
      "Iteration  7500, loss = 0.477872\n",
      "Iteration  7600, loss = 0.477869\n",
      "Iteration  7700, loss = 0.477867\n",
      "Iteration  7800, loss = 0.477865\n",
      "Iteration  7900, loss = 0.477862\n",
      "Iteration  8000, loss = 0.477860\n",
      "Iteration  8100, loss = 0.477858\n",
      "Iteration  8200, loss = 0.477856\n",
      "Iteration  8300, loss = 0.477854\n",
      "Iteration  8400, loss = 0.477852\n",
      "Iteration  8500, loss = 0.477850\n",
      "Iteration  8600, loss = 0.477848\n",
      "Iteration  8700, loss = 0.477846\n",
      "Iteration  8800, loss = 0.477844\n",
      "Iteration  8900, loss = 0.477842\n",
      "Iteration  9000, loss = 0.477840\n",
      "Iteration  9100, loss = 0.477838\n",
      "Iteration  9200, loss = 0.477836\n",
      "Iteration  9300, loss = 0.477835\n",
      "Iteration  9400, loss = 0.477833\n",
      "Iteration  9500, loss = 0.477831\n",
      "Iteration  9600, loss = 0.477829\n",
      "Iteration  9700, loss = 0.477828\n",
      "Iteration  9800, loss = 0.477826\n",
      "Iteration  9900, loss = 0.477825\n",
      " Accuracy: 85.74%\n",
      " F1 Score: 0.4070\n",
      "\n",
      "Validation loss: 0.4874435202686255 f1 score 0.406996641105266 with data size of 13125\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479523\n",
      "Iteration   200, loss = 0.478503\n",
      "Iteration   300, loss = 0.478193\n",
      "Iteration   400, loss = 0.478021\n",
      "Iteration   500, loss = 0.477906\n",
      "Iteration   600, loss = 0.477820\n",
      "Iteration   700, loss = 0.477752\n",
      "Iteration   800, loss = 0.477696\n",
      "Iteration   900, loss = 0.477648\n",
      "Iteration  1000, loss = 0.477606\n",
      "Iteration  1100, loss = 0.477568\n",
      "Iteration  1200, loss = 0.477535\n",
      "Iteration  1300, loss = 0.477505\n",
      "Iteration  1400, loss = 0.477478\n",
      "Iteration  1500, loss = 0.477452\n",
      "Iteration  1600, loss = 0.477429\n",
      "Iteration  1700, loss = 0.477408\n",
      "Iteration  1800, loss = 0.477388\n",
      "Iteration  1900, loss = 0.477370\n",
      "Iteration  2000, loss = 0.477352\n",
      "Iteration  2100, loss = 0.477336\n",
      "Iteration  2200, loss = 0.477321\n",
      "Iteration  2300, loss = 0.477307\n",
      "Iteration  2400, loss = 0.477293\n",
      "Iteration  2500, loss = 0.477281\n",
      "Iteration  2600, loss = 0.477269\n",
      "Iteration  2700, loss = 0.477257\n",
      "Iteration  2800, loss = 0.477246\n",
      "Iteration  2900, loss = 0.477236\n",
      "Iteration  3000, loss = 0.477227\n",
      "Iteration  3100, loss = 0.477217\n",
      "Iteration  3200, loss = 0.477209\n",
      "Iteration  3300, loss = 0.477200\n",
      "Iteration  3400, loss = 0.477192\n",
      "Iteration  3500, loss = 0.477185\n",
      "Iteration  3600, loss = 0.477177\n",
      "Iteration  3700, loss = 0.477170\n",
      "Iteration  3800, loss = 0.477164\n",
      "Iteration  3900, loss = 0.477157\n",
      "Iteration  4000, loss = 0.477151\n",
      "Iteration  4100, loss = 0.477145\n",
      "Iteration  4200, loss = 0.477139\n",
      "Iteration  4300, loss = 0.477134\n",
      "Iteration  4400, loss = 0.477129\n",
      "Iteration  4500, loss = 0.477124\n",
      "Iteration  4600, loss = 0.477119\n",
      "Iteration  4700, loss = 0.477114\n",
      "Iteration  4800, loss = 0.477110\n",
      "Iteration  4900, loss = 0.477105\n",
      "Iteration  5000, loss = 0.477101\n",
      "Iteration  5100, loss = 0.477097\n",
      "Iteration  5200, loss = 0.477093\n",
      "Iteration  5300, loss = 0.477089\n",
      "Iteration  5400, loss = 0.477086\n",
      "Iteration  5500, loss = 0.477082\n",
      "Iteration  5600, loss = 0.477079\n",
      "Iteration  5700, loss = 0.477075\n",
      "Iteration  5800, loss = 0.477072\n",
      "Iteration  5900, loss = 0.477069\n",
      "Iteration  6000, loss = 0.477066\n",
      "Iteration  6100, loss = 0.477063\n",
      "Iteration  6200, loss = 0.477060\n",
      "Iteration  6300, loss = 0.477057\n",
      "Iteration  6400, loss = 0.477054\n",
      "Iteration  6500, loss = 0.477052\n",
      "Iteration  6600, loss = 0.477049\n",
      "Iteration  6700, loss = 0.477047\n",
      "Iteration  6800, loss = 0.477044\n",
      "Iteration  6900, loss = 0.477042\n",
      "Iteration  7000, loss = 0.477039\n",
      "Iteration  7100, loss = 0.477037\n",
      "Iteration  7200, loss = 0.477035\n",
      "Iteration  7300, loss = 0.477033\n",
      "Iteration  7400, loss = 0.477030\n",
      "Iteration  7500, loss = 0.477028\n",
      "Iteration  7600, loss = 0.477026\n",
      "Iteration  7700, loss = 0.477024\n",
      "Iteration  7800, loss = 0.477022\n",
      "Iteration  7900, loss = 0.477020\n",
      "Iteration  8000, loss = 0.477019\n",
      "Iteration  8100, loss = 0.477017\n",
      "Iteration  8200, loss = 0.477015\n",
      "Iteration  8300, loss = 0.477013\n",
      "Iteration  8400, loss = 0.477011\n",
      "Iteration  8500, loss = 0.477010\n",
      "Iteration  8600, loss = 0.477008\n",
      "Iteration  8700, loss = 0.477006\n",
      "Iteration  8800, loss = 0.477005\n",
      "Iteration  8900, loss = 0.477003\n",
      "Iteration  9000, loss = 0.477002\n",
      "Iteration  9100, loss = 0.477000\n",
      "Iteration  9200, loss = 0.476999\n",
      "Iteration  9300, loss = 0.476997\n",
      "Iteration  9400, loss = 0.476996\n",
      "Iteration  9500, loss = 0.476994\n",
      "Iteration  9600, loss = 0.476993\n",
      "Iteration  9700, loss = 0.476991\n",
      "Iteration  9800, loss = 0.476990\n",
      "Iteration  9900, loss = 0.476989\n",
      " Accuracy: 85.73%\n",
      " F1 Score: 0.4069\n",
      "\n",
      "Validation loss: 0.4878356131434696 f1 score 0.4069384654342867 with data size of 13816\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479686\n",
      "Iteration   200, loss = 0.478588\n",
      "Iteration   300, loss = 0.478242\n",
      "Iteration   400, loss = 0.478052\n",
      "Iteration   500, loss = 0.477926\n",
      "Iteration   600, loss = 0.477834\n",
      "Iteration   700, loss = 0.477762\n",
      "Iteration   800, loss = 0.477703\n",
      "Iteration   900, loss = 0.477652\n",
      "Iteration  1000, loss = 0.477609\n",
      "Iteration  1100, loss = 0.477571\n",
      "Iteration  1200, loss = 0.477537\n",
      "Iteration  1300, loss = 0.477506\n",
      "Iteration  1400, loss = 0.477478\n",
      "Iteration  1500, loss = 0.477452\n",
      "Iteration  1600, loss = 0.477429\n",
      "Iteration  1700, loss = 0.477407\n",
      "Iteration  1800, loss = 0.477387\n",
      "Iteration  1900, loss = 0.477368\n",
      "Iteration  2000, loss = 0.477351\n",
      "Iteration  2100, loss = 0.477335\n",
      "Iteration  2200, loss = 0.477319\n",
      "Iteration  2300, loss = 0.477305\n",
      "Iteration  2400, loss = 0.477291\n",
      "Iteration  2500, loss = 0.477279\n",
      "Iteration  2600, loss = 0.477266\n",
      "Iteration  2700, loss = 0.477255\n",
      "Iteration  2800, loss = 0.477244\n",
      "Iteration  2900, loss = 0.477234\n",
      "Iteration  3000, loss = 0.477224\n",
      "Iteration  3100, loss = 0.477215\n",
      "Iteration  3200, loss = 0.477206\n",
      "Iteration  3300, loss = 0.477197\n",
      "Iteration  3400, loss = 0.477189\n",
      "Iteration  3500, loss = 0.477181\n",
      "Iteration  3600, loss = 0.477174\n",
      "Iteration  3700, loss = 0.477167\n",
      "Iteration  3800, loss = 0.477160\n",
      "Iteration  3900, loss = 0.477153\n",
      "Iteration  4000, loss = 0.477147\n",
      "Iteration  4100, loss = 0.477141\n",
      "Iteration  4200, loss = 0.477135\n",
      "Iteration  4300, loss = 0.477130\n",
      "Iteration  4400, loss = 0.477124\n",
      "Iteration  4500, loss = 0.477119\n",
      "Iteration  4600, loss = 0.477114\n",
      "Iteration  4700, loss = 0.477109\n",
      "Iteration  4800, loss = 0.477105\n",
      "Iteration  4900, loss = 0.477100\n",
      "Iteration  5000, loss = 0.477096\n",
      "Iteration  5100, loss = 0.477092\n",
      "Iteration  5200, loss = 0.477088\n",
      "Iteration  5300, loss = 0.477084\n",
      "Iteration  5400, loss = 0.477080\n",
      "Iteration  5500, loss = 0.477076\n",
      "Iteration  5600, loss = 0.477073\n",
      "Iteration  5700, loss = 0.477070\n",
      "Iteration  5800, loss = 0.477066\n",
      "Iteration  5900, loss = 0.477063\n",
      "Iteration  6000, loss = 0.477060\n",
      "Iteration  6100, loss = 0.477057\n",
      "Iteration  6200, loss = 0.477054\n",
      "Iteration  6300, loss = 0.477051\n",
      "Iteration  6400, loss = 0.477048\n",
      "Iteration  6500, loss = 0.477045\n",
      "Iteration  6600, loss = 0.477043\n",
      "Iteration  6700, loss = 0.477040\n",
      "Iteration  6800, loss = 0.477038\n",
      "Iteration  6900, loss = 0.477035\n",
      "Iteration  7000, loss = 0.477033\n",
      "Iteration  7100, loss = 0.477030\n",
      "Iteration  7200, loss = 0.477028\n",
      "Iteration  7300, loss = 0.477026\n",
      "Iteration  7400, loss = 0.477024\n",
      "Iteration  7500, loss = 0.477022\n",
      "Iteration  7600, loss = 0.477020\n",
      "Iteration  7700, loss = 0.477018\n",
      "Iteration  7800, loss = 0.477016\n",
      "Iteration  7900, loss = 0.477014\n",
      "Iteration  8000, loss = 0.477012\n",
      "Iteration  8100, loss = 0.477010\n",
      "Iteration  8200, loss = 0.477008\n",
      "Iteration  8300, loss = 0.477006\n",
      "Iteration  8400, loss = 0.477004\n",
      "Iteration  8500, loss = 0.477003\n",
      "Iteration  8600, loss = 0.477001\n",
      "Iteration  8700, loss = 0.476999\n",
      "Iteration  8800, loss = 0.476998\n",
      "Iteration  8900, loss = 0.476996\n",
      "Iteration  9000, loss = 0.476994\n",
      "Iteration  9100, loss = 0.476993\n",
      "Iteration  9200, loss = 0.476991\n",
      "Iteration  9300, loss = 0.476990\n",
      "Iteration  9400, loss = 0.476988\n",
      "Iteration  9500, loss = 0.476987\n",
      "Iteration  9600, loss = 0.476985\n",
      "Iteration  9700, loss = 0.476984\n",
      "Iteration  9800, loss = 0.476982\n",
      "Iteration  9900, loss = 0.476981\n",
      " Accuracy: 85.79%\n",
      " F1 Score: 0.4062\n",
      "\n",
      "Validation loss: 0.4853181247979072 f1 score 0.4061883236773408 with data size of 14583\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479655\n",
      "Iteration   200, loss = 0.478570\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478044\n",
      "Iteration   500, loss = 0.477922\n",
      "Iteration   600, loss = 0.477832\n",
      "Iteration   700, loss = 0.477761\n",
      "Iteration   800, loss = 0.477703\n",
      "Iteration   900, loss = 0.477654\n",
      "Iteration  1000, loss = 0.477611\n",
      "Iteration  1100, loss = 0.477574\n",
      "Iteration  1200, loss = 0.477540\n",
      "Iteration  1300, loss = 0.477510\n",
      "Iteration  1400, loss = 0.477483\n",
      "Iteration  1500, loss = 0.477458\n",
      "Iteration  1600, loss = 0.477435\n",
      "Iteration  1700, loss = 0.477414\n",
      "Iteration  1800, loss = 0.477394\n",
      "Iteration  1900, loss = 0.477376\n",
      "Iteration  2000, loss = 0.477359\n",
      "Iteration  2100, loss = 0.477343\n",
      "Iteration  2200, loss = 0.477328\n",
      "Iteration  2300, loss = 0.477314\n",
      "Iteration  2400, loss = 0.477301\n",
      "Iteration  2500, loss = 0.477288\n",
      "Iteration  2600, loss = 0.477277\n",
      "Iteration  2700, loss = 0.477265\n",
      "Iteration  2800, loss = 0.477255\n",
      "Iteration  2900, loss = 0.477245\n",
      "Iteration  3000, loss = 0.477235\n",
      "Iteration  3100, loss = 0.477226\n",
      "Iteration  3200, loss = 0.477218\n",
      "Iteration  3300, loss = 0.477209\n",
      "Iteration  3400, loss = 0.477202\n",
      "Iteration  3500, loss = 0.477194\n",
      "Iteration  3600, loss = 0.477187\n",
      "Iteration  3700, loss = 0.477180\n",
      "Iteration  3800, loss = 0.477174\n",
      "Iteration  3900, loss = 0.477167\n",
      "Iteration  4000, loss = 0.477161\n",
      "Iteration  4100, loss = 0.477156\n",
      "Iteration  4200, loss = 0.477150\n",
      "Iteration  4300, loss = 0.477145\n",
      "Iteration  4400, loss = 0.477140\n",
      "Iteration  4500, loss = 0.477135\n",
      "Iteration  4600, loss = 0.477130\n",
      "Iteration  4700, loss = 0.477125\n",
      "Iteration  4800, loss = 0.477121\n",
      "Iteration  4900, loss = 0.477117\n",
      "Iteration  5000, loss = 0.477113\n",
      "Iteration  5100, loss = 0.477109\n",
      "Iteration  5200, loss = 0.477105\n",
      "Iteration  5300, loss = 0.477101\n",
      "Iteration  5400, loss = 0.477098\n",
      "Iteration  5500, loss = 0.477094\n",
      "Iteration  5600, loss = 0.477091\n",
      "Iteration  5700, loss = 0.477088\n",
      "Iteration  5800, loss = 0.477085\n",
      "Iteration  5900, loss = 0.477082\n",
      "Iteration  6000, loss = 0.477079\n",
      "Iteration  6100, loss = 0.477076\n",
      "Iteration  6200, loss = 0.477073\n",
      "Iteration  6300, loss = 0.477070\n",
      "Iteration  6400, loss = 0.477068\n",
      "Iteration  6500, loss = 0.477065\n",
      "Iteration  6600, loss = 0.477063\n",
      "Iteration  6700, loss = 0.477060\n",
      "Iteration  6800, loss = 0.477058\n",
      "Iteration  6900, loss = 0.477056\n",
      "Iteration  7000, loss = 0.477053\n",
      "Iteration  7100, loss = 0.477051\n",
      "Iteration  7200, loss = 0.477049\n",
      "Iteration  7300, loss = 0.477047\n",
      "Iteration  7400, loss = 0.477045\n",
      "Iteration  7500, loss = 0.477043\n",
      "Iteration  7600, loss = 0.477041\n",
      "Iteration  7700, loss = 0.477039\n",
      "Iteration  7800, loss = 0.477037\n",
      "Iteration  7900, loss = 0.477035\n",
      "Iteration  8000, loss = 0.477034\n",
      "Iteration  8100, loss = 0.477032\n",
      "Iteration  8200, loss = 0.477030\n",
      "Iteration  8300, loss = 0.477028\n",
      "Iteration  8400, loss = 0.477027\n",
      "Iteration  8500, loss = 0.477025\n",
      "Iteration  8600, loss = 0.477024\n",
      "Iteration  8700, loss = 0.477022\n",
      "Iteration  8800, loss = 0.477020\n",
      "Iteration  8900, loss = 0.477019\n",
      "Iteration  9000, loss = 0.477018\n",
      "Iteration  9100, loss = 0.477016\n",
      "Iteration  9200, loss = 0.477015\n",
      "Iteration  9300, loss = 0.477013\n",
      "Iteration  9400, loss = 0.477012\n",
      "Iteration  9500, loss = 0.477010\n",
      "Iteration  9600, loss = 0.477009\n",
      "Iteration  9700, loss = 0.477008\n",
      "Iteration  9800, loss = 0.477006\n",
      "Iteration  9900, loss = 0.477005\n",
      " Accuracy: 85.86%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.48374045722021747 f1 score 0.4075847538785669 with data size of 15441\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479315\n",
      "Iteration   200, loss = 0.478272\n",
      "Iteration   300, loss = 0.477950\n",
      "Iteration   400, loss = 0.477776\n",
      "Iteration   500, loss = 0.477662\n",
      "Iteration   600, loss = 0.477581\n",
      "Iteration   700, loss = 0.477517\n",
      "Iteration   800, loss = 0.477465\n",
      "Iteration   900, loss = 0.477420\n",
      "Iteration  1000, loss = 0.477382\n",
      "Iteration  1100, loss = 0.477348\n",
      "Iteration  1200, loss = 0.477318\n",
      "Iteration  1300, loss = 0.477291\n",
      "Iteration  1400, loss = 0.477266\n",
      "Iteration  1500, loss = 0.477243\n",
      "Iteration  1600, loss = 0.477221\n",
      "Iteration  1700, loss = 0.477202\n",
      "Iteration  1800, loss = 0.477184\n",
      "Iteration  1900, loss = 0.477167\n",
      "Iteration  2000, loss = 0.477151\n",
      "Iteration  2100, loss = 0.477136\n",
      "Iteration  2200, loss = 0.477122\n",
      "Iteration  2300, loss = 0.477108\n",
      "Iteration  2400, loss = 0.477096\n",
      "Iteration  2500, loss = 0.477084\n",
      "Iteration  2600, loss = 0.477073\n",
      "Iteration  2700, loss = 0.477062\n",
      "Iteration  2800, loss = 0.477052\n",
      "Iteration  2900, loss = 0.477043\n",
      "Iteration  3000, loss = 0.477034\n",
      "Iteration  3100, loss = 0.477025\n",
      "Iteration  3200, loss = 0.477017\n",
      "Iteration  3300, loss = 0.477009\n",
      "Iteration  3400, loss = 0.477001\n",
      "Iteration  3500, loss = 0.476994\n",
      "Iteration  3600, loss = 0.476988\n",
      "Iteration  3700, loss = 0.476981\n",
      "Iteration  3800, loss = 0.476975\n",
      "Iteration  3900, loss = 0.476969\n",
      "Iteration  4000, loss = 0.476963\n",
      "Iteration  4100, loss = 0.476958\n",
      "Iteration  4200, loss = 0.476952\n",
      "Iteration  4300, loss = 0.476947\n",
      "Iteration  4400, loss = 0.476942\n",
      "Iteration  4500, loss = 0.476938\n",
      "Iteration  4600, loss = 0.476933\n",
      "Iteration  4700, loss = 0.476929\n",
      "Iteration  4800, loss = 0.476925\n",
      "Iteration  4900, loss = 0.476921\n",
      "Iteration  5000, loss = 0.476917\n",
      "Iteration  5100, loss = 0.476913\n",
      "Iteration  5200, loss = 0.476909\n",
      "Iteration  5300, loss = 0.476906\n",
      "Iteration  5400, loss = 0.476902\n",
      "Iteration  5500, loss = 0.476899\n",
      "Iteration  5600, loss = 0.476896\n",
      "Iteration  5700, loss = 0.476893\n",
      "Iteration  5800, loss = 0.476890\n",
      "Iteration  5900, loss = 0.476887\n",
      "Iteration  6000, loss = 0.476884\n",
      "Iteration  6100, loss = 0.476882\n",
      "Iteration  6200, loss = 0.476879\n",
      "Iteration  6300, loss = 0.476876\n",
      "Iteration  6400, loss = 0.476874\n",
      "Iteration  6500, loss = 0.476871\n",
      "Iteration  6600, loss = 0.476869\n",
      "Iteration  6700, loss = 0.476867\n",
      "Iteration  6800, loss = 0.476865\n",
      "Iteration  6900, loss = 0.476862\n",
      "Iteration  7000, loss = 0.476860\n",
      "Iteration  7100, loss = 0.476858\n",
      "Iteration  7200, loss = 0.476856\n",
      "Iteration  7300, loss = 0.476854\n",
      "Iteration  7400, loss = 0.476852\n",
      "Iteration  7500, loss = 0.476850\n",
      "Iteration  7600, loss = 0.476848\n",
      "Iteration  7700, loss = 0.476847\n",
      "Iteration  7800, loss = 0.476845\n",
      "Iteration  7900, loss = 0.476843\n",
      "Iteration  8000, loss = 0.476841\n",
      "Iteration  8100, loss = 0.476840\n",
      "Iteration  8200, loss = 0.476838\n",
      "Iteration  8300, loss = 0.476836\n",
      "Iteration  8400, loss = 0.476835\n",
      "Iteration  8500, loss = 0.476833\n",
      "Iteration  8600, loss = 0.476832\n",
      "Iteration  8700, loss = 0.476830\n",
      "Iteration  8800, loss = 0.476829\n",
      "Iteration  8900, loss = 0.476827\n",
      "Iteration  9000, loss = 0.476826\n",
      "Iteration  9100, loss = 0.476824\n",
      "Iteration  9200, loss = 0.476823\n",
      "Iteration  9300, loss = 0.476822\n",
      "Iteration  9400, loss = 0.476820\n",
      "Iteration  9500, loss = 0.476819\n",
      "Iteration  9600, loss = 0.476818\n",
      "Iteration  9700, loss = 0.476816\n",
      "Iteration  9800, loss = 0.476815\n",
      "Iteration  9900, loss = 0.476814\n",
      " Accuracy: 85.83%\n",
      " F1 Score: 0.4084\n",
      "\n",
      "Validation loss: 0.4851587551659745 f1 score 0.4083996181991723 with data size of 16406\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479681\n",
      "Iteration   200, loss = 0.478651\n",
      "Iteration   300, loss = 0.478333\n",
      "Iteration   400, loss = 0.478162\n",
      "Iteration   500, loss = 0.478052\n",
      "Iteration   600, loss = 0.477974\n",
      "Iteration   700, loss = 0.477914\n",
      "Iteration   800, loss = 0.477866\n",
      "Iteration   900, loss = 0.477826\n",
      "Iteration  1000, loss = 0.477791\n",
      "Iteration  1100, loss = 0.477761\n",
      "Iteration  1200, loss = 0.477734\n",
      "Iteration  1300, loss = 0.477710\n",
      "Iteration  1400, loss = 0.477688\n",
      "Iteration  1500, loss = 0.477669\n",
      "Iteration  1600, loss = 0.477650\n",
      "Iteration  1700, loss = 0.477633\n",
      "Iteration  1800, loss = 0.477618\n",
      "Iteration  1900, loss = 0.477603\n",
      "Iteration  2000, loss = 0.477590\n",
      "Iteration  2100, loss = 0.477577\n",
      "Iteration  2200, loss = 0.477565\n",
      "Iteration  2300, loss = 0.477554\n",
      "Iteration  2400, loss = 0.477543\n",
      "Iteration  2500, loss = 0.477533\n",
      "Iteration  2600, loss = 0.477524\n",
      "Iteration  2700, loss = 0.477515\n",
      "Iteration  2800, loss = 0.477507\n",
      "Iteration  2900, loss = 0.477499\n",
      "Iteration  3000, loss = 0.477492\n",
      "Iteration  3100, loss = 0.477484\n",
      "Iteration  3200, loss = 0.477478\n",
      "Iteration  3300, loss = 0.477471\n",
      "Iteration  3400, loss = 0.477465\n",
      "Iteration  3500, loss = 0.477459\n",
      "Iteration  3600, loss = 0.477454\n",
      "Iteration  3700, loss = 0.477448\n",
      "Iteration  3800, loss = 0.477443\n",
      "Iteration  3900, loss = 0.477438\n",
      "Iteration  4000, loss = 0.477434\n",
      "Iteration  4100, loss = 0.477429\n",
      "Iteration  4200, loss = 0.477425\n",
      "Iteration  4300, loss = 0.477421\n",
      "Iteration  4400, loss = 0.477417\n",
      "Iteration  4500, loss = 0.477413\n",
      "Iteration  4600, loss = 0.477409\n",
      "Iteration  4700, loss = 0.477406\n",
      "Iteration  4800, loss = 0.477402\n",
      "Iteration  4900, loss = 0.477399\n",
      "Iteration  5000, loss = 0.477396\n",
      "Iteration  5100, loss = 0.477393\n",
      "Iteration  5200, loss = 0.477390\n",
      "Iteration  5300, loss = 0.477387\n",
      "Iteration  5400, loss = 0.477385\n",
      "Iteration  5500, loss = 0.477382\n",
      "Iteration  5600, loss = 0.477379\n",
      "Iteration  5700, loss = 0.477377\n",
      "Iteration  5800, loss = 0.477375\n",
      "Iteration  5900, loss = 0.477372\n",
      "Iteration  6000, loss = 0.477370\n",
      "Iteration  6100, loss = 0.477368\n",
      "Iteration  6200, loss = 0.477366\n",
      "Iteration  6300, loss = 0.477364\n",
      "Iteration  6400, loss = 0.477362\n",
      "Iteration  6500, loss = 0.477360\n",
      "Iteration  6600, loss = 0.477358\n",
      "Iteration  6700, loss = 0.477356\n",
      "Iteration  6800, loss = 0.477354\n",
      "Iteration  6900, loss = 0.477353\n",
      "Iteration  7000, loss = 0.477351\n",
      "Iteration  7100, loss = 0.477349\n",
      "Iteration  7200, loss = 0.477348\n",
      "Iteration  7300, loss = 0.477346\n",
      "Iteration  7400, loss = 0.477344\n",
      "Iteration  7500, loss = 0.477343\n",
      "Iteration  7600, loss = 0.477341\n",
      "Iteration  7700, loss = 0.477340\n",
      "Iteration  7800, loss = 0.477339\n",
      "Iteration  7900, loss = 0.477337\n",
      "Iteration  8000, loss = 0.477336\n",
      "Iteration  8100, loss = 0.477335\n",
      "Iteration  8200, loss = 0.477333\n",
      "Iteration  8300, loss = 0.477332\n",
      "Iteration  8400, loss = 0.477331\n",
      "Iteration  8500, loss = 0.477329\n",
      "Iteration  8600, loss = 0.477328\n",
      "Iteration  8700, loss = 0.477327\n",
      "Iteration  8800, loss = 0.477326\n",
      "Iteration  8900, loss = 0.477325\n",
      "Iteration  9000, loss = 0.477324\n",
      "Iteration  9100, loss = 0.477322\n",
      "Iteration  9200, loss = 0.477321\n",
      "Iteration  9300, loss = 0.477320\n",
      "Iteration  9400, loss = 0.477319\n",
      "Iteration  9500, loss = 0.477318\n",
      "Iteration  9600, loss = 0.477317\n",
      "Iteration  9700, loss = 0.477316\n",
      "Iteration  9800, loss = 0.477315\n",
      "Converged at iteration 9844\n",
      " Accuracy: 85.86%\n",
      " F1 Score: 0.4072\n",
      "\n",
      "Validation loss: 0.48429493042715854 f1 score 0.407229992974388 with data size of 17500\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480720\n",
      "Iteration   200, loss = 0.479806\n",
      "Iteration   300, loss = 0.479536\n",
      "Iteration   400, loss = 0.479392\n",
      "Iteration   500, loss = 0.479301\n",
      "Iteration   600, loss = 0.479236\n",
      "Iteration   700, loss = 0.479186\n",
      "Iteration   800, loss = 0.479146\n",
      "Iteration   900, loss = 0.479113\n",
      "Iteration  1000, loss = 0.479084\n",
      "Iteration  1100, loss = 0.479059\n",
      "Iteration  1200, loss = 0.479037\n",
      "Iteration  1300, loss = 0.479017\n",
      "Iteration  1400, loss = 0.478998\n",
      "Iteration  1500, loss = 0.478982\n",
      "Iteration  1600, loss = 0.478967\n",
      "Iteration  1700, loss = 0.478953\n",
      "Iteration  1800, loss = 0.478940\n",
      "Iteration  1900, loss = 0.478927\n",
      "Iteration  2000, loss = 0.478916\n",
      "Iteration  2100, loss = 0.478905\n",
      "Iteration  2200, loss = 0.478895\n",
      "Iteration  2300, loss = 0.478886\n",
      "Iteration  2400, loss = 0.478877\n",
      "Iteration  2500, loss = 0.478869\n",
      "Iteration  2600, loss = 0.478861\n",
      "Iteration  2700, loss = 0.478853\n",
      "Iteration  2800, loss = 0.478846\n",
      "Iteration  2900, loss = 0.478839\n",
      "Iteration  3000, loss = 0.478833\n",
      "Iteration  3100, loss = 0.478826\n",
      "Iteration  3200, loss = 0.478821\n",
      "Iteration  3300, loss = 0.478815\n",
      "Iteration  3400, loss = 0.478809\n",
      "Iteration  3500, loss = 0.478804\n",
      "Iteration  3600, loss = 0.478799\n",
      "Iteration  3700, loss = 0.478795\n",
      "Iteration  3800, loss = 0.478790\n",
      "Iteration  3900, loss = 0.478786\n",
      "Iteration  4000, loss = 0.478781\n",
      "Iteration  4100, loss = 0.478777\n",
      "Iteration  4200, loss = 0.478773\n",
      "Iteration  4300, loss = 0.478769\n",
      "Iteration  4400, loss = 0.478766\n",
      "Iteration  4500, loss = 0.478762\n",
      "Iteration  4600, loss = 0.478759\n",
      "Iteration  4700, loss = 0.478755\n",
      "Iteration  4800, loss = 0.478752\n",
      "Iteration  4900, loss = 0.478749\n",
      "Iteration  5000, loss = 0.478746\n",
      "Iteration  5100, loss = 0.478743\n",
      "Iteration  5200, loss = 0.478740\n",
      "Iteration  5300, loss = 0.478738\n",
      "Iteration  5400, loss = 0.478735\n",
      "Iteration  5500, loss = 0.478732\n",
      "Iteration  5600, loss = 0.478730\n",
      "Iteration  5700, loss = 0.478727\n",
      "Iteration  5800, loss = 0.478725\n",
      "Iteration  5900, loss = 0.478723\n",
      "Iteration  6000, loss = 0.478720\n",
      "Iteration  6100, loss = 0.478718\n",
      "Iteration  6200, loss = 0.478716\n",
      "Iteration  6300, loss = 0.478714\n",
      "Iteration  6400, loss = 0.478712\n",
      "Iteration  6500, loss = 0.478709\n",
      "Iteration  6600, loss = 0.478707\n",
      "Iteration  6700, loss = 0.478706\n",
      "Iteration  6800, loss = 0.478704\n",
      "Iteration  6900, loss = 0.478702\n",
      "Iteration  7000, loss = 0.478700\n",
      "Iteration  7100, loss = 0.478698\n",
      "Iteration  7200, loss = 0.478696\n",
      "Iteration  7300, loss = 0.478695\n",
      "Iteration  7400, loss = 0.478693\n",
      "Iteration  7500, loss = 0.478691\n",
      "Iteration  7600, loss = 0.478689\n",
      "Iteration  7700, loss = 0.478688\n",
      "Iteration  7800, loss = 0.478686\n",
      "Iteration  7900, loss = 0.478685\n",
      "Iteration  8000, loss = 0.478683\n",
      "Iteration  8100, loss = 0.478682\n",
      "Iteration  8200, loss = 0.478680\n",
      "Iteration  8300, loss = 0.478679\n",
      "Iteration  8400, loss = 0.478677\n",
      "Iteration  8500, loss = 0.478676\n",
      "Iteration  8600, loss = 0.478674\n",
      "Iteration  8700, loss = 0.478673\n",
      "Iteration  8800, loss = 0.478671\n",
      "Iteration  8900, loss = 0.478670\n",
      "Iteration  9000, loss = 0.478669\n",
      "Iteration  9100, loss = 0.478667\n",
      "Iteration  9200, loss = 0.478666\n",
      "Iteration  9300, loss = 0.478665\n",
      "Iteration  9400, loss = 0.478664\n",
      "Iteration  9500, loss = 0.478662\n",
      "Iteration  9600, loss = 0.478661\n",
      "Iteration  9700, loss = 0.478660\n",
      "Iteration  9800, loss = 0.478658\n",
      "Iteration  9900, loss = 0.478657\n",
      " Accuracy: 85.87%\n",
      " F1 Score: 0.4081\n",
      "\n",
      "Validation loss: 0.48526459479699247 f1 score 0.40814242868993633 with data size of 18750\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.481637\n",
      "Iteration   200, loss = 0.480741\n",
      "Iteration   300, loss = 0.480479\n",
      "Iteration   400, loss = 0.480342\n",
      "Iteration   500, loss = 0.480256\n",
      "Iteration   600, loss = 0.480196\n",
      "Iteration   700, loss = 0.480150\n",
      "Iteration   800, loss = 0.480113\n",
      "Iteration   900, loss = 0.480083\n",
      "Iteration  1000, loss = 0.480057\n",
      "Iteration  1100, loss = 0.480035\n",
      "Iteration  1200, loss = 0.480015\n",
      "Iteration  1300, loss = 0.479998\n",
      "Iteration  1400, loss = 0.479982\n",
      "Iteration  1500, loss = 0.479968\n",
      "Iteration  1600, loss = 0.479954\n",
      "Iteration  1700, loss = 0.479942\n",
      "Iteration  1800, loss = 0.479931\n",
      "Iteration  1900, loss = 0.479920\n",
      "Iteration  2000, loss = 0.479910\n",
      "Iteration  2100, loss = 0.479901\n",
      "Iteration  2200, loss = 0.479892\n",
      "Iteration  2300, loss = 0.479884\n",
      "Iteration  2400, loss = 0.479876\n",
      "Iteration  2500, loss = 0.479869\n",
      "Iteration  2600, loss = 0.479862\n",
      "Iteration  2700, loss = 0.479855\n",
      "Iteration  2800, loss = 0.479849\n",
      "Iteration  2900, loss = 0.479843\n",
      "Iteration  3000, loss = 0.479837\n",
      "Iteration  3100, loss = 0.479831\n",
      "Iteration  3200, loss = 0.479826\n",
      "Iteration  3300, loss = 0.479821\n",
      "Iteration  3400, loss = 0.479816\n",
      "Iteration  3500, loss = 0.479811\n",
      "Iteration  3600, loss = 0.479807\n",
      "Iteration  3700, loss = 0.479802\n",
      "Iteration  3800, loss = 0.479798\n",
      "Iteration  3900, loss = 0.479794\n",
      "Iteration  4000, loss = 0.479790\n",
      "Iteration  4100, loss = 0.479786\n",
      "Iteration  4200, loss = 0.479783\n",
      "Iteration  4300, loss = 0.479779\n",
      "Iteration  4400, loss = 0.479776\n",
      "Iteration  4500, loss = 0.479772\n",
      "Iteration  4600, loss = 0.479769\n",
      "Iteration  4700, loss = 0.479766\n",
      "Iteration  4800, loss = 0.479763\n",
      "Iteration  4900, loss = 0.479760\n",
      "Iteration  5000, loss = 0.479757\n",
      "Iteration  5100, loss = 0.479754\n",
      "Iteration  5200, loss = 0.479752\n",
      "Iteration  5300, loss = 0.479749\n",
      "Iteration  5400, loss = 0.479747\n",
      "Iteration  5500, loss = 0.479744\n",
      "Iteration  5600, loss = 0.479742\n",
      "Iteration  5700, loss = 0.479739\n",
      "Iteration  5800, loss = 0.479737\n",
      "Iteration  5900, loss = 0.479735\n",
      "Iteration  6000, loss = 0.479733\n",
      "Iteration  6100, loss = 0.479730\n",
      "Iteration  6200, loss = 0.479728\n",
      "Iteration  6300, loss = 0.479726\n",
      "Iteration  6400, loss = 0.479724\n",
      "Iteration  6500, loss = 0.479722\n",
      "Iteration  6600, loss = 0.479720\n",
      "Iteration  6700, loss = 0.479719\n",
      "Iteration  6800, loss = 0.479717\n",
      "Iteration  6900, loss = 0.479715\n",
      "Iteration  7000, loss = 0.479713\n",
      "Iteration  7100, loss = 0.479711\n",
      "Iteration  7200, loss = 0.479710\n",
      "Iteration  7300, loss = 0.479708\n",
      "Iteration  7400, loss = 0.479706\n",
      "Iteration  7500, loss = 0.479705\n",
      "Iteration  7600, loss = 0.479703\n",
      "Iteration  7700, loss = 0.479702\n",
      "Iteration  7800, loss = 0.479700\n",
      "Iteration  7900, loss = 0.479699\n",
      "Iteration  8000, loss = 0.479697\n",
      "Iteration  8100, loss = 0.479696\n",
      "Iteration  8200, loss = 0.479694\n",
      "Iteration  8300, loss = 0.479693\n",
      "Iteration  8400, loss = 0.479692\n",
      "Iteration  8500, loss = 0.479690\n",
      "Iteration  8600, loss = 0.479689\n",
      "Iteration  8700, loss = 0.479687\n",
      "Iteration  8800, loss = 0.479686\n",
      "Iteration  8900, loss = 0.479685\n",
      "Iteration  9000, loss = 0.479684\n",
      "Iteration  9100, loss = 0.479682\n",
      "Iteration  9200, loss = 0.479681\n",
      "Iteration  9300, loss = 0.479680\n",
      "Iteration  9400, loss = 0.479679\n",
      "Iteration  9500, loss = 0.479677\n",
      "Iteration  9600, loss = 0.479676\n",
      "Iteration  9700, loss = 0.479675\n",
      "Iteration  9800, loss = 0.479674\n",
      "Iteration  9900, loss = 0.479673\n",
      " Accuracy: 85.83%\n",
      " F1 Score: 0.4075\n",
      "\n",
      "Validation loss: 0.48646705527952266 f1 score 0.40751831793564786 with data size of 20192\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480240\n",
      "Iteration   200, loss = 0.479322\n",
      "Iteration   300, loss = 0.479050\n",
      "Iteration   400, loss = 0.478908\n",
      "Iteration   500, loss = 0.478820\n",
      "Iteration   600, loss = 0.478757\n",
      "Iteration   700, loss = 0.478710\n",
      "Iteration   800, loss = 0.478673\n",
      "Iteration   900, loss = 0.478642\n",
      "Iteration  1000, loss = 0.478615\n",
      "Iteration  1100, loss = 0.478592\n",
      "Iteration  1200, loss = 0.478572\n",
      "Iteration  1300, loss = 0.478554\n",
      "Iteration  1400, loss = 0.478538\n",
      "Iteration  1500, loss = 0.478523\n",
      "Iteration  1600, loss = 0.478510\n",
      "Iteration  1700, loss = 0.478497\n",
      "Iteration  1800, loss = 0.478485\n",
      "Iteration  1900, loss = 0.478475\n",
      "Iteration  2000, loss = 0.478465\n",
      "Iteration  2100, loss = 0.478455\n",
      "Iteration  2200, loss = 0.478446\n",
      "Iteration  2300, loss = 0.478438\n",
      "Iteration  2400, loss = 0.478430\n",
      "Iteration  2500, loss = 0.478422\n",
      "Iteration  2600, loss = 0.478415\n",
      "Iteration  2700, loss = 0.478408\n",
      "Iteration  2800, loss = 0.478402\n",
      "Iteration  2900, loss = 0.478396\n",
      "Iteration  3000, loss = 0.478390\n",
      "Iteration  3100, loss = 0.478384\n",
      "Iteration  3200, loss = 0.478379\n",
      "Iteration  3300, loss = 0.478374\n",
      "Iteration  3400, loss = 0.478369\n",
      "Iteration  3500, loss = 0.478364\n",
      "Iteration  3600, loss = 0.478359\n",
      "Iteration  3700, loss = 0.478355\n",
      "Iteration  3800, loss = 0.478351\n",
      "Iteration  3900, loss = 0.478346\n",
      "Iteration  4000, loss = 0.478342\n",
      "Iteration  4100, loss = 0.478339\n",
      "Iteration  4200, loss = 0.478335\n",
      "Iteration  4300, loss = 0.478331\n",
      "Iteration  4400, loss = 0.478328\n",
      "Iteration  4500, loss = 0.478325\n",
      "Iteration  4600, loss = 0.478321\n",
      "Iteration  4700, loss = 0.478318\n",
      "Iteration  4800, loss = 0.478315\n",
      "Iteration  4900, loss = 0.478312\n",
      "Iteration  5000, loss = 0.478310\n",
      "Iteration  5100, loss = 0.478307\n",
      "Iteration  5200, loss = 0.478304\n",
      "Iteration  5300, loss = 0.478301\n",
      "Iteration  5400, loss = 0.478299\n",
      "Iteration  5500, loss = 0.478296\n",
      "Iteration  5600, loss = 0.478294\n",
      "Iteration  5700, loss = 0.478292\n",
      "Iteration  5800, loss = 0.478289\n",
      "Iteration  5900, loss = 0.478287\n",
      "Iteration  6000, loss = 0.478285\n",
      "Iteration  6100, loss = 0.478283\n",
      "Iteration  6200, loss = 0.478281\n",
      "Iteration  6300, loss = 0.478279\n",
      "Iteration  6400, loss = 0.478277\n",
      "Iteration  6500, loss = 0.478275\n",
      "Iteration  6600, loss = 0.478273\n",
      "Iteration  6700, loss = 0.478271\n",
      "Iteration  6800, loss = 0.478269\n",
      "Iteration  6900, loss = 0.478267\n",
      "Iteration  7000, loss = 0.478265\n",
      "Iteration  7100, loss = 0.478264\n",
      "Iteration  7200, loss = 0.478262\n",
      "Iteration  7300, loss = 0.478260\n",
      "Iteration  7400, loss = 0.478259\n",
      "Iteration  7500, loss = 0.478257\n",
      "Iteration  7600, loss = 0.478256\n",
      "Iteration  7700, loss = 0.478254\n",
      "Iteration  7800, loss = 0.478252\n",
      "Iteration  7900, loss = 0.478251\n",
      "Iteration  8000, loss = 0.478250\n",
      "Iteration  8100, loss = 0.478248\n",
      "Iteration  8200, loss = 0.478247\n",
      "Iteration  8300, loss = 0.478245\n",
      "Iteration  8400, loss = 0.478244\n",
      "Iteration  8500, loss = 0.478242\n",
      "Iteration  8600, loss = 0.478241\n",
      "Iteration  8700, loss = 0.478240\n",
      "Iteration  8800, loss = 0.478239\n",
      "Iteration  8900, loss = 0.478237\n",
      "Iteration  9000, loss = 0.478236\n",
      "Iteration  9100, loss = 0.478235\n",
      "Iteration  9200, loss = 0.478233\n",
      "Iteration  9300, loss = 0.478232\n",
      "Iteration  9400, loss = 0.478231\n",
      "Iteration  9500, loss = 0.478230\n",
      "Iteration  9600, loss = 0.478229\n",
      "Iteration  9700, loss = 0.478227\n",
      "Iteration  9800, loss = 0.478226\n",
      "Iteration  9900, loss = 0.478225\n",
      " Accuracy: 85.71%\n",
      " F1 Score: 0.4088\n",
      "\n",
      "Validation loss: 0.488010278641259 f1 score 0.40877845746358027 with data size of 21875\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.481242\n",
      "Iteration   200, loss = 0.480306\n",
      "Iteration   300, loss = 0.480027\n",
      "Iteration   400, loss = 0.479881\n",
      "Iteration   500, loss = 0.479789\n",
      "Iteration   600, loss = 0.479724\n",
      "Iteration   700, loss = 0.479674\n",
      "Iteration   800, loss = 0.479634\n",
      "Iteration   900, loss = 0.479601\n",
      "Iteration  1000, loss = 0.479573\n",
      "Iteration  1100, loss = 0.479548\n",
      "Iteration  1200, loss = 0.479526\n",
      "Iteration  1300, loss = 0.479506\n",
      "Iteration  1400, loss = 0.479488\n",
      "Iteration  1500, loss = 0.479471\n",
      "Iteration  1600, loss = 0.479456\n",
      "Iteration  1700, loss = 0.479442\n",
      "Iteration  1800, loss = 0.479429\n",
      "Iteration  1900, loss = 0.479416\n",
      "Iteration  2000, loss = 0.479405\n",
      "Iteration  2100, loss = 0.479394\n",
      "Iteration  2200, loss = 0.479383\n",
      "Iteration  2300, loss = 0.479374\n",
      "Iteration  2400, loss = 0.479364\n",
      "Iteration  2500, loss = 0.479356\n",
      "Iteration  2600, loss = 0.479347\n",
      "Iteration  2700, loss = 0.479339\n",
      "Iteration  2800, loss = 0.479332\n",
      "Iteration  2900, loss = 0.479324\n",
      "Iteration  3000, loss = 0.479317\n",
      "Iteration  3100, loss = 0.479311\n",
      "Iteration  3200, loss = 0.479304\n",
      "Iteration  3300, loss = 0.479298\n",
      "Iteration  3400, loss = 0.479292\n",
      "Iteration  3500, loss = 0.479287\n",
      "Iteration  3600, loss = 0.479281\n",
      "Iteration  3700, loss = 0.479276\n",
      "Iteration  3800, loss = 0.479271\n",
      "Iteration  3900, loss = 0.479266\n",
      "Iteration  4000, loss = 0.479262\n",
      "Iteration  4100, loss = 0.479257\n",
      "Iteration  4200, loss = 0.479253\n",
      "Iteration  4300, loss = 0.479249\n",
      "Iteration  4400, loss = 0.479245\n",
      "Iteration  4500, loss = 0.479241\n",
      "Iteration  4600, loss = 0.479237\n",
      "Iteration  4700, loss = 0.479233\n",
      "Iteration  4800, loss = 0.479230\n",
      "Iteration  4900, loss = 0.479226\n",
      "Iteration  5000, loss = 0.479223\n",
      "Iteration  5100, loss = 0.479220\n",
      "Iteration  5200, loss = 0.479217\n",
      "Iteration  5300, loss = 0.479214\n",
      "Iteration  5400, loss = 0.479211\n",
      "Iteration  5500, loss = 0.479208\n",
      "Iteration  5600, loss = 0.479205\n",
      "Iteration  5700, loss = 0.479202\n",
      "Iteration  5800, loss = 0.479200\n",
      "Iteration  5900, loss = 0.479197\n",
      "Iteration  6000, loss = 0.479194\n",
      "Iteration  6100, loss = 0.479192\n",
      "Iteration  6200, loss = 0.479190\n",
      "Iteration  6300, loss = 0.479187\n",
      "Iteration  6400, loss = 0.479185\n",
      "Iteration  6500, loss = 0.479183\n",
      "Iteration  6600, loss = 0.479180\n",
      "Iteration  6700, loss = 0.479178\n",
      "Iteration  6800, loss = 0.479176\n",
      "Iteration  6900, loss = 0.479174\n",
      "Iteration  7000, loss = 0.479172\n",
      "Iteration  7100, loss = 0.479170\n",
      "Iteration  7200, loss = 0.479168\n",
      "Iteration  7300, loss = 0.479166\n",
      "Iteration  7400, loss = 0.479165\n",
      "Iteration  7500, loss = 0.479163\n",
      "Iteration  7600, loss = 0.479161\n",
      "Iteration  7700, loss = 0.479159\n",
      "Iteration  7800, loss = 0.479157\n",
      "Iteration  7900, loss = 0.479156\n",
      "Iteration  8000, loss = 0.479154\n",
      "Iteration  8100, loss = 0.479153\n",
      "Iteration  8200, loss = 0.479151\n",
      "Iteration  8300, loss = 0.479149\n",
      "Iteration  8400, loss = 0.479148\n",
      "Iteration  8500, loss = 0.479146\n",
      "Iteration  8600, loss = 0.479145\n",
      "Iteration  8700, loss = 0.479143\n",
      "Iteration  8800, loss = 0.479142\n",
      "Iteration  8900, loss = 0.479140\n",
      "Iteration  9000, loss = 0.479139\n",
      "Iteration  9100, loss = 0.479138\n",
      "Iteration  9200, loss = 0.479136\n",
      "Iteration  9300, loss = 0.479135\n",
      "Iteration  9400, loss = 0.479134\n",
      "Iteration  9500, loss = 0.479132\n",
      "Iteration  9600, loss = 0.479131\n",
      "Iteration  9700, loss = 0.479130\n",
      "Iteration  9800, loss = 0.479128\n",
      "Iteration  9900, loss = 0.479127\n",
      " Accuracy: 85.64%\n",
      " F1 Score: 0.4071\n",
      "\n",
      "Validation loss: 0.4887613152202043 f1 score 0.4071464519375939 with data size of 23864\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480306\n",
      "Iteration   200, loss = 0.479427\n",
      "Iteration   300, loss = 0.479165\n",
      "Iteration   400, loss = 0.479025\n",
      "Iteration   500, loss = 0.478936\n",
      "Iteration   600, loss = 0.478874\n",
      "Iteration   700, loss = 0.478827\n",
      "Iteration   800, loss = 0.478790\n",
      "Iteration   900, loss = 0.478760\n",
      "Iteration  1000, loss = 0.478735\n",
      "Iteration  1100, loss = 0.478712\n",
      "Iteration  1200, loss = 0.478693\n",
      "Iteration  1300, loss = 0.478676\n",
      "Iteration  1400, loss = 0.478660\n",
      "Iteration  1500, loss = 0.478646\n",
      "Iteration  1600, loss = 0.478633\n",
      "Iteration  1700, loss = 0.478620\n",
      "Iteration  1800, loss = 0.478609\n",
      "Iteration  1900, loss = 0.478599\n",
      "Iteration  2000, loss = 0.478589\n",
      "Iteration  2100, loss = 0.478580\n",
      "Iteration  2200, loss = 0.478571\n",
      "Iteration  2300, loss = 0.478563\n",
      "Iteration  2400, loss = 0.478555\n",
      "Iteration  2500, loss = 0.478548\n",
      "Iteration  2600, loss = 0.478541\n",
      "Iteration  2700, loss = 0.478534\n",
      "Iteration  2800, loss = 0.478528\n",
      "Iteration  2900, loss = 0.478522\n",
      "Iteration  3000, loss = 0.478516\n",
      "Iteration  3100, loss = 0.478511\n",
      "Iteration  3200, loss = 0.478505\n",
      "Iteration  3300, loss = 0.478500\n",
      "Iteration  3400, loss = 0.478496\n",
      "Iteration  3500, loss = 0.478491\n",
      "Iteration  3600, loss = 0.478486\n",
      "Iteration  3700, loss = 0.478482\n",
      "Iteration  3800, loss = 0.478478\n",
      "Iteration  3900, loss = 0.478474\n",
      "Iteration  4000, loss = 0.478470\n",
      "Iteration  4100, loss = 0.478466\n",
      "Iteration  4200, loss = 0.478463\n",
      "Iteration  4300, loss = 0.478459\n",
      "Iteration  4400, loss = 0.478456\n",
      "Iteration  4500, loss = 0.478453\n",
      "Iteration  4600, loss = 0.478450\n",
      "Iteration  4700, loss = 0.478447\n",
      "Iteration  4800, loss = 0.478444\n",
      "Iteration  4900, loss = 0.478441\n",
      "Iteration  5000, loss = 0.478438\n",
      "Iteration  5100, loss = 0.478435\n",
      "Iteration  5200, loss = 0.478433\n",
      "Iteration  5300, loss = 0.478430\n",
      "Iteration  5400, loss = 0.478428\n",
      "Iteration  5500, loss = 0.478425\n",
      "Iteration  5600, loss = 0.478423\n",
      "Iteration  5700, loss = 0.478421\n",
      "Iteration  5800, loss = 0.478418\n",
      "Iteration  5900, loss = 0.478416\n",
      "Iteration  6000, loss = 0.478414\n",
      "Iteration  6100, loss = 0.478412\n",
      "Iteration  6200, loss = 0.478410\n",
      "Iteration  6300, loss = 0.478408\n",
      "Iteration  6400, loss = 0.478406\n",
      "Iteration  6500, loss = 0.478404\n",
      "Iteration  6600, loss = 0.478402\n",
      "Iteration  6700, loss = 0.478400\n",
      "Iteration  6800, loss = 0.478399\n",
      "Iteration  6900, loss = 0.478397\n",
      "Iteration  7000, loss = 0.478395\n",
      "Iteration  7100, loss = 0.478393\n",
      "Iteration  7200, loss = 0.478392\n",
      "Iteration  7300, loss = 0.478390\n",
      "Iteration  7400, loss = 0.478388\n",
      "Iteration  7500, loss = 0.478387\n",
      "Iteration  7600, loss = 0.478385\n",
      "Iteration  7700, loss = 0.478384\n",
      "Iteration  7800, loss = 0.478382\n",
      "Iteration  7900, loss = 0.478381\n",
      "Iteration  8000, loss = 0.478379\n",
      "Iteration  8100, loss = 0.478378\n",
      "Iteration  8200, loss = 0.478376\n",
      "Iteration  8300, loss = 0.478375\n",
      "Iteration  8400, loss = 0.478374\n",
      "Iteration  8500, loss = 0.478372\n",
      "Iteration  8600, loss = 0.478371\n",
      "Iteration  8700, loss = 0.478369\n",
      "Iteration  8800, loss = 0.478368\n",
      "Iteration  8900, loss = 0.478367\n",
      "Iteration  9000, loss = 0.478366\n",
      "Iteration  9100, loss = 0.478364\n",
      "Iteration  9200, loss = 0.478363\n",
      "Iteration  9300, loss = 0.478362\n",
      "Iteration  9400, loss = 0.478361\n",
      "Iteration  9500, loss = 0.478359\n",
      "Iteration  9600, loss = 0.478358\n",
      "Iteration  9700, loss = 0.478357\n",
      "Iteration  9800, loss = 0.478356\n",
      "Iteration  9900, loss = 0.478355\n",
      " Accuracy: 85.52%\n",
      " F1 Score: 0.4057\n",
      "\n",
      "Validation loss: 0.4906768206448792 f1 score 0.4057264316079015 with data size of 26250\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.481591\n",
      "Iteration   200, loss = 0.480714\n",
      "Iteration   300, loss = 0.480446\n",
      "Iteration   400, loss = 0.480303\n",
      "Iteration   500, loss = 0.480212\n",
      "Iteration   600, loss = 0.480148\n",
      "Iteration   700, loss = 0.480100\n",
      "Iteration   800, loss = 0.480061\n",
      "Iteration   900, loss = 0.480029\n",
      "Iteration  1000, loss = 0.480002\n",
      "Iteration  1100, loss = 0.479978\n",
      "Iteration  1200, loss = 0.479958\n",
      "Iteration  1300, loss = 0.479939\n",
      "Iteration  1400, loss = 0.479922\n",
      "Iteration  1500, loss = 0.479907\n",
      "Iteration  1600, loss = 0.479893\n",
      "Iteration  1700, loss = 0.479880\n",
      "Iteration  1800, loss = 0.479868\n",
      "Iteration  1900, loss = 0.479856\n",
      "Iteration  2000, loss = 0.479846\n",
      "Iteration  2100, loss = 0.479836\n",
      "Iteration  2200, loss = 0.479826\n",
      "Iteration  2300, loss = 0.479818\n",
      "Iteration  2400, loss = 0.479809\n",
      "Iteration  2500, loss = 0.479801\n",
      "Iteration  2600, loss = 0.479794\n",
      "Iteration  2700, loss = 0.479787\n",
      "Iteration  2800, loss = 0.479780\n",
      "Iteration  2900, loss = 0.479774\n",
      "Iteration  3000, loss = 0.479768\n",
      "Iteration  3100, loss = 0.479762\n",
      "Iteration  3200, loss = 0.479756\n",
      "Iteration  3300, loss = 0.479751\n",
      "Iteration  3400, loss = 0.479746\n",
      "Iteration  3500, loss = 0.479741\n",
      "Iteration  3600, loss = 0.479736\n",
      "Iteration  3700, loss = 0.479732\n",
      "Iteration  3800, loss = 0.479727\n",
      "Iteration  3900, loss = 0.479723\n",
      "Iteration  4000, loss = 0.479719\n",
      "Iteration  4100, loss = 0.479715\n",
      "Iteration  4200, loss = 0.479711\n",
      "Iteration  4300, loss = 0.479708\n",
      "Iteration  4400, loss = 0.479704\n",
      "Iteration  4500, loss = 0.479701\n",
      "Iteration  4600, loss = 0.479698\n",
      "Iteration  4700, loss = 0.479694\n",
      "Iteration  4800, loss = 0.479691\n",
      "Iteration  4900, loss = 0.479688\n",
      "Iteration  5000, loss = 0.479685\n",
      "Iteration  5100, loss = 0.479683\n",
      "Iteration  5200, loss = 0.479680\n",
      "Iteration  5300, loss = 0.479677\n",
      "Iteration  5400, loss = 0.479675\n",
      "Iteration  5500, loss = 0.479672\n",
      "Iteration  5600, loss = 0.479670\n",
      "Iteration  5700, loss = 0.479667\n",
      "Iteration  5800, loss = 0.479665\n",
      "Iteration  5900, loss = 0.479663\n",
      "Iteration  6000, loss = 0.479660\n",
      "Iteration  6100, loss = 0.479658\n",
      "Iteration  6200, loss = 0.479656\n",
      "Iteration  6300, loss = 0.479654\n",
      "Iteration  6400, loss = 0.479652\n",
      "Iteration  6500, loss = 0.479650\n",
      "Iteration  6600, loss = 0.479648\n",
      "Iteration  6700, loss = 0.479646\n",
      "Iteration  6800, loss = 0.479644\n",
      "Iteration  6900, loss = 0.479642\n",
      "Iteration  7000, loss = 0.479641\n",
      "Iteration  7100, loss = 0.479639\n",
      "Iteration  7200, loss = 0.479637\n",
      "Iteration  7300, loss = 0.479635\n",
      "Iteration  7400, loss = 0.479634\n",
      "Iteration  7500, loss = 0.479632\n",
      "Iteration  7600, loss = 0.479630\n",
      "Iteration  7700, loss = 0.479629\n",
      "Iteration  7800, loss = 0.479627\n",
      "Iteration  7900, loss = 0.479626\n",
      "Iteration  8000, loss = 0.479624\n",
      "Iteration  8100, loss = 0.479622\n",
      "Iteration  8200, loss = 0.479621\n",
      "Iteration  8300, loss = 0.479620\n",
      "Iteration  8400, loss = 0.479618\n",
      "Iteration  8500, loss = 0.479617\n",
      "Iteration  8600, loss = 0.479615\n",
      "Iteration  8700, loss = 0.479614\n",
      "Iteration  8800, loss = 0.479612\n",
      "Iteration  8900, loss = 0.479611\n",
      "Iteration  9000, loss = 0.479610\n",
      "Iteration  9100, loss = 0.479608\n",
      "Iteration  9200, loss = 0.479607\n",
      "Iteration  9300, loss = 0.479606\n",
      "Iteration  9400, loss = 0.479604\n",
      "Iteration  9500, loss = 0.479603\n",
      "Iteration  9600, loss = 0.479602\n",
      "Iteration  9700, loss = 0.479601\n",
      "Iteration  9800, loss = 0.479599\n",
      "Iteration  9900, loss = 0.479598\n",
      " Accuracy: 85.53%\n",
      " F1 Score: 0.4072\n",
      "\n",
      "Validation loss: 0.49142285106197076 f1 score 0.40716470074268196 with data size of 29167\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479996\n",
      "Iteration   200, loss = 0.479096\n",
      "Iteration   300, loss = 0.478822\n",
      "Iteration   400, loss = 0.478675\n",
      "Iteration   500, loss = 0.478582\n",
      "Iteration   600, loss = 0.478517\n",
      "Iteration   700, loss = 0.478468\n",
      "Iteration   800, loss = 0.478429\n",
      "Iteration   900, loss = 0.478398\n",
      "Iteration  1000, loss = 0.478371\n",
      "Iteration  1100, loss = 0.478349\n",
      "Iteration  1200, loss = 0.478329\n",
      "Iteration  1300, loss = 0.478311\n",
      "Iteration  1400, loss = 0.478296\n",
      "Iteration  1500, loss = 0.478282\n",
      "Iteration  1600, loss = 0.478269\n",
      "Iteration  1700, loss = 0.478257\n",
      "Iteration  1800, loss = 0.478246\n",
      "Iteration  1900, loss = 0.478236\n",
      "Iteration  2000, loss = 0.478226\n",
      "Iteration  2100, loss = 0.478217\n",
      "Iteration  2200, loss = 0.478209\n",
      "Iteration  2300, loss = 0.478201\n",
      "Iteration  2400, loss = 0.478194\n",
      "Iteration  2500, loss = 0.478187\n",
      "Iteration  2600, loss = 0.478180\n",
      "Iteration  2700, loss = 0.478174\n",
      "Iteration  2800, loss = 0.478168\n",
      "Iteration  2900, loss = 0.478162\n",
      "Iteration  3000, loss = 0.478156\n",
      "Iteration  3100, loss = 0.478151\n",
      "Iteration  3200, loss = 0.478146\n",
      "Iteration  3300, loss = 0.478141\n",
      "Iteration  3400, loss = 0.478136\n",
      "Iteration  3500, loss = 0.478132\n",
      "Iteration  3600, loss = 0.478128\n",
      "Iteration  3700, loss = 0.478124\n",
      "Iteration  3800, loss = 0.478120\n",
      "Iteration  3900, loss = 0.478116\n",
      "Iteration  4000, loss = 0.478112\n",
      "Iteration  4100, loss = 0.478108\n",
      "Iteration  4200, loss = 0.478105\n",
      "Iteration  4300, loss = 0.478102\n",
      "Iteration  4400, loss = 0.478098\n",
      "Iteration  4500, loss = 0.478095\n",
      "Iteration  4600, loss = 0.478092\n",
      "Iteration  4700, loss = 0.478089\n",
      "Iteration  4800, loss = 0.478086\n",
      "Iteration  4900, loss = 0.478083\n",
      "Iteration  5000, loss = 0.478081\n",
      "Iteration  5100, loss = 0.478078\n",
      "Iteration  5200, loss = 0.478076\n",
      "Iteration  5300, loss = 0.478073\n",
      "Iteration  5400, loss = 0.478071\n",
      "Iteration  5500, loss = 0.478068\n",
      "Iteration  5600, loss = 0.478066\n",
      "Iteration  5700, loss = 0.478063\n",
      "Iteration  5800, loss = 0.478061\n",
      "Iteration  5900, loss = 0.478059\n",
      "Iteration  6000, loss = 0.478057\n",
      "Iteration  6100, loss = 0.478055\n",
      "Iteration  6200, loss = 0.478053\n",
      "Iteration  6300, loss = 0.478051\n",
      "Iteration  6400, loss = 0.478049\n",
      "Iteration  6500, loss = 0.478047\n",
      "Iteration  6600, loss = 0.478045\n",
      "Iteration  6700, loss = 0.478043\n",
      "Iteration  6800, loss = 0.478041\n",
      "Iteration  6900, loss = 0.478039\n",
      "Iteration  7000, loss = 0.478038\n",
      "Iteration  7100, loss = 0.478036\n",
      "Iteration  7200, loss = 0.478034\n",
      "Iteration  7300, loss = 0.478033\n",
      "Iteration  7400, loss = 0.478031\n",
      "Iteration  7500, loss = 0.478029\n",
      "Iteration  7600, loss = 0.478028\n",
      "Iteration  7700, loss = 0.478026\n",
      "Iteration  7800, loss = 0.478024\n",
      "Iteration  7900, loss = 0.478023\n",
      "Iteration  8000, loss = 0.478021\n",
      "Iteration  8100, loss = 0.478020\n",
      "Iteration  8200, loss = 0.478018\n",
      "Iteration  8300, loss = 0.478017\n",
      "Iteration  8400, loss = 0.478016\n",
      "Iteration  8500, loss = 0.478014\n",
      "Iteration  8600, loss = 0.478013\n",
      "Iteration  8700, loss = 0.478011\n",
      "Iteration  8800, loss = 0.478010\n",
      "Iteration  8900, loss = 0.478009\n",
      "Iteration  9000, loss = 0.478007\n",
      "Iteration  9100, loss = 0.478006\n",
      "Iteration  9200, loss = 0.478005\n",
      "Iteration  9300, loss = 0.478004\n",
      "Iteration  9400, loss = 0.478002\n",
      "Iteration  9500, loss = 0.478001\n",
      "Iteration  9600, loss = 0.478000\n",
      "Iteration  9700, loss = 0.477999\n",
      "Iteration  9800, loss = 0.477997\n",
      "Iteration  9900, loss = 0.477996\n",
      " Accuracy: 85.52%\n",
      " F1 Score: 0.4066\n",
      "\n",
      "Validation loss: 0.49041808556156025 f1 score 0.4065934065934061 with data size of 32813\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478613\n",
      "Iteration   200, loss = 0.477697\n",
      "Iteration   300, loss = 0.477412\n",
      "Iteration   400, loss = 0.477258\n",
      "Iteration   500, loss = 0.477161\n",
      "Iteration   600, loss = 0.477094\n",
      "Iteration   700, loss = 0.477044\n",
      "Iteration   800, loss = 0.477004\n",
      "Iteration   900, loss = 0.476972\n",
      "Iteration  1000, loss = 0.476946\n",
      "Iteration  1100, loss = 0.476923\n",
      "Iteration  1200, loss = 0.476903\n",
      "Iteration  1300, loss = 0.476885\n",
      "Iteration  1400, loss = 0.476870\n",
      "Iteration  1500, loss = 0.476856\n",
      "Iteration  1600, loss = 0.476843\n",
      "Iteration  1700, loss = 0.476831\n",
      "Iteration  1800, loss = 0.476820\n",
      "Iteration  1900, loss = 0.476810\n",
      "Iteration  2000, loss = 0.476800\n",
      "Iteration  2100, loss = 0.476792\n",
      "Iteration  2200, loss = 0.476783\n",
      "Iteration  2300, loss = 0.476776\n",
      "Iteration  2400, loss = 0.476768\n",
      "Iteration  2500, loss = 0.476761\n",
      "Iteration  2600, loss = 0.476755\n",
      "Iteration  2700, loss = 0.476748\n",
      "Iteration  2800, loss = 0.476743\n",
      "Iteration  2900, loss = 0.476737\n",
      "Iteration  3000, loss = 0.476731\n",
      "Iteration  3100, loss = 0.476726\n",
      "Iteration  3200, loss = 0.476721\n",
      "Iteration  3300, loss = 0.476717\n",
      "Iteration  3400, loss = 0.476712\n",
      "Iteration  3500, loss = 0.476708\n",
      "Iteration  3600, loss = 0.476703\n",
      "Iteration  3700, loss = 0.476699\n",
      "Iteration  3800, loss = 0.476695\n",
      "Iteration  3900, loss = 0.476692\n",
      "Iteration  4000, loss = 0.476688\n",
      "Iteration  4100, loss = 0.476685\n",
      "Iteration  4200, loss = 0.476681\n",
      "Iteration  4300, loss = 0.476678\n",
      "Iteration  4400, loss = 0.476675\n",
      "Iteration  4500, loss = 0.476672\n",
      "Iteration  4600, loss = 0.476669\n",
      "Iteration  4700, loss = 0.476666\n",
      "Iteration  4800, loss = 0.476663\n",
      "Iteration  4900, loss = 0.476660\n",
      "Iteration  5000, loss = 0.476657\n",
      "Iteration  5100, loss = 0.476655\n",
      "Iteration  5200, loss = 0.476652\n",
      "Iteration  5300, loss = 0.476650\n",
      "Iteration  5400, loss = 0.476647\n",
      "Iteration  5500, loss = 0.476645\n",
      "Iteration  5600, loss = 0.476643\n",
      "Iteration  5700, loss = 0.476641\n",
      "Iteration  5800, loss = 0.476638\n",
      "Iteration  5900, loss = 0.476636\n",
      "Iteration  6000, loss = 0.476634\n",
      "Iteration  6100, loss = 0.476632\n",
      "Iteration  6200, loss = 0.476630\n",
      "Iteration  6300, loss = 0.476628\n",
      "Iteration  6400, loss = 0.476626\n",
      "Iteration  6500, loss = 0.476624\n",
      "Iteration  6600, loss = 0.476623\n",
      "Iteration  6700, loss = 0.476621\n",
      "Iteration  6800, loss = 0.476619\n",
      "Iteration  6900, loss = 0.476617\n",
      "Iteration  7000, loss = 0.476615\n",
      "Iteration  7100, loss = 0.476614\n",
      "Iteration  7200, loss = 0.476612\n",
      "Iteration  7300, loss = 0.476610\n",
      "Iteration  7400, loss = 0.476609\n",
      "Iteration  7500, loss = 0.476607\n",
      "Iteration  7600, loss = 0.476606\n",
      "Iteration  7700, loss = 0.476604\n",
      "Iteration  7800, loss = 0.476603\n",
      "Iteration  7900, loss = 0.476601\n",
      "Iteration  8000, loss = 0.476600\n",
      "Iteration  8100, loss = 0.476598\n",
      "Iteration  8200, loss = 0.476597\n",
      "Iteration  8300, loss = 0.476595\n",
      "Iteration  8400, loss = 0.476594\n",
      "Iteration  8500, loss = 0.476593\n",
      "Iteration  8600, loss = 0.476591\n",
      "Iteration  8700, loss = 0.476590\n",
      "Iteration  8800, loss = 0.476589\n",
      "Iteration  8900, loss = 0.476587\n",
      "Iteration  9000, loss = 0.476586\n",
      "Iteration  9100, loss = 0.476585\n",
      "Iteration  9200, loss = 0.476584\n",
      "Iteration  9300, loss = 0.476582\n",
      "Iteration  9400, loss = 0.476581\n",
      "Iteration  9500, loss = 0.476580\n",
      "Iteration  9600, loss = 0.476579\n",
      "Iteration  9700, loss = 0.476578\n",
      "Iteration  9800, loss = 0.476576\n",
      "Iteration  9900, loss = 0.476575\n",
      " Accuracy: 85.57%\n",
      " F1 Score: 0.4082\n",
      "\n",
      "Validation loss: 0.4883372675418509 f1 score 0.40822191678120656 with data size of 37501\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478246\n",
      "Iteration   200, loss = 0.477327\n",
      "Iteration   300, loss = 0.477047\n",
      "Iteration   400, loss = 0.476900\n",
      "Iteration   500, loss = 0.476809\n",
      "Iteration   600, loss = 0.476747\n",
      "Iteration   700, loss = 0.476702\n",
      "Iteration   800, loss = 0.476667\n",
      "Iteration   900, loss = 0.476639\n",
      "Iteration  1000, loss = 0.476615\n",
      "Iteration  1100, loss = 0.476595\n",
      "Iteration  1200, loss = 0.476577\n",
      "Iteration  1300, loss = 0.476562\n",
      "Iteration  1400, loss = 0.476548\n",
      "Iteration  1500, loss = 0.476536\n",
      "Iteration  1600, loss = 0.476524\n",
      "Iteration  1700, loss = 0.476514\n",
      "Iteration  1800, loss = 0.476504\n",
      "Iteration  1900, loss = 0.476495\n",
      "Iteration  2000, loss = 0.476486\n",
      "Iteration  2100, loss = 0.476479\n",
      "Iteration  2200, loss = 0.476471\n",
      "Iteration  2300, loss = 0.476464\n",
      "Iteration  2400, loss = 0.476458\n",
      "Iteration  2500, loss = 0.476451\n",
      "Iteration  2600, loss = 0.476445\n",
      "Iteration  2700, loss = 0.476440\n",
      "Iteration  2800, loss = 0.476434\n",
      "Iteration  2900, loss = 0.476429\n",
      "Iteration  3000, loss = 0.476424\n",
      "Iteration  3100, loss = 0.476420\n",
      "Iteration  3200, loss = 0.476415\n",
      "Iteration  3300, loss = 0.476411\n",
      "Iteration  3400, loss = 0.476407\n",
      "Iteration  3500, loss = 0.476403\n",
      "Iteration  3600, loss = 0.476399\n",
      "Iteration  3700, loss = 0.476395\n",
      "Iteration  3800, loss = 0.476392\n",
      "Iteration  3900, loss = 0.476388\n",
      "Iteration  4000, loss = 0.476385\n",
      "Iteration  4100, loss = 0.476382\n",
      "Iteration  4200, loss = 0.476379\n",
      "Iteration  4300, loss = 0.476376\n",
      "Iteration  4400, loss = 0.476373\n",
      "Iteration  4500, loss = 0.476370\n",
      "Iteration  4600, loss = 0.476367\n",
      "Iteration  4700, loss = 0.476365\n",
      "Iteration  4800, loss = 0.476362\n",
      "Iteration  4900, loss = 0.476360\n",
      "Iteration  5000, loss = 0.476357\n",
      "Iteration  5100, loss = 0.476355\n",
      "Iteration  5200, loss = 0.476353\n",
      "Iteration  5300, loss = 0.476350\n",
      "Iteration  5400, loss = 0.476348\n",
      "Iteration  5500, loss = 0.476346\n",
      "Iteration  5600, loss = 0.476344\n",
      "Iteration  5700, loss = 0.476342\n",
      "Iteration  5800, loss = 0.476340\n",
      "Iteration  5900, loss = 0.476338\n",
      "Iteration  6000, loss = 0.476336\n",
      "Iteration  6100, loss = 0.476334\n",
      "Iteration  6200, loss = 0.476332\n",
      "Iteration  6300, loss = 0.476330\n",
      "Iteration  6400, loss = 0.476329\n",
      "Iteration  6500, loss = 0.476327\n",
      "Iteration  6600, loss = 0.476325\n",
      "Iteration  6700, loss = 0.476323\n",
      "Iteration  6800, loss = 0.476322\n",
      "Iteration  6900, loss = 0.476320\n",
      "Iteration  7000, loss = 0.476319\n",
      "Iteration  7100, loss = 0.476317\n",
      "Iteration  7200, loss = 0.476315\n",
      "Iteration  7300, loss = 0.476314\n",
      "Iteration  7400, loss = 0.476312\n",
      "Iteration  7500, loss = 0.476311\n",
      "Iteration  7600, loss = 0.476309\n",
      "Iteration  7700, loss = 0.476308\n",
      "Iteration  7800, loss = 0.476307\n",
      "Iteration  7900, loss = 0.476305\n",
      "Iteration  8000, loss = 0.476304\n",
      "Iteration  8100, loss = 0.476303\n",
      "Iteration  8200, loss = 0.476301\n",
      "Iteration  8300, loss = 0.476300\n",
      "Iteration  8400, loss = 0.476299\n",
      "Iteration  8500, loss = 0.476297\n",
      "Iteration  8600, loss = 0.476296\n",
      "Iteration  8700, loss = 0.476295\n",
      "Iteration  8800, loss = 0.476294\n",
      "Iteration  8900, loss = 0.476292\n",
      "Iteration  9000, loss = 0.476291\n",
      "Iteration  9100, loss = 0.476290\n",
      "Iteration  9200, loss = 0.476289\n",
      "Iteration  9300, loss = 0.476288\n",
      "Iteration  9400, loss = 0.476286\n",
      "Iteration  9500, loss = 0.476285\n",
      "Iteration  9600, loss = 0.476284\n",
      "Iteration  9700, loss = 0.476283\n",
      "Iteration  9800, loss = 0.476282\n",
      "Iteration  9900, loss = 0.476281\n",
      " Accuracy: 85.55%\n",
      " F1 Score: 0.4089\n",
      "\n",
      "Validation loss: 0.4888581119241422 f1 score 0.40887835899993713 with data size of 43751\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478435\n",
      "Iteration   200, loss = 0.477515\n",
      "Iteration   300, loss = 0.477240\n",
      "Iteration   400, loss = 0.477101\n",
      "Iteration   500, loss = 0.477018\n",
      "Iteration   600, loss = 0.476962\n",
      "Iteration   700, loss = 0.476922\n",
      "Iteration   800, loss = 0.476891\n",
      "Iteration   900, loss = 0.476867\n",
      "Iteration  1000, loss = 0.476846\n",
      "Iteration  1100, loss = 0.476828\n",
      "Iteration  1200, loss = 0.476813\n",
      "Iteration  1300, loss = 0.476799\n",
      "Iteration  1400, loss = 0.476787\n",
      "Iteration  1500, loss = 0.476776\n",
      "Iteration  1600, loss = 0.476766\n",
      "Iteration  1700, loss = 0.476756\n",
      "Iteration  1800, loss = 0.476747\n",
      "Iteration  1900, loss = 0.476739\n",
      "Iteration  2000, loss = 0.476732\n",
      "Iteration  2100, loss = 0.476724\n",
      "Iteration  2200, loss = 0.476718\n",
      "Iteration  2300, loss = 0.476711\n",
      "Iteration  2400, loss = 0.476705\n",
      "Iteration  2500, loss = 0.476699\n",
      "Iteration  2600, loss = 0.476694\n",
      "Iteration  2700, loss = 0.476689\n",
      "Iteration  2800, loss = 0.476684\n",
      "Iteration  2900, loss = 0.476679\n",
      "Iteration  3000, loss = 0.476675\n",
      "Iteration  3100, loss = 0.476670\n",
      "Iteration  3200, loss = 0.476666\n",
      "Iteration  3300, loss = 0.476662\n",
      "Iteration  3400, loss = 0.476658\n",
      "Iteration  3500, loss = 0.476655\n",
      "Iteration  3600, loss = 0.476651\n",
      "Iteration  3700, loss = 0.476648\n",
      "Iteration  3800, loss = 0.476644\n",
      "Iteration  3900, loss = 0.476641\n",
      "Iteration  4000, loss = 0.476638\n",
      "Iteration  4100, loss = 0.476635\n",
      "Iteration  4200, loss = 0.476632\n",
      "Iteration  4300, loss = 0.476629\n",
      "Iteration  4400, loss = 0.476627\n",
      "Iteration  4500, loss = 0.476624\n",
      "Iteration  4600, loss = 0.476621\n",
      "Iteration  4700, loss = 0.476619\n",
      "Iteration  4800, loss = 0.476617\n",
      "Iteration  4900, loss = 0.476614\n",
      "Iteration  5000, loss = 0.476612\n",
      "Iteration  5100, loss = 0.476610\n",
      "Iteration  5200, loss = 0.476607\n",
      "Iteration  5300, loss = 0.476605\n",
      "Iteration  5400, loss = 0.476603\n",
      "Iteration  5500, loss = 0.476601\n",
      "Iteration  5600, loss = 0.476599\n",
      "Iteration  5700, loss = 0.476597\n",
      "Iteration  5800, loss = 0.476595\n",
      "Iteration  5900, loss = 0.476593\n",
      "Iteration  6000, loss = 0.476592\n",
      "Iteration  6100, loss = 0.476590\n",
      "Iteration  6200, loss = 0.476588\n",
      "Iteration  6300, loss = 0.476586\n",
      "Iteration  6400, loss = 0.476585\n",
      "Iteration  6500, loss = 0.476583\n",
      "Iteration  6600, loss = 0.476581\n",
      "Iteration  6700, loss = 0.476580\n",
      "Iteration  6800, loss = 0.476578\n",
      "Iteration  6900, loss = 0.476577\n",
      "Iteration  7000, loss = 0.476575\n",
      "Iteration  7100, loss = 0.476574\n",
      "Iteration  7200, loss = 0.476572\n",
      "Iteration  7300, loss = 0.476571\n",
      "Iteration  7400, loss = 0.476569\n",
      "Iteration  7500, loss = 0.476568\n",
      "Iteration  7600, loss = 0.476566\n",
      "Iteration  7700, loss = 0.476565\n",
      "Iteration  7800, loss = 0.476564\n",
      "Iteration  7900, loss = 0.476562\n",
      "Iteration  8000, loss = 0.476561\n",
      "Iteration  8100, loss = 0.476560\n",
      "Iteration  8200, loss = 0.476558\n",
      "Iteration  8300, loss = 0.476557\n",
      "Iteration  8400, loss = 0.476556\n",
      "Iteration  8500, loss = 0.476555\n",
      "Iteration  8600, loss = 0.476553\n",
      "Iteration  8700, loss = 0.476552\n",
      "Iteration  8800, loss = 0.476551\n",
      "Iteration  8900, loss = 0.476550\n",
      "Iteration  9000, loss = 0.476549\n",
      "Iteration  9100, loss = 0.476547\n",
      "Iteration  9200, loss = 0.476546\n",
      "Iteration  9300, loss = 0.476545\n",
      "Iteration  9400, loss = 0.476544\n",
      "Iteration  9500, loss = 0.476543\n",
      "Iteration  9600, loss = 0.476542\n",
      "Iteration  9700, loss = 0.476541\n",
      "Iteration  9800, loss = 0.476540\n",
      "Iteration  9900, loss = 0.476538\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4085\n",
      "\n",
      "Validation loss: 0.4881518971410055 f1 score 0.408466533466533 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478435\n",
      "Iteration   200, loss = 0.477515\n",
      "Iteration   300, loss = 0.477240\n",
      "Iteration   400, loss = 0.477101\n",
      "Iteration   500, loss = 0.477018\n",
      "Iteration   600, loss = 0.476962\n",
      "Iteration   700, loss = 0.476922\n",
      "Iteration   800, loss = 0.476891\n",
      "Iteration   900, loss = 0.476867\n",
      "Iteration  1000, loss = 0.476846\n",
      "Iteration  1100, loss = 0.476828\n",
      "Iteration  1200, loss = 0.476813\n",
      "Iteration  1300, loss = 0.476799\n",
      "Iteration  1400, loss = 0.476787\n",
      "Iteration  1500, loss = 0.476776\n",
      "Iteration  1600, loss = 0.476766\n",
      "Iteration  1700, loss = 0.476756\n",
      "Iteration  1800, loss = 0.476747\n",
      "Iteration  1900, loss = 0.476739\n",
      "Iteration  2000, loss = 0.476732\n",
      "Iteration  2100, loss = 0.476724\n",
      "Iteration  2200, loss = 0.476718\n",
      "Iteration  2300, loss = 0.476711\n",
      "Iteration  2400, loss = 0.476705\n",
      "Iteration  2500, loss = 0.476699\n",
      "Iteration  2600, loss = 0.476694\n",
      "Iteration  2700, loss = 0.476689\n",
      "Iteration  2800, loss = 0.476684\n",
      "Iteration  2900, loss = 0.476679\n",
      "Iteration  3000, loss = 0.476675\n",
      "Iteration  3100, loss = 0.476670\n",
      "Iteration  3200, loss = 0.476666\n",
      "Iteration  3300, loss = 0.476662\n",
      "Iteration  3400, loss = 0.476658\n",
      "Iteration  3500, loss = 0.476655\n",
      "Iteration  3600, loss = 0.476651\n",
      "Iteration  3700, loss = 0.476648\n",
      "Iteration  3800, loss = 0.476644\n",
      "Iteration  3900, loss = 0.476641\n",
      "Iteration  4000, loss = 0.476638\n",
      "Iteration  4100, loss = 0.476635\n",
      "Iteration  4200, loss = 0.476632\n",
      "Iteration  4300, loss = 0.476629\n",
      "Iteration  4400, loss = 0.476627\n",
      "Iteration  4500, loss = 0.476624\n",
      "Iteration  4600, loss = 0.476621\n",
      "Iteration  4700, loss = 0.476619\n",
      "Iteration  4800, loss = 0.476617\n",
      "Iteration  4900, loss = 0.476614\n",
      "Iteration  5000, loss = 0.476612\n",
      "Iteration  5100, loss = 0.476610\n",
      "Iteration  5200, loss = 0.476607\n",
      "Iteration  5300, loss = 0.476605\n",
      "Iteration  5400, loss = 0.476603\n",
      "Iteration  5500, loss = 0.476601\n",
      "Iteration  5600, loss = 0.476599\n",
      "Iteration  5700, loss = 0.476597\n",
      "Iteration  5800, loss = 0.476595\n",
      "Iteration  5900, loss = 0.476593\n",
      "Iteration  6000, loss = 0.476592\n",
      "Iteration  6100, loss = 0.476590\n",
      "Iteration  6200, loss = 0.476588\n",
      "Iteration  6300, loss = 0.476586\n",
      "Iteration  6400, loss = 0.476585\n",
      "Iteration  6500, loss = 0.476583\n",
      "Iteration  6600, loss = 0.476581\n",
      "Iteration  6700, loss = 0.476580\n",
      "Iteration  6800, loss = 0.476578\n",
      "Iteration  6900, loss = 0.476577\n",
      "Iteration  7000, loss = 0.476575\n",
      "Iteration  7100, loss = 0.476574\n",
      "Iteration  7200, loss = 0.476572\n",
      "Iteration  7300, loss = 0.476571\n",
      "Iteration  7400, loss = 0.476569\n",
      "Iteration  7500, loss = 0.476568\n",
      "Iteration  7600, loss = 0.476566\n",
      "Iteration  7700, loss = 0.476565\n",
      "Iteration  7800, loss = 0.476564\n",
      "Iteration  7900, loss = 0.476562\n",
      "Iteration  8000, loss = 0.476561\n",
      "Iteration  8100, loss = 0.476560\n",
      "Iteration  8200, loss = 0.476558\n",
      "Iteration  8300, loss = 0.476557\n",
      "Iteration  8400, loss = 0.476556\n",
      "Iteration  8500, loss = 0.476555\n",
      "Iteration  8600, loss = 0.476553\n",
      "Iteration  8700, loss = 0.476552\n",
      "Iteration  8800, loss = 0.476551\n",
      "Iteration  8900, loss = 0.476550\n",
      "Iteration  9000, loss = 0.476549\n",
      "Iteration  9100, loss = 0.476547\n",
      "Iteration  9200, loss = 0.476546\n",
      "Iteration  9300, loss = 0.476545\n",
      "Iteration  9400, loss = 0.476544\n",
      "Iteration  9500, loss = 0.476543\n",
      "Iteration  9600, loss = 0.476542\n",
      "Iteration  9700, loss = 0.476541\n",
      "Iteration  9800, loss = 0.476540\n",
      "Iteration  9900, loss = 0.476538\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4085\n",
      "\n",
      "Validation loss: 0.4881518971410055 f1 score 0.408466533466533 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478435\n",
      "Iteration   200, loss = 0.477515\n",
      "Iteration   300, loss = 0.477240\n",
      "Iteration   400, loss = 0.477101\n",
      "Iteration   500, loss = 0.477018\n",
      "Iteration   600, loss = 0.476962\n",
      "Iteration   700, loss = 0.476922\n",
      "Iteration   800, loss = 0.476891\n",
      "Iteration   900, loss = 0.476867\n",
      "Iteration  1000, loss = 0.476846\n",
      "Iteration  1100, loss = 0.476828\n",
      "Iteration  1200, loss = 0.476813\n",
      "Iteration  1300, loss = 0.476799\n",
      "Iteration  1400, loss = 0.476787\n",
      "Iteration  1500, loss = 0.476776\n",
      "Iteration  1600, loss = 0.476766\n",
      "Iteration  1700, loss = 0.476756\n",
      "Iteration  1800, loss = 0.476747\n",
      "Iteration  1900, loss = 0.476739\n",
      "Iteration  2000, loss = 0.476732\n",
      "Iteration  2100, loss = 0.476724\n",
      "Iteration  2200, loss = 0.476718\n",
      "Iteration  2300, loss = 0.476711\n",
      "Iteration  2400, loss = 0.476705\n",
      "Iteration  2500, loss = 0.476699\n",
      "Iteration  2600, loss = 0.476694\n",
      "Iteration  2700, loss = 0.476689\n",
      "Iteration  2800, loss = 0.476684\n",
      "Iteration  2900, loss = 0.476679\n",
      "Iteration  3000, loss = 0.476675\n",
      "Iteration  3100, loss = 0.476670\n",
      "Iteration  3200, loss = 0.476666\n",
      "Iteration  3300, loss = 0.476662\n",
      "Iteration  3400, loss = 0.476658\n",
      "Iteration  3500, loss = 0.476655\n",
      "Iteration  3600, loss = 0.476651\n",
      "Iteration  3700, loss = 0.476648\n",
      "Iteration  3800, loss = 0.476644\n",
      "Iteration  3900, loss = 0.476641\n",
      "Iteration  4000, loss = 0.476638\n",
      "Iteration  4100, loss = 0.476635\n",
      "Iteration  4200, loss = 0.476632\n",
      "Iteration  4300, loss = 0.476629\n",
      "Iteration  4400, loss = 0.476627\n",
      "Iteration  4500, loss = 0.476624\n",
      "Iteration  4600, loss = 0.476621\n",
      "Iteration  4700, loss = 0.476619\n",
      "Iteration  4800, loss = 0.476617\n",
      "Iteration  4900, loss = 0.476614\n",
      "Iteration  5000, loss = 0.476612\n",
      "Iteration  5100, loss = 0.476610\n",
      "Iteration  5200, loss = 0.476607\n",
      "Iteration  5300, loss = 0.476605\n",
      "Iteration  5400, loss = 0.476603\n",
      "Iteration  5500, loss = 0.476601\n",
      "Iteration  5600, loss = 0.476599\n",
      "Iteration  5700, loss = 0.476597\n",
      "Iteration  5800, loss = 0.476595\n",
      "Iteration  5900, loss = 0.476593\n",
      "Iteration  6000, loss = 0.476592\n",
      "Iteration  6100, loss = 0.476590\n",
      "Iteration  6200, loss = 0.476588\n",
      "Iteration  6300, loss = 0.476586\n",
      "Iteration  6400, loss = 0.476585\n",
      "Iteration  6500, loss = 0.476583\n",
      "Iteration  6600, loss = 0.476581\n",
      "Iteration  6700, loss = 0.476580\n",
      "Iteration  6800, loss = 0.476578\n",
      "Iteration  6900, loss = 0.476577\n",
      "Iteration  7000, loss = 0.476575\n",
      "Iteration  7100, loss = 0.476574\n",
      "Iteration  7200, loss = 0.476572\n",
      "Iteration  7300, loss = 0.476571\n",
      "Iteration  7400, loss = 0.476569\n",
      "Iteration  7500, loss = 0.476568\n",
      "Iteration  7600, loss = 0.476566\n",
      "Iteration  7700, loss = 0.476565\n",
      "Iteration  7800, loss = 0.476564\n",
      "Iteration  7900, loss = 0.476562\n",
      "Iteration  8000, loss = 0.476561\n",
      "Iteration  8100, loss = 0.476560\n",
      "Iteration  8200, loss = 0.476558\n",
      "Iteration  8300, loss = 0.476557\n",
      "Iteration  8400, loss = 0.476556\n",
      "Iteration  8500, loss = 0.476555\n",
      "Iteration  8600, loss = 0.476553\n",
      "Iteration  8700, loss = 0.476552\n",
      "Iteration  8800, loss = 0.476551\n",
      "Iteration  8900, loss = 0.476550\n",
      "Iteration  9000, loss = 0.476549\n",
      "Iteration  9100, loss = 0.476547\n",
      "Iteration  9200, loss = 0.476546\n",
      "Iteration  9300, loss = 0.476545\n",
      "Iteration  9400, loss = 0.476544\n",
      "Iteration  9500, loss = 0.476543\n",
      "Iteration  9600, loss = 0.476542\n",
      "Iteration  9700, loss = 0.476541\n",
      "Iteration  9800, loss = 0.476540\n",
      "Iteration  9900, loss = 0.476538\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4085\n",
      "\n",
      "Validation loss: 0.4881518971410055 f1 score 0.408466533466533 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478435\n",
      "Iteration   200, loss = 0.477515\n",
      "Iteration   300, loss = 0.477240\n",
      "Iteration   400, loss = 0.477101\n",
      "Iteration   500, loss = 0.477018\n",
      "Iteration   600, loss = 0.476962\n",
      "Iteration   700, loss = 0.476922\n",
      "Iteration   800, loss = 0.476891\n",
      "Iteration   900, loss = 0.476867\n",
      "Iteration  1000, loss = 0.476846\n",
      "Iteration  1100, loss = 0.476828\n",
      "Iteration  1200, loss = 0.476813\n",
      "Iteration  1300, loss = 0.476799\n",
      "Iteration  1400, loss = 0.476787\n",
      "Iteration  1500, loss = 0.476776\n",
      "Iteration  1600, loss = 0.476766\n",
      "Iteration  1700, loss = 0.476756\n",
      "Iteration  1800, loss = 0.476747\n",
      "Iteration  1900, loss = 0.476739\n",
      "Iteration  2000, loss = 0.476732\n",
      "Iteration  2100, loss = 0.476724\n",
      "Iteration  2200, loss = 0.476718\n",
      "Iteration  2300, loss = 0.476711\n",
      "Iteration  2400, loss = 0.476705\n",
      "Iteration  2500, loss = 0.476699\n",
      "Iteration  2600, loss = 0.476694\n",
      "Iteration  2700, loss = 0.476689\n",
      "Iteration  2800, loss = 0.476684\n",
      "Iteration  2900, loss = 0.476679\n",
      "Iteration  3000, loss = 0.476675\n",
      "Iteration  3100, loss = 0.476670\n",
      "Iteration  3200, loss = 0.476666\n",
      "Iteration  3300, loss = 0.476662\n",
      "Iteration  3400, loss = 0.476658\n",
      "Iteration  3500, loss = 0.476655\n",
      "Iteration  3600, loss = 0.476651\n",
      "Iteration  3700, loss = 0.476648\n",
      "Iteration  3800, loss = 0.476644\n",
      "Iteration  3900, loss = 0.476641\n",
      "Iteration  4000, loss = 0.476638\n",
      "Iteration  4100, loss = 0.476635\n",
      "Iteration  4200, loss = 0.476632\n",
      "Iteration  4300, loss = 0.476629\n",
      "Iteration  4400, loss = 0.476627\n",
      "Iteration  4500, loss = 0.476624\n",
      "Iteration  4600, loss = 0.476621\n",
      "Iteration  4700, loss = 0.476619\n",
      "Iteration  4800, loss = 0.476617\n",
      "Iteration  4900, loss = 0.476614\n",
      "Iteration  5000, loss = 0.476612\n",
      "Iteration  5100, loss = 0.476610\n",
      "Iteration  5200, loss = 0.476607\n",
      "Iteration  5300, loss = 0.476605\n",
      "Iteration  5400, loss = 0.476603\n",
      "Iteration  5500, loss = 0.476601\n",
      "Iteration  5600, loss = 0.476599\n",
      "Iteration  5700, loss = 0.476597\n",
      "Iteration  5800, loss = 0.476595\n",
      "Iteration  5900, loss = 0.476593\n",
      "Iteration  6000, loss = 0.476592\n",
      "Iteration  6100, loss = 0.476590\n",
      "Iteration  6200, loss = 0.476588\n",
      "Iteration  6300, loss = 0.476586\n",
      "Iteration  6400, loss = 0.476585\n",
      "Iteration  6500, loss = 0.476583\n",
      "Iteration  6600, loss = 0.476581\n",
      "Iteration  6700, loss = 0.476580\n",
      "Iteration  6800, loss = 0.476578\n",
      "Iteration  6900, loss = 0.476577\n",
      "Iteration  7000, loss = 0.476575\n",
      "Iteration  7100, loss = 0.476574\n",
      "Iteration  7200, loss = 0.476572\n",
      "Iteration  7300, loss = 0.476571\n",
      "Iteration  7400, loss = 0.476569\n",
      "Iteration  7500, loss = 0.476568\n",
      "Iteration  7600, loss = 0.476566\n",
      "Iteration  7700, loss = 0.476565\n",
      "Iteration  7800, loss = 0.476564\n",
      "Iteration  7900, loss = 0.476562\n",
      "Iteration  8000, loss = 0.476561\n",
      "Iteration  8100, loss = 0.476560\n",
      "Iteration  8200, loss = 0.476558\n",
      "Iteration  8300, loss = 0.476557\n",
      "Iteration  8400, loss = 0.476556\n",
      "Iteration  8500, loss = 0.476555\n",
      "Iteration  8600, loss = 0.476553\n",
      "Iteration  8700, loss = 0.476552\n",
      "Iteration  8800, loss = 0.476551\n",
      "Iteration  8900, loss = 0.476550\n",
      "Iteration  9000, loss = 0.476549\n",
      "Iteration  9100, loss = 0.476547\n",
      "Iteration  9200, loss = 0.476546\n",
      "Iteration  9300, loss = 0.476545\n",
      "Iteration  9400, loss = 0.476544\n",
      "Iteration  9500, loss = 0.476543\n",
      "Iteration  9600, loss = 0.476542\n",
      "Iteration  9700, loss = 0.476541\n",
      "Iteration  9800, loss = 0.476540\n",
      "Iteration  9900, loss = 0.476538\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4085\n",
      "\n",
      "Validation loss: 0.4881518971410055 f1 score 0.408466533466533 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478435\n",
      "Iteration   200, loss = 0.477515\n",
      "Iteration   300, loss = 0.477240\n",
      "Iteration   400, loss = 0.477101\n",
      "Iteration   500, loss = 0.477018\n",
      "Iteration   600, loss = 0.476962\n",
      "Iteration   700, loss = 0.476922\n",
      "Iteration   800, loss = 0.476891\n",
      "Iteration   900, loss = 0.476867\n",
      "Iteration  1000, loss = 0.476846\n",
      "Iteration  1100, loss = 0.476828\n",
      "Iteration  1200, loss = 0.476813\n",
      "Iteration  1300, loss = 0.476799\n",
      "Iteration  1400, loss = 0.476787\n",
      "Iteration  1500, loss = 0.476776\n",
      "Iteration  1600, loss = 0.476766\n",
      "Iteration  1700, loss = 0.476756\n",
      "Iteration  1800, loss = 0.476747\n",
      "Iteration  1900, loss = 0.476739\n",
      "Iteration  2000, loss = 0.476732\n",
      "Iteration  2100, loss = 0.476724\n",
      "Iteration  2200, loss = 0.476718\n",
      "Iteration  2300, loss = 0.476711\n",
      "Iteration  2400, loss = 0.476705\n",
      "Iteration  2500, loss = 0.476699\n",
      "Iteration  2600, loss = 0.476694\n",
      "Iteration  2700, loss = 0.476689\n",
      "Iteration  2800, loss = 0.476684\n",
      "Iteration  2900, loss = 0.476679\n",
      "Iteration  3000, loss = 0.476675\n",
      "Iteration  3100, loss = 0.476670\n",
      "Iteration  3200, loss = 0.476666\n",
      "Iteration  3300, loss = 0.476662\n",
      "Iteration  3400, loss = 0.476658\n",
      "Iteration  3500, loss = 0.476655\n",
      "Iteration  3600, loss = 0.476651\n",
      "Iteration  3700, loss = 0.476648\n",
      "Iteration  3800, loss = 0.476644\n",
      "Iteration  3900, loss = 0.476641\n",
      "Iteration  4000, loss = 0.476638\n",
      "Iteration  4100, loss = 0.476635\n",
      "Iteration  4200, loss = 0.476632\n",
      "Iteration  4300, loss = 0.476629\n",
      "Iteration  4400, loss = 0.476627\n",
      "Iteration  4500, loss = 0.476624\n",
      "Iteration  4600, loss = 0.476621\n",
      "Iteration  4700, loss = 0.476619\n",
      "Iteration  4800, loss = 0.476617\n",
      "Iteration  4900, loss = 0.476614\n",
      "Iteration  5000, loss = 0.476612\n",
      "Iteration  5100, loss = 0.476610\n",
      "Iteration  5200, loss = 0.476607\n",
      "Iteration  5300, loss = 0.476605\n",
      "Iteration  5400, loss = 0.476603\n",
      "Iteration  5500, loss = 0.476601\n",
      "Iteration  5600, loss = 0.476599\n",
      "Iteration  5700, loss = 0.476597\n",
      "Iteration  5800, loss = 0.476595\n",
      "Iteration  5900, loss = 0.476593\n",
      "Iteration  6000, loss = 0.476592\n",
      "Iteration  6100, loss = 0.476590\n",
      "Iteration  6200, loss = 0.476588\n",
      "Iteration  6300, loss = 0.476586\n",
      "Iteration  6400, loss = 0.476585\n",
      "Iteration  6500, loss = 0.476583\n",
      "Iteration  6600, loss = 0.476581\n",
      "Iteration  6700, loss = 0.476580\n",
      "Iteration  6800, loss = 0.476578\n",
      "Iteration  6900, loss = 0.476577\n",
      "Iteration  7000, loss = 0.476575\n",
      "Iteration  7100, loss = 0.476574\n",
      "Iteration  7200, loss = 0.476572\n",
      "Iteration  7300, loss = 0.476571\n",
      "Iteration  7400, loss = 0.476569\n",
      "Iteration  7500, loss = 0.476568\n",
      "Iteration  7600, loss = 0.476566\n",
      "Iteration  7700, loss = 0.476565\n",
      "Iteration  7800, loss = 0.476564\n",
      "Iteration  7900, loss = 0.476562\n",
      "Iteration  8000, loss = 0.476561\n",
      "Iteration  8100, loss = 0.476560\n",
      "Iteration  8200, loss = 0.476558\n",
      "Iteration  8300, loss = 0.476557\n",
      "Iteration  8400, loss = 0.476556\n",
      "Iteration  8500, loss = 0.476555\n",
      "Iteration  8600, loss = 0.476553\n",
      "Iteration  8700, loss = 0.476552\n",
      "Iteration  8800, loss = 0.476551\n",
      "Iteration  8900, loss = 0.476550\n",
      "Iteration  9000, loss = 0.476549\n",
      "Iteration  9100, loss = 0.476547\n",
      "Iteration  9200, loss = 0.476546\n",
      "Iteration  9300, loss = 0.476545\n",
      "Iteration  9400, loss = 0.476544\n",
      "Iteration  9500, loss = 0.476543\n",
      "Iteration  9600, loss = 0.476542\n",
      "Iteration  9700, loss = 0.476541\n",
      "Iteration  9800, loss = 0.476540\n",
      "Iteration  9900, loss = 0.476538\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4085\n",
      "\n",
      "Validation loss: 0.4881518971410055 f1 score 0.408466533466533 with data size of 46564\n",
      "For lambda: 0.0 best f1: 0.40887835899993713\n",
      "Before preprocess (262508, 321) (262508,)\n",
      "Number of removes features due to NaN values: 117\n",
      "After preprocess (46564, 204) (46564,)\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472791\n",
      "Iteration   200, loss = 0.471419\n",
      "Iteration   300, loss = 0.470935\n",
      "Iteration   400, loss = 0.470664\n",
      "Iteration   500, loss = 0.470487\n",
      "Iteration   600, loss = 0.470358\n",
      "Iteration   700, loss = 0.470258\n",
      "Iteration   800, loss = 0.470177\n",
      "Iteration   900, loss = 0.470108\n",
      "Iteration  1000, loss = 0.470049\n",
      "Iteration  1100, loss = 0.469996\n",
      "Iteration  1200, loss = 0.469949\n",
      "Iteration  1300, loss = 0.469907\n",
      "Iteration  1400, loss = 0.469868\n",
      "Iteration  1500, loss = 0.469832\n",
      "Iteration  1600, loss = 0.469799\n",
      "Iteration  1700, loss = 0.469769\n",
      "Iteration  1800, loss = 0.469740\n",
      "Iteration  1900, loss = 0.469714\n",
      "Iteration  2000, loss = 0.469689\n",
      "Iteration  2100, loss = 0.469666\n",
      "Iteration  2200, loss = 0.469643\n",
      "Iteration  2300, loss = 0.469623\n",
      "Iteration  2400, loss = 0.469603\n",
      "Iteration  2500, loss = 0.469584\n",
      "Iteration  2600, loss = 0.469567\n",
      "Iteration  2700, loss = 0.469550\n",
      "Iteration  2800, loss = 0.469534\n",
      "Iteration  2900, loss = 0.469519\n",
      "Iteration  3000, loss = 0.469504\n",
      "Iteration  3100, loss = 0.469491\n",
      "Iteration  3200, loss = 0.469477\n",
      "Iteration  3300, loss = 0.469465\n",
      "Iteration  3400, loss = 0.469453\n",
      "Iteration  3500, loss = 0.469441\n",
      "Iteration  3600, loss = 0.469430\n",
      "Iteration  3700, loss = 0.469420\n",
      "Iteration  3800, loss = 0.469410\n",
      "Iteration  3900, loss = 0.469400\n",
      "Iteration  4000, loss = 0.469390\n",
      "Iteration  4100, loss = 0.469381\n",
      "Iteration  4200, loss = 0.469373\n",
      "Iteration  4300, loss = 0.469364\n",
      "Iteration  4400, loss = 0.469356\n",
      "Iteration  4500, loss = 0.469349\n",
      "Iteration  4600, loss = 0.469341\n",
      "Iteration  4700, loss = 0.469334\n",
      "Iteration  4800, loss = 0.469327\n",
      "Iteration  4900, loss = 0.469320\n",
      "Iteration  5000, loss = 0.469314\n",
      "Iteration  5100, loss = 0.469307\n",
      "Iteration  5200, loss = 0.469301\n",
      "Iteration  5300, loss = 0.469295\n",
      "Iteration  5400, loss = 0.469290\n",
      "Iteration  5500, loss = 0.469284\n",
      "Iteration  5600, loss = 0.469279\n",
      "Iteration  5700, loss = 0.469274\n",
      "Iteration  5800, loss = 0.469269\n",
      "Iteration  5900, loss = 0.469264\n",
      "Iteration  6000, loss = 0.469259\n",
      "Iteration  6100, loss = 0.469254\n",
      "Iteration  6200, loss = 0.469250\n",
      "Iteration  6300, loss = 0.469246\n",
      "Iteration  6400, loss = 0.469241\n",
      "Iteration  6500, loss = 0.469237\n",
      "Iteration  6600, loss = 0.469233\n",
      "Iteration  6700, loss = 0.469229\n",
      "Iteration  6800, loss = 0.469225\n",
      "Iteration  6900, loss = 0.469222\n",
      "Iteration  7000, loss = 0.469218\n",
      "Iteration  7100, loss = 0.469215\n",
      "Iteration  7200, loss = 0.469211\n",
      "Iteration  7300, loss = 0.469208\n",
      "Iteration  7400, loss = 0.469204\n",
      "Iteration  7500, loss = 0.469201\n",
      "Iteration  7600, loss = 0.469198\n",
      "Iteration  7700, loss = 0.469195\n",
      "Iteration  7800, loss = 0.469192\n",
      "Iteration  7900, loss = 0.469189\n",
      "Iteration  8000, loss = 0.469186\n",
      "Iteration  8100, loss = 0.469183\n",
      "Iteration  8200, loss = 0.469180\n",
      "Iteration  8300, loss = 0.469178\n",
      "Iteration  8400, loss = 0.469175\n",
      "Iteration  8500, loss = 0.469172\n",
      "Iteration  8600, loss = 0.469170\n",
      "Iteration  8700, loss = 0.469167\n",
      "Iteration  8800, loss = 0.469165\n",
      "Iteration  8900, loss = 0.469162\n",
      "Iteration  9000, loss = 0.469160\n",
      "Iteration  9100, loss = 0.469157\n",
      "Iteration  9200, loss = 0.469155\n",
      "Iteration  9300, loss = 0.469153\n",
      "Iteration  9400, loss = 0.469150\n",
      "Iteration  9500, loss = 0.469148\n",
      "Iteration  9600, loss = 0.469146\n",
      "Iteration  9700, loss = 0.469144\n",
      "Iteration  9800, loss = 0.469142\n",
      "Iteration  9900, loss = 0.469140\n",
      " Accuracy: 84.90%\n",
      " F1 Score: 0.4024\n",
      "\n",
      "Validation loss: 0.5013040401356746 f1 score 0.40236400916656573 with data size of 13125\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472120\n",
      "Iteration   200, loss = 0.470797\n",
      "Iteration   300, loss = 0.470330\n",
      "Iteration   400, loss = 0.470072\n",
      "Iteration   500, loss = 0.469905\n",
      "Iteration   600, loss = 0.469786\n",
      "Iteration   700, loss = 0.469693\n",
      "Iteration   800, loss = 0.469619\n",
      "Iteration   900, loss = 0.469555\n",
      "Iteration  1000, loss = 0.469501\n",
      "Iteration  1100, loss = 0.469452\n",
      "Iteration  1200, loss = 0.469409\n",
      "Iteration  1300, loss = 0.469370\n",
      "Iteration  1400, loss = 0.469334\n",
      "Iteration  1500, loss = 0.469300\n",
      "Iteration  1600, loss = 0.469270\n",
      "Iteration  1700, loss = 0.469241\n",
      "Iteration  1800, loss = 0.469215\n",
      "Iteration  1900, loss = 0.469190\n",
      "Iteration  2000, loss = 0.469167\n",
      "Iteration  2100, loss = 0.469145\n",
      "Iteration  2200, loss = 0.469124\n",
      "Iteration  2300, loss = 0.469105\n",
      "Iteration  2400, loss = 0.469086\n",
      "Iteration  2500, loss = 0.469068\n",
      "Iteration  2600, loss = 0.469052\n",
      "Iteration  2700, loss = 0.469036\n",
      "Iteration  2800, loss = 0.469021\n",
      "Iteration  2900, loss = 0.469007\n",
      "Iteration  3000, loss = 0.468993\n",
      "Iteration  3100, loss = 0.468980\n",
      "Iteration  3200, loss = 0.468967\n",
      "Iteration  3300, loss = 0.468956\n",
      "Iteration  3400, loss = 0.468944\n",
      "Iteration  3500, loss = 0.468933\n",
      "Iteration  3600, loss = 0.468923\n",
      "Iteration  3700, loss = 0.468913\n",
      "Iteration  3800, loss = 0.468903\n",
      "Iteration  3900, loss = 0.468894\n",
      "Iteration  4000, loss = 0.468885\n",
      "Iteration  4100, loss = 0.468876\n",
      "Iteration  4200, loss = 0.468868\n",
      "Iteration  4300, loss = 0.468860\n",
      "Iteration  4400, loss = 0.468852\n",
      "Iteration  4500, loss = 0.468845\n",
      "Iteration  4600, loss = 0.468838\n",
      "Iteration  4700, loss = 0.468831\n",
      "Iteration  4800, loss = 0.468824\n",
      "Iteration  4900, loss = 0.468818\n",
      "Iteration  5000, loss = 0.468812\n",
      "Iteration  5100, loss = 0.468806\n",
      "Iteration  5200, loss = 0.468800\n",
      "Iteration  5300, loss = 0.468794\n",
      "Iteration  5400, loss = 0.468789\n",
      "Iteration  5500, loss = 0.468784\n",
      "Iteration  5600, loss = 0.468779\n",
      "Iteration  5700, loss = 0.468774\n",
      "Iteration  5800, loss = 0.468769\n",
      "Iteration  5900, loss = 0.468764\n",
      "Iteration  6000, loss = 0.468760\n",
      "Iteration  6100, loss = 0.468755\n",
      "Iteration  6200, loss = 0.468751\n",
      "Iteration  6300, loss = 0.468747\n",
      "Iteration  6400, loss = 0.468743\n",
      "Iteration  6500, loss = 0.468739\n",
      "Iteration  6600, loss = 0.468735\n",
      "Iteration  6700, loss = 0.468731\n",
      "Iteration  6800, loss = 0.468728\n",
      "Iteration  6900, loss = 0.468724\n",
      "Iteration  7000, loss = 0.468720\n",
      "Iteration  7100, loss = 0.468717\n",
      "Iteration  7200, loss = 0.468714\n",
      "Iteration  7300, loss = 0.468711\n",
      "Iteration  7400, loss = 0.468707\n",
      "Iteration  7500, loss = 0.468704\n",
      "Iteration  7600, loss = 0.468701\n",
      "Iteration  7700, loss = 0.468698\n",
      "Iteration  7800, loss = 0.468695\n",
      "Iteration  7900, loss = 0.468693\n",
      "Iteration  8000, loss = 0.468690\n",
      "Iteration  8100, loss = 0.468687\n",
      "Iteration  8200, loss = 0.468684\n",
      "Iteration  8300, loss = 0.468682\n",
      "Iteration  8400, loss = 0.468679\n",
      "Iteration  8500, loss = 0.468677\n",
      "Iteration  8600, loss = 0.468674\n",
      "Iteration  8700, loss = 0.468672\n",
      "Iteration  8800, loss = 0.468669\n",
      "Iteration  8900, loss = 0.468667\n",
      "Iteration  9000, loss = 0.468665\n",
      "Iteration  9100, loss = 0.468662\n",
      "Iteration  9200, loss = 0.468660\n",
      "Iteration  9300, loss = 0.468658\n",
      "Iteration  9400, loss = 0.468656\n",
      "Iteration  9500, loss = 0.468654\n",
      "Iteration  9600, loss = 0.468652\n",
      "Iteration  9700, loss = 0.468649\n",
      "Iteration  9800, loss = 0.468647\n",
      "Iteration  9900, loss = 0.468645\n",
      " Accuracy: 84.91%\n",
      " F1 Score: 0.4018\n",
      "\n",
      "Validation loss: 0.4991454862914758 f1 score 0.40183585965336027 with data size of 13816\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472757\n",
      "Iteration   200, loss = 0.471437\n",
      "Iteration   300, loss = 0.470972\n",
      "Iteration   400, loss = 0.470717\n",
      "Iteration   500, loss = 0.470555\n",
      "Iteration   600, loss = 0.470440\n",
      "Iteration   700, loss = 0.470351\n",
      "Iteration   800, loss = 0.470280\n",
      "Iteration   900, loss = 0.470220\n",
      "Iteration  1000, loss = 0.470168\n",
      "Iteration  1100, loss = 0.470122\n",
      "Iteration  1200, loss = 0.470081\n",
      "Iteration  1300, loss = 0.470043\n",
      "Iteration  1400, loss = 0.470009\n",
      "Iteration  1500, loss = 0.469977\n",
      "Iteration  1600, loss = 0.469948\n",
      "Iteration  1700, loss = 0.469921\n",
      "Iteration  1800, loss = 0.469895\n",
      "Iteration  1900, loss = 0.469871\n",
      "Iteration  2000, loss = 0.469849\n",
      "Iteration  2100, loss = 0.469827\n",
      "Iteration  2200, loss = 0.469807\n",
      "Iteration  2300, loss = 0.469789\n",
      "Iteration  2400, loss = 0.469771\n",
      "Iteration  2500, loss = 0.469754\n",
      "Iteration  2600, loss = 0.469738\n",
      "Iteration  2700, loss = 0.469722\n",
      "Iteration  2800, loss = 0.469708\n",
      "Iteration  2900, loss = 0.469694\n",
      "Iteration  3000, loss = 0.469680\n",
      "Iteration  3100, loss = 0.469668\n",
      "Iteration  3200, loss = 0.469655\n",
      "Iteration  3300, loss = 0.469644\n",
      "Iteration  3400, loss = 0.469633\n",
      "Iteration  3500, loss = 0.469622\n",
      "Iteration  3600, loss = 0.469612\n",
      "Iteration  3700, loss = 0.469602\n",
      "Iteration  3800, loss = 0.469592\n",
      "Iteration  3900, loss = 0.469583\n",
      "Iteration  4000, loss = 0.469574\n",
      "Iteration  4100, loss = 0.469566\n",
      "Iteration  4200, loss = 0.469558\n",
      "Iteration  4300, loss = 0.469550\n",
      "Iteration  4400, loss = 0.469543\n",
      "Iteration  4500, loss = 0.469535\n",
      "Iteration  4600, loss = 0.469528\n",
      "Iteration  4700, loss = 0.469521\n",
      "Iteration  4800, loss = 0.469515\n",
      "Iteration  4900, loss = 0.469509\n",
      "Iteration  5000, loss = 0.469502\n",
      "Iteration  5100, loss = 0.469497\n",
      "Iteration  5200, loss = 0.469491\n",
      "Iteration  5300, loss = 0.469485\n",
      "Iteration  5400, loss = 0.469480\n",
      "Iteration  5500, loss = 0.469475\n",
      "Iteration  5600, loss = 0.469470\n",
      "Iteration  5700, loss = 0.469465\n",
      "Iteration  5800, loss = 0.469460\n",
      "Iteration  5900, loss = 0.469455\n",
      "Iteration  6000, loss = 0.469451\n",
      "Iteration  6100, loss = 0.469446\n",
      "Iteration  6200, loss = 0.469442\n",
      "Iteration  6300, loss = 0.469438\n",
      "Iteration  6400, loss = 0.469434\n",
      "Iteration  6500, loss = 0.469430\n",
      "Iteration  6600, loss = 0.469426\n",
      "Iteration  6700, loss = 0.469422\n",
      "Iteration  6800, loss = 0.469419\n",
      "Iteration  6900, loss = 0.469415\n",
      "Iteration  7000, loss = 0.469412\n",
      "Iteration  7100, loss = 0.469408\n",
      "Iteration  7200, loss = 0.469405\n",
      "Iteration  7300, loss = 0.469402\n",
      "Iteration  7400, loss = 0.469399\n",
      "Iteration  7500, loss = 0.469395\n",
      "Iteration  7600, loss = 0.469392\n",
      "Iteration  7700, loss = 0.469389\n",
      "Iteration  7800, loss = 0.469387\n",
      "Iteration  7900, loss = 0.469384\n",
      "Iteration  8000, loss = 0.469381\n",
      "Iteration  8100, loss = 0.469378\n",
      "Iteration  8200, loss = 0.469376\n",
      "Iteration  8300, loss = 0.469373\n",
      "Iteration  8400, loss = 0.469370\n",
      "Iteration  8500, loss = 0.469368\n",
      "Iteration  8600, loss = 0.469365\n",
      "Iteration  8700, loss = 0.469363\n",
      "Iteration  8800, loss = 0.469360\n",
      "Iteration  8900, loss = 0.469358\n",
      "Iteration  9000, loss = 0.469356\n",
      "Iteration  9100, loss = 0.469353\n",
      "Iteration  9200, loss = 0.469351\n",
      "Iteration  9300, loss = 0.469349\n",
      "Iteration  9400, loss = 0.469347\n",
      "Iteration  9500, loss = 0.469345\n",
      "Iteration  9600, loss = 0.469343\n",
      "Iteration  9700, loss = 0.469340\n",
      "Iteration  9800, loss = 0.469338\n",
      "Iteration  9900, loss = 0.469336\n",
      " Accuracy: 84.98%\n",
      " F1 Score: 0.4030\n",
      "\n",
      "Validation loss: 0.49829904980747075 f1 score 0.40300496789046364 with data size of 14583\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472957\n",
      "Iteration   200, loss = 0.471698\n",
      "Iteration   300, loss = 0.471260\n",
      "Iteration   400, loss = 0.471017\n",
      "Iteration   500, loss = 0.470859\n",
      "Iteration   600, loss = 0.470744\n",
      "Iteration   700, loss = 0.470654\n",
      "Iteration   800, loss = 0.470580\n",
      "Iteration   900, loss = 0.470516\n",
      "Iteration  1000, loss = 0.470461\n",
      "Iteration  1100, loss = 0.470412\n",
      "Iteration  1200, loss = 0.470367\n",
      "Iteration  1300, loss = 0.470327\n",
      "Iteration  1400, loss = 0.470290\n",
      "Iteration  1500, loss = 0.470255\n",
      "Iteration  1600, loss = 0.470223\n",
      "Iteration  1700, loss = 0.470194\n",
      "Iteration  1800, loss = 0.470166\n",
      "Iteration  1900, loss = 0.470140\n",
      "Iteration  2000, loss = 0.470116\n",
      "Iteration  2100, loss = 0.470093\n",
      "Iteration  2200, loss = 0.470071\n",
      "Iteration  2300, loss = 0.470051\n",
      "Iteration  2400, loss = 0.470031\n",
      "Iteration  2500, loss = 0.470013\n",
      "Iteration  2600, loss = 0.469996\n",
      "Iteration  2700, loss = 0.469979\n",
      "Iteration  2800, loss = 0.469963\n",
      "Iteration  2900, loss = 0.469949\n",
      "Iteration  3000, loss = 0.469934\n",
      "Iteration  3100, loss = 0.469921\n",
      "Iteration  3200, loss = 0.469908\n",
      "Iteration  3300, loss = 0.469895\n",
      "Iteration  3400, loss = 0.469884\n",
      "Iteration  3500, loss = 0.469872\n",
      "Iteration  3600, loss = 0.469861\n",
      "Iteration  3700, loss = 0.469851\n",
      "Iteration  3800, loss = 0.469841\n",
      "Iteration  3900, loss = 0.469832\n",
      "Iteration  4000, loss = 0.469822\n",
      "Iteration  4100, loss = 0.469814\n",
      "Iteration  4200, loss = 0.469805\n",
      "Iteration  4300, loss = 0.469797\n",
      "Iteration  4400, loss = 0.469789\n",
      "Iteration  4500, loss = 0.469781\n",
      "Iteration  4600, loss = 0.469774\n",
      "Iteration  4700, loss = 0.469767\n",
      "Iteration  4800, loss = 0.469760\n",
      "Iteration  4900, loss = 0.469754\n",
      "Iteration  5000, loss = 0.469747\n",
      "Iteration  5100, loss = 0.469741\n",
      "Iteration  5200, loss = 0.469735\n",
      "Iteration  5300, loss = 0.469730\n",
      "Iteration  5400, loss = 0.469724\n",
      "Iteration  5500, loss = 0.469719\n",
      "Iteration  5600, loss = 0.469713\n",
      "Iteration  5700, loss = 0.469708\n",
      "Iteration  5800, loss = 0.469704\n",
      "Iteration  5900, loss = 0.469699\n",
      "Iteration  6000, loss = 0.469694\n",
      "Iteration  6100, loss = 0.469690\n",
      "Iteration  6200, loss = 0.469685\n",
      "Iteration  6300, loss = 0.469681\n",
      "Iteration  6400, loss = 0.469677\n",
      "Iteration  6500, loss = 0.469673\n",
      "Iteration  6600, loss = 0.469669\n",
      "Iteration  6700, loss = 0.469665\n",
      "Iteration  6800, loss = 0.469661\n",
      "Iteration  6900, loss = 0.469658\n",
      "Iteration  7000, loss = 0.469654\n",
      "Iteration  7100, loss = 0.469651\n",
      "Iteration  7200, loss = 0.469647\n",
      "Iteration  7300, loss = 0.469644\n",
      "Iteration  7400, loss = 0.469641\n",
      "Iteration  7500, loss = 0.469638\n",
      "Iteration  7600, loss = 0.469635\n",
      "Iteration  7700, loss = 0.469632\n",
      "Iteration  7800, loss = 0.469629\n",
      "Iteration  7900, loss = 0.469626\n",
      "Iteration  8000, loss = 0.469623\n",
      "Iteration  8100, loss = 0.469620\n",
      "Iteration  8200, loss = 0.469618\n",
      "Iteration  8300, loss = 0.469615\n",
      "Iteration  8400, loss = 0.469612\n",
      "Iteration  8500, loss = 0.469610\n",
      "Iteration  8600, loss = 0.469607\n",
      "Iteration  8700, loss = 0.469605\n",
      "Iteration  8800, loss = 0.469602\n",
      "Iteration  8900, loss = 0.469600\n",
      "Iteration  9000, loss = 0.469597\n",
      "Iteration  9100, loss = 0.469595\n",
      "Iteration  9200, loss = 0.469593\n",
      "Iteration  9300, loss = 0.469591\n",
      "Iteration  9400, loss = 0.469588\n",
      "Iteration  9500, loss = 0.469586\n",
      "Iteration  9600, loss = 0.469584\n",
      "Iteration  9700, loss = 0.469582\n",
      "Iteration  9800, loss = 0.469580\n",
      "Iteration  9900, loss = 0.469578\n",
      " Accuracy: 84.96%\n",
      " F1 Score: 0.4019\n",
      "\n",
      "Validation loss: 0.4970741085677811 f1 score 0.4018906799175853 with data size of 15441\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473274\n",
      "Iteration   200, loss = 0.472071\n",
      "Iteration   300, loss = 0.471653\n",
      "Iteration   400, loss = 0.471422\n",
      "Iteration   500, loss = 0.471271\n",
      "Iteration   600, loss = 0.471163\n",
      "Iteration   700, loss = 0.471079\n",
      "Iteration   800, loss = 0.471010\n",
      "Iteration   900, loss = 0.470952\n",
      "Iteration  1000, loss = 0.470902\n",
      "Iteration  1100, loss = 0.470858\n",
      "Iteration  1200, loss = 0.470818\n",
      "Iteration  1300, loss = 0.470782\n",
      "Iteration  1400, loss = 0.470749\n",
      "Iteration  1500, loss = 0.470719\n",
      "Iteration  1600, loss = 0.470691\n",
      "Iteration  1700, loss = 0.470665\n",
      "Iteration  1800, loss = 0.470640\n",
      "Iteration  1900, loss = 0.470618\n",
      "Iteration  2000, loss = 0.470596\n",
      "Iteration  2100, loss = 0.470576\n",
      "Iteration  2200, loss = 0.470557\n",
      "Iteration  2300, loss = 0.470540\n",
      "Iteration  2400, loss = 0.470523\n",
      "Iteration  2500, loss = 0.470507\n",
      "Iteration  2600, loss = 0.470492\n",
      "Iteration  2700, loss = 0.470477\n",
      "Iteration  2800, loss = 0.470464\n",
      "Iteration  2900, loss = 0.470451\n",
      "Iteration  3000, loss = 0.470438\n",
      "Iteration  3100, loss = 0.470427\n",
      "Iteration  3200, loss = 0.470415\n",
      "Iteration  3300, loss = 0.470405\n",
      "Iteration  3400, loss = 0.470394\n",
      "Iteration  3500, loss = 0.470385\n",
      "Iteration  3600, loss = 0.470375\n",
      "Iteration  3700, loss = 0.470366\n",
      "Iteration  3800, loss = 0.470358\n",
      "Iteration  3900, loss = 0.470350\n",
      "Iteration  4000, loss = 0.470342\n",
      "Iteration  4100, loss = 0.470334\n",
      "Iteration  4200, loss = 0.470327\n",
      "Iteration  4300, loss = 0.470320\n",
      "Iteration  4400, loss = 0.470313\n",
      "Iteration  4500, loss = 0.470307\n",
      "Iteration  4600, loss = 0.470300\n",
      "Iteration  4700, loss = 0.470294\n",
      "Iteration  4800, loss = 0.470288\n",
      "Iteration  4900, loss = 0.470283\n",
      "Iteration  5000, loss = 0.470277\n",
      "Iteration  5100, loss = 0.470272\n",
      "Iteration  5200, loss = 0.470267\n",
      "Iteration  5300, loss = 0.470262\n",
      "Iteration  5400, loss = 0.470258\n",
      "Iteration  5500, loss = 0.470253\n",
      "Iteration  5600, loss = 0.470249\n",
      "Iteration  5700, loss = 0.470244\n",
      "Iteration  5800, loss = 0.470240\n",
      "Iteration  5900, loss = 0.470236\n",
      "Iteration  6000, loss = 0.470232\n",
      "Iteration  6100, loss = 0.470228\n",
      "Iteration  6200, loss = 0.470225\n",
      "Iteration  6300, loss = 0.470221\n",
      "Iteration  6400, loss = 0.470217\n",
      "Iteration  6500, loss = 0.470214\n",
      "Iteration  6600, loss = 0.470211\n",
      "Iteration  6700, loss = 0.470207\n",
      "Iteration  6800, loss = 0.470204\n",
      "Iteration  6900, loss = 0.470201\n",
      "Iteration  7000, loss = 0.470198\n",
      "Iteration  7100, loss = 0.470195\n",
      "Iteration  7200, loss = 0.470192\n",
      "Iteration  7300, loss = 0.470190\n",
      "Iteration  7400, loss = 0.470187\n",
      "Iteration  7500, loss = 0.470184\n",
      "Iteration  7600, loss = 0.470182\n",
      "Iteration  7700, loss = 0.470179\n",
      "Iteration  7800, loss = 0.470176\n",
      "Iteration  7900, loss = 0.470174\n",
      "Iteration  8000, loss = 0.470172\n",
      "Iteration  8100, loss = 0.470169\n",
      "Iteration  8200, loss = 0.470167\n",
      "Iteration  8300, loss = 0.470165\n",
      "Iteration  8400, loss = 0.470162\n",
      "Iteration  8500, loss = 0.470160\n",
      "Iteration  8600, loss = 0.470158\n",
      "Iteration  8700, loss = 0.470156\n",
      "Iteration  8800, loss = 0.470154\n",
      "Iteration  8900, loss = 0.470152\n",
      "Iteration  9000, loss = 0.470150\n",
      "Iteration  9100, loss = 0.470148\n",
      "Iteration  9200, loss = 0.470146\n",
      "Iteration  9300, loss = 0.470144\n",
      "Iteration  9400, loss = 0.470142\n",
      "Iteration  9500, loss = 0.470140\n",
      "Iteration  9600, loss = 0.470138\n",
      "Iteration  9700, loss = 0.470136\n",
      "Iteration  9800, loss = 0.470134\n",
      "Iteration  9900, loss = 0.470133\n",
      " Accuracy: 84.98%\n",
      " F1 Score: 0.4018\n",
      "\n",
      "Validation loss: 0.4963960622163562 f1 score 0.4017965525613008 with data size of 16406\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475945\n",
      "Iteration   200, loss = 0.474770\n",
      "Iteration   300, loss = 0.474344\n",
      "Iteration   400, loss = 0.474097\n",
      "Iteration   500, loss = 0.473932\n",
      "Iteration   600, loss = 0.473811\n",
      "Iteration   700, loss = 0.473718\n",
      "Iteration   800, loss = 0.473641\n",
      "Iteration   900, loss = 0.473577\n",
      "Iteration  1000, loss = 0.473522\n",
      "Iteration  1100, loss = 0.473474\n",
      "Iteration  1200, loss = 0.473431\n",
      "Iteration  1300, loss = 0.473393\n",
      "Iteration  1400, loss = 0.473357\n",
      "Iteration  1500, loss = 0.473325\n",
      "Iteration  1600, loss = 0.473296\n",
      "Iteration  1700, loss = 0.473268\n",
      "Iteration  1800, loss = 0.473243\n",
      "Iteration  1900, loss = 0.473219\n",
      "Iteration  2000, loss = 0.473196\n",
      "Iteration  2100, loss = 0.473175\n",
      "Iteration  2200, loss = 0.473156\n",
      "Iteration  2300, loss = 0.473137\n",
      "Iteration  2400, loss = 0.473119\n",
      "Iteration  2500, loss = 0.473103\n",
      "Iteration  2600, loss = 0.473087\n",
      "Iteration  2700, loss = 0.473072\n",
      "Iteration  2800, loss = 0.473058\n",
      "Iteration  2900, loss = 0.473044\n",
      "Iteration  3000, loss = 0.473032\n",
      "Iteration  3100, loss = 0.473019\n",
      "Iteration  3200, loss = 0.473008\n",
      "Iteration  3300, loss = 0.472997\n",
      "Iteration  3400, loss = 0.472986\n",
      "Iteration  3500, loss = 0.472976\n",
      "Iteration  3600, loss = 0.472966\n",
      "Iteration  3700, loss = 0.472957\n",
      "Iteration  3800, loss = 0.472948\n",
      "Iteration  3900, loss = 0.472939\n",
      "Iteration  4000, loss = 0.472931\n",
      "Iteration  4100, loss = 0.472923\n",
      "Iteration  4200, loss = 0.472916\n",
      "Iteration  4300, loss = 0.472908\n",
      "Iteration  4400, loss = 0.472902\n",
      "Iteration  4500, loss = 0.472895\n",
      "Iteration  4600, loss = 0.472888\n",
      "Iteration  4700, loss = 0.472882\n",
      "Iteration  4800, loss = 0.472876\n",
      "Iteration  4900, loss = 0.472870\n",
      "Iteration  5000, loss = 0.472865\n",
      "Iteration  5100, loss = 0.472859\n",
      "Iteration  5200, loss = 0.472854\n",
      "Iteration  5300, loss = 0.472849\n",
      "Iteration  5400, loss = 0.472844\n",
      "Iteration  5500, loss = 0.472840\n",
      "Iteration  5600, loss = 0.472835\n",
      "Iteration  5700, loss = 0.472831\n",
      "Iteration  5800, loss = 0.472826\n",
      "Iteration  5900, loss = 0.472822\n",
      "Iteration  6000, loss = 0.472818\n",
      "Iteration  6100, loss = 0.472814\n",
      "Iteration  6200, loss = 0.472811\n",
      "Iteration  6300, loss = 0.472807\n",
      "Iteration  6400, loss = 0.472803\n",
      "Iteration  6500, loss = 0.472800\n",
      "Iteration  6600, loss = 0.472796\n",
      "Iteration  6700, loss = 0.472793\n",
      "Iteration  6800, loss = 0.472790\n",
      "Iteration  6900, loss = 0.472787\n",
      "Iteration  7000, loss = 0.472784\n",
      "Iteration  7100, loss = 0.472781\n",
      "Iteration  7200, loss = 0.472778\n",
      "Iteration  7300, loss = 0.472775\n",
      "Iteration  7400, loss = 0.472772\n",
      "Iteration  7500, loss = 0.472769\n",
      "Iteration  7600, loss = 0.472767\n",
      "Iteration  7700, loss = 0.472764\n",
      "Iteration  7800, loss = 0.472761\n",
      "Iteration  7900, loss = 0.472759\n",
      "Iteration  8000, loss = 0.472756\n",
      "Iteration  8100, loss = 0.472754\n",
      "Iteration  8200, loss = 0.472752\n",
      "Iteration  8300, loss = 0.472749\n",
      "Iteration  8400, loss = 0.472747\n",
      "Iteration  8500, loss = 0.472745\n",
      "Iteration  8600, loss = 0.472742\n",
      "Iteration  8700, loss = 0.472740\n",
      "Iteration  8800, loss = 0.472738\n",
      "Iteration  8900, loss = 0.472736\n",
      "Iteration  9000, loss = 0.472734\n",
      "Iteration  9100, loss = 0.472732\n",
      "Iteration  9200, loss = 0.472730\n",
      "Iteration  9300, loss = 0.472728\n",
      "Iteration  9400, loss = 0.472726\n",
      "Iteration  9500, loss = 0.472724\n",
      "Iteration  9600, loss = 0.472722\n",
      "Iteration  9700, loss = 0.472720\n",
      "Iteration  9800, loss = 0.472718\n",
      "Iteration  9900, loss = 0.472717\n",
      " Accuracy: 85.15%\n",
      " F1 Score: 0.4031\n",
      "\n",
      "Validation loss: 0.49418407360084016 f1 score 0.4031349497918193 with data size of 17500\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475540\n",
      "Iteration   200, loss = 0.474402\n",
      "Iteration   300, loss = 0.474009\n",
      "Iteration   400, loss = 0.473787\n",
      "Iteration   500, loss = 0.473643\n",
      "Iteration   600, loss = 0.473539\n",
      "Iteration   700, loss = 0.473461\n",
      "Iteration   800, loss = 0.473398\n",
      "Iteration   900, loss = 0.473345\n",
      "Iteration  1000, loss = 0.473301\n",
      "Iteration  1100, loss = 0.473263\n",
      "Iteration  1200, loss = 0.473229\n",
      "Iteration  1300, loss = 0.473198\n",
      "Iteration  1400, loss = 0.473171\n",
      "Iteration  1500, loss = 0.473145\n",
      "Iteration  1600, loss = 0.473122\n",
      "Iteration  1700, loss = 0.473101\n",
      "Iteration  1800, loss = 0.473081\n",
      "Iteration  1900, loss = 0.473062\n",
      "Iteration  2000, loss = 0.473045\n",
      "Iteration  2100, loss = 0.473029\n",
      "Iteration  2200, loss = 0.473014\n",
      "Iteration  2300, loss = 0.472999\n",
      "Iteration  2400, loss = 0.472985\n",
      "Iteration  2500, loss = 0.472973\n",
      "Iteration  2600, loss = 0.472960\n",
      "Iteration  2700, loss = 0.472949\n",
      "Iteration  2800, loss = 0.472938\n",
      "Iteration  2900, loss = 0.472927\n",
      "Iteration  3000, loss = 0.472917\n",
      "Iteration  3100, loss = 0.472907\n",
      "Iteration  3200, loss = 0.472898\n",
      "Iteration  3300, loss = 0.472890\n",
      "Iteration  3400, loss = 0.472881\n",
      "Iteration  3500, loss = 0.472873\n",
      "Iteration  3600, loss = 0.472865\n",
      "Iteration  3700, loss = 0.472858\n",
      "Iteration  3800, loss = 0.472851\n",
      "Iteration  3900, loss = 0.472844\n",
      "Iteration  4000, loss = 0.472838\n",
      "Iteration  4100, loss = 0.472831\n",
      "Iteration  4200, loss = 0.472825\n",
      "Iteration  4300, loss = 0.472819\n",
      "Iteration  4400, loss = 0.472814\n",
      "Iteration  4500, loss = 0.472808\n",
      "Iteration  4600, loss = 0.472803\n",
      "Iteration  4700, loss = 0.472798\n",
      "Iteration  4800, loss = 0.472793\n",
      "Iteration  4900, loss = 0.472788\n",
      "Iteration  5000, loss = 0.472784\n",
      "Iteration  5100, loss = 0.472779\n",
      "Iteration  5200, loss = 0.472775\n",
      "Iteration  5300, loss = 0.472771\n",
      "Iteration  5400, loss = 0.472767\n",
      "Iteration  5500, loss = 0.472763\n",
      "Iteration  5600, loss = 0.472759\n",
      "Iteration  5700, loss = 0.472755\n",
      "Iteration  5800, loss = 0.472751\n",
      "Iteration  5900, loss = 0.472748\n",
      "Iteration  6000, loss = 0.472744\n",
      "Iteration  6100, loss = 0.472741\n",
      "Iteration  6200, loss = 0.472738\n",
      "Iteration  6300, loss = 0.472734\n",
      "Iteration  6400, loss = 0.472731\n",
      "Iteration  6500, loss = 0.472728\n",
      "Iteration  6600, loss = 0.472725\n",
      "Iteration  6700, loss = 0.472722\n",
      "Iteration  6800, loss = 0.472719\n",
      "Iteration  6900, loss = 0.472717\n",
      "Iteration  7000, loss = 0.472714\n",
      "Iteration  7100, loss = 0.472711\n",
      "Iteration  7200, loss = 0.472709\n",
      "Iteration  7300, loss = 0.472706\n",
      "Iteration  7400, loss = 0.472703\n",
      "Iteration  7500, loss = 0.472701\n",
      "Iteration  7600, loss = 0.472698\n",
      "Iteration  7700, loss = 0.472696\n",
      "Iteration  7800, loss = 0.472694\n",
      "Iteration  7900, loss = 0.472691\n",
      "Iteration  8000, loss = 0.472689\n",
      "Iteration  8100, loss = 0.472687\n",
      "Iteration  8200, loss = 0.472685\n",
      "Iteration  8300, loss = 0.472682\n",
      "Iteration  8400, loss = 0.472680\n",
      "Iteration  8500, loss = 0.472678\n",
      "Iteration  8600, loss = 0.472676\n",
      "Iteration  8700, loss = 0.472674\n",
      "Iteration  8800, loss = 0.472672\n",
      "Iteration  8900, loss = 0.472670\n",
      "Iteration  9000, loss = 0.472668\n",
      "Iteration  9100, loss = 0.472666\n",
      "Iteration  9200, loss = 0.472664\n",
      "Iteration  9300, loss = 0.472662\n",
      "Iteration  9400, loss = 0.472660\n",
      "Iteration  9500, loss = 0.472658\n",
      "Iteration  9600, loss = 0.472656\n",
      "Iteration  9700, loss = 0.472655\n",
      "Iteration  9800, loss = 0.472653\n",
      "Iteration  9900, loss = 0.472651\n",
      " Accuracy: 85.39%\n",
      " F1 Score: 0.4055\n",
      "\n",
      "Validation loss: 0.48996743386081004 f1 score 0.40545567265964 with data size of 18750\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475050\n",
      "Iteration   200, loss = 0.473899\n",
      "Iteration   300, loss = 0.473509\n",
      "Iteration   400, loss = 0.473295\n",
      "Iteration   500, loss = 0.473160\n",
      "Iteration   600, loss = 0.473065\n",
      "Iteration   700, loss = 0.472995\n",
      "Iteration   800, loss = 0.472940\n",
      "Iteration   900, loss = 0.472894\n",
      "Iteration  1000, loss = 0.472856\n",
      "Iteration  1100, loss = 0.472823\n",
      "Iteration  1200, loss = 0.472794\n",
      "Iteration  1300, loss = 0.472769\n",
      "Iteration  1400, loss = 0.472745\n",
      "Iteration  1500, loss = 0.472724\n",
      "Iteration  1600, loss = 0.472705\n",
      "Iteration  1700, loss = 0.472687\n",
      "Iteration  1800, loss = 0.472670\n",
      "Iteration  1900, loss = 0.472655\n",
      "Iteration  2000, loss = 0.472640\n",
      "Iteration  2100, loss = 0.472627\n",
      "Iteration  2200, loss = 0.472614\n",
      "Iteration  2300, loss = 0.472602\n",
      "Iteration  2400, loss = 0.472591\n",
      "Iteration  2500, loss = 0.472580\n",
      "Iteration  2600, loss = 0.472570\n",
      "Iteration  2700, loss = 0.472560\n",
      "Iteration  2800, loss = 0.472551\n",
      "Iteration  2900, loss = 0.472542\n",
      "Iteration  3000, loss = 0.472534\n",
      "Iteration  3100, loss = 0.472526\n",
      "Iteration  3200, loss = 0.472518\n",
      "Iteration  3300, loss = 0.472511\n",
      "Iteration  3400, loss = 0.472504\n",
      "Iteration  3500, loss = 0.472497\n",
      "Iteration  3600, loss = 0.472491\n",
      "Iteration  3700, loss = 0.472485\n",
      "Iteration  3800, loss = 0.472479\n",
      "Iteration  3900, loss = 0.472473\n",
      "Iteration  4000, loss = 0.472468\n",
      "Iteration  4100, loss = 0.472463\n",
      "Iteration  4200, loss = 0.472458\n",
      "Iteration  4300, loss = 0.472453\n",
      "Iteration  4400, loss = 0.472448\n",
      "Iteration  4500, loss = 0.472443\n",
      "Iteration  4600, loss = 0.472439\n",
      "Iteration  4700, loss = 0.472435\n",
      "Iteration  4800, loss = 0.472431\n",
      "Iteration  4900, loss = 0.472427\n",
      "Iteration  5000, loss = 0.472423\n",
      "Iteration  5100, loss = 0.472419\n",
      "Iteration  5200, loss = 0.472416\n",
      "Iteration  5300, loss = 0.472412\n",
      "Iteration  5400, loss = 0.472409\n",
      "Iteration  5500, loss = 0.472405\n",
      "Iteration  5600, loss = 0.472402\n",
      "Iteration  5700, loss = 0.472399\n",
      "Iteration  5800, loss = 0.472396\n",
      "Iteration  5900, loss = 0.472393\n",
      "Iteration  6000, loss = 0.472390\n",
      "Iteration  6100, loss = 0.472387\n",
      "Iteration  6200, loss = 0.472384\n",
      "Iteration  6300, loss = 0.472382\n",
      "Iteration  6400, loss = 0.472379\n",
      "Iteration  6500, loss = 0.472377\n",
      "Iteration  6600, loss = 0.472374\n",
      "Iteration  6700, loss = 0.472372\n",
      "Iteration  6800, loss = 0.472369\n",
      "Iteration  6900, loss = 0.472367\n",
      "Iteration  7000, loss = 0.472365\n",
      "Iteration  7100, loss = 0.472362\n",
      "Iteration  7200, loss = 0.472360\n",
      "Iteration  7300, loss = 0.472358\n",
      "Iteration  7400, loss = 0.472356\n",
      "Iteration  7500, loss = 0.472354\n",
      "Iteration  7600, loss = 0.472352\n",
      "Iteration  7700, loss = 0.472350\n",
      "Iteration  7800, loss = 0.472348\n",
      "Iteration  7900, loss = 0.472346\n",
      "Iteration  8000, loss = 0.472344\n",
      "Iteration  8100, loss = 0.472342\n",
      "Iteration  8200, loss = 0.472340\n",
      "Iteration  8300, loss = 0.472338\n",
      "Iteration  8400, loss = 0.472336\n",
      "Iteration  8500, loss = 0.472335\n",
      "Iteration  8600, loss = 0.472333\n",
      "Iteration  8700, loss = 0.472331\n",
      "Iteration  8800, loss = 0.472329\n",
      "Iteration  8900, loss = 0.472328\n",
      "Iteration  9000, loss = 0.472326\n",
      "Iteration  9100, loss = 0.472325\n",
      "Iteration  9200, loss = 0.472323\n",
      "Iteration  9300, loss = 0.472321\n",
      "Iteration  9400, loss = 0.472320\n",
      "Iteration  9500, loss = 0.472318\n",
      "Iteration  9600, loss = 0.472317\n",
      "Iteration  9700, loss = 0.472315\n",
      "Iteration  9800, loss = 0.472314\n",
      "Iteration  9900, loss = 0.472312\n",
      " Accuracy: 85.37%\n",
      " F1 Score: 0.4060\n",
      "\n",
      "Validation loss: 0.4895770864352618 f1 score 0.406012247170161 with data size of 20192\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476018\n",
      "Iteration   200, loss = 0.474871\n",
      "Iteration   300, loss = 0.474470\n",
      "Iteration   400, loss = 0.474244\n",
      "Iteration   500, loss = 0.474099\n",
      "Iteration   600, loss = 0.473997\n",
      "Iteration   700, loss = 0.473922\n",
      "Iteration   800, loss = 0.473863\n",
      "Iteration   900, loss = 0.473816\n",
      "Iteration  1000, loss = 0.473776\n",
      "Iteration  1100, loss = 0.473742\n",
      "Iteration  1200, loss = 0.473712\n",
      "Iteration  1300, loss = 0.473686\n",
      "Iteration  1400, loss = 0.473662\n",
      "Iteration  1500, loss = 0.473641\n",
      "Iteration  1600, loss = 0.473622\n",
      "Iteration  1700, loss = 0.473604\n",
      "Iteration  1800, loss = 0.473587\n",
      "Iteration  1900, loss = 0.473572\n",
      "Iteration  2000, loss = 0.473558\n",
      "Iteration  2100, loss = 0.473544\n",
      "Iteration  2200, loss = 0.473532\n",
      "Iteration  2300, loss = 0.473520\n",
      "Iteration  2400, loss = 0.473509\n",
      "Iteration  2500, loss = 0.473498\n",
      "Iteration  2600, loss = 0.473488\n",
      "Iteration  2700, loss = 0.473479\n",
      "Iteration  2800, loss = 0.473470\n",
      "Iteration  2900, loss = 0.473461\n",
      "Iteration  3000, loss = 0.473453\n",
      "Iteration  3100, loss = 0.473445\n",
      "Iteration  3200, loss = 0.473438\n",
      "Iteration  3300, loss = 0.473431\n",
      "Iteration  3400, loss = 0.473424\n",
      "Iteration  3500, loss = 0.473418\n",
      "Iteration  3600, loss = 0.473411\n",
      "Iteration  3700, loss = 0.473405\n",
      "Iteration  3800, loss = 0.473400\n",
      "Iteration  3900, loss = 0.473394\n",
      "Iteration  4000, loss = 0.473389\n",
      "Iteration  4100, loss = 0.473384\n",
      "Iteration  4200, loss = 0.473379\n",
      "Iteration  4300, loss = 0.473374\n",
      "Iteration  4400, loss = 0.473370\n",
      "Iteration  4500, loss = 0.473365\n",
      "Iteration  4600, loss = 0.473361\n",
      "Iteration  4700, loss = 0.473357\n",
      "Iteration  4800, loss = 0.473353\n",
      "Iteration  4900, loss = 0.473349\n",
      "Iteration  5000, loss = 0.473346\n",
      "Iteration  5100, loss = 0.473342\n",
      "Iteration  5200, loss = 0.473338\n",
      "Iteration  5300, loss = 0.473335\n",
      "Iteration  5400, loss = 0.473332\n",
      "Iteration  5500, loss = 0.473329\n",
      "Iteration  5600, loss = 0.473325\n",
      "Iteration  5700, loss = 0.473322\n",
      "Iteration  5800, loss = 0.473320\n",
      "Iteration  5900, loss = 0.473317\n",
      "Iteration  6000, loss = 0.473314\n",
      "Iteration  6100, loss = 0.473311\n",
      "Iteration  6200, loss = 0.473309\n",
      "Iteration  6300, loss = 0.473306\n",
      "Iteration  6400, loss = 0.473303\n",
      "Iteration  6500, loss = 0.473301\n",
      "Iteration  6600, loss = 0.473299\n",
      "Iteration  6700, loss = 0.473296\n",
      "Iteration  6800, loss = 0.473294\n",
      "Iteration  6900, loss = 0.473292\n",
      "Iteration  7000, loss = 0.473290\n",
      "Iteration  7100, loss = 0.473287\n",
      "Iteration  7200, loss = 0.473285\n",
      "Iteration  7300, loss = 0.473283\n",
      "Iteration  7400, loss = 0.473281\n",
      "Iteration  7500, loss = 0.473279\n",
      "Iteration  7600, loss = 0.473277\n",
      "Iteration  7700, loss = 0.473275\n",
      "Iteration  7800, loss = 0.473273\n",
      "Iteration  7900, loss = 0.473272\n",
      "Iteration  8000, loss = 0.473270\n",
      "Iteration  8100, loss = 0.473268\n",
      "Iteration  8200, loss = 0.473266\n",
      "Iteration  8300, loss = 0.473264\n",
      "Iteration  8400, loss = 0.473263\n",
      "Iteration  8500, loss = 0.473261\n",
      "Iteration  8600, loss = 0.473259\n",
      "Iteration  8700, loss = 0.473258\n",
      "Iteration  8800, loss = 0.473256\n",
      "Iteration  8900, loss = 0.473255\n",
      "Iteration  9000, loss = 0.473253\n",
      "Iteration  9100, loss = 0.473251\n",
      "Iteration  9200, loss = 0.473250\n",
      "Iteration  9300, loss = 0.473248\n",
      "Iteration  9400, loss = 0.473247\n",
      "Iteration  9500, loss = 0.473245\n",
      "Iteration  9600, loss = 0.473244\n",
      "Iteration  9700, loss = 0.473243\n",
      "Iteration  9800, loss = 0.473241\n",
      "Iteration  9900, loss = 0.473240\n",
      " Accuracy: 85.41%\n",
      " F1 Score: 0.4052\n",
      "\n",
      "Validation loss: 0.4885411258687079 f1 score 0.4051938369781307 with data size of 21875\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475721\n",
      "Iteration   200, loss = 0.474647\n",
      "Iteration   300, loss = 0.474279\n",
      "Iteration   400, loss = 0.474076\n",
      "Iteration   500, loss = 0.473946\n",
      "Iteration   600, loss = 0.473856\n",
      "Iteration   700, loss = 0.473789\n",
      "Iteration   800, loss = 0.473736\n",
      "Iteration   900, loss = 0.473693\n",
      "Iteration  1000, loss = 0.473658\n",
      "Iteration  1100, loss = 0.473627\n",
      "Iteration  1200, loss = 0.473600\n",
      "Iteration  1300, loss = 0.473576\n",
      "Iteration  1400, loss = 0.473554\n",
      "Iteration  1500, loss = 0.473534\n",
      "Iteration  1600, loss = 0.473516\n",
      "Iteration  1700, loss = 0.473499\n",
      "Iteration  1800, loss = 0.473484\n",
      "Iteration  1900, loss = 0.473469\n",
      "Iteration  2000, loss = 0.473456\n",
      "Iteration  2100, loss = 0.473443\n",
      "Iteration  2200, loss = 0.473431\n",
      "Iteration  2300, loss = 0.473420\n",
      "Iteration  2400, loss = 0.473410\n",
      "Iteration  2500, loss = 0.473400\n",
      "Iteration  2600, loss = 0.473390\n",
      "Iteration  2700, loss = 0.473381\n",
      "Iteration  2800, loss = 0.473373\n",
      "Iteration  2900, loss = 0.473364\n",
      "Iteration  3000, loss = 0.473357\n",
      "Iteration  3100, loss = 0.473349\n",
      "Iteration  3200, loss = 0.473342\n",
      "Iteration  3300, loss = 0.473335\n",
      "Iteration  3400, loss = 0.473329\n",
      "Iteration  3500, loss = 0.473323\n",
      "Iteration  3600, loss = 0.473317\n",
      "Iteration  3700, loss = 0.473311\n",
      "Iteration  3800, loss = 0.473305\n",
      "Iteration  3900, loss = 0.473300\n",
      "Iteration  4000, loss = 0.473295\n",
      "Iteration  4100, loss = 0.473290\n",
      "Iteration  4200, loss = 0.473285\n",
      "Iteration  4300, loss = 0.473281\n",
      "Iteration  4400, loss = 0.473276\n",
      "Iteration  4500, loss = 0.473272\n",
      "Iteration  4600, loss = 0.473268\n",
      "Iteration  4700, loss = 0.473264\n",
      "Iteration  4800, loss = 0.473260\n",
      "Iteration  4900, loss = 0.473256\n",
      "Iteration  5000, loss = 0.473253\n",
      "Iteration  5100, loss = 0.473249\n",
      "Iteration  5200, loss = 0.473246\n",
      "Iteration  5300, loss = 0.473242\n",
      "Iteration  5400, loss = 0.473239\n",
      "Iteration  5500, loss = 0.473236\n",
      "Iteration  5600, loss = 0.473233\n",
      "Iteration  5700, loss = 0.473230\n",
      "Iteration  5800, loss = 0.473227\n",
      "Iteration  5900, loss = 0.473224\n",
      "Iteration  6000, loss = 0.473222\n",
      "Iteration  6100, loss = 0.473219\n",
      "Iteration  6200, loss = 0.473216\n",
      "Iteration  6300, loss = 0.473214\n",
      "Iteration  6400, loss = 0.473211\n",
      "Iteration  6500, loss = 0.473209\n",
      "Iteration  6600, loss = 0.473206\n",
      "Iteration  6700, loss = 0.473204\n",
      "Iteration  6800, loss = 0.473201\n",
      "Iteration  6900, loss = 0.473199\n",
      "Iteration  7000, loss = 0.473197\n",
      "Iteration  7100, loss = 0.473195\n",
      "Iteration  7200, loss = 0.473193\n",
      "Iteration  7300, loss = 0.473190\n",
      "Iteration  7400, loss = 0.473188\n",
      "Iteration  7500, loss = 0.473186\n",
      "Iteration  7600, loss = 0.473184\n",
      "Iteration  7700, loss = 0.473182\n",
      "Iteration  7800, loss = 0.473180\n",
      "Iteration  7900, loss = 0.473179\n",
      "Iteration  8000, loss = 0.473177\n",
      "Iteration  8100, loss = 0.473175\n",
      "Iteration  8200, loss = 0.473173\n",
      "Iteration  8300, loss = 0.473171\n",
      "Iteration  8400, loss = 0.473169\n",
      "Iteration  8500, loss = 0.473168\n",
      "Iteration  8600, loss = 0.473166\n",
      "Iteration  8700, loss = 0.473164\n",
      "Iteration  8800, loss = 0.473162\n",
      "Iteration  8900, loss = 0.473161\n",
      "Iteration  9000, loss = 0.473159\n",
      "Iteration  9100, loss = 0.473157\n",
      "Iteration  9200, loss = 0.473156\n",
      "Iteration  9300, loss = 0.473154\n",
      "Iteration  9400, loss = 0.473153\n",
      "Iteration  9500, loss = 0.473151\n",
      "Iteration  9600, loss = 0.473150\n",
      "Iteration  9700, loss = 0.473148\n",
      "Iteration  9800, loss = 0.473146\n",
      "Iteration  9900, loss = 0.473145\n",
      " Accuracy: 85.47%\n",
      " F1 Score: 0.4070\n",
      "\n",
      "Validation loss: 0.48850162579566575 f1 score 0.4070389255067773 with data size of 23864\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474635\n",
      "Iteration   200, loss = 0.473645\n",
      "Iteration   300, loss = 0.473321\n",
      "Iteration   400, loss = 0.473143\n",
      "Iteration   500, loss = 0.473030\n",
      "Iteration   600, loss = 0.472954\n",
      "Iteration   700, loss = 0.472897\n",
      "Iteration   800, loss = 0.472855\n",
      "Iteration   900, loss = 0.472820\n",
      "Iteration  1000, loss = 0.472792\n",
      "Iteration  1100, loss = 0.472769\n",
      "Iteration  1200, loss = 0.472749\n",
      "Iteration  1300, loss = 0.472731\n",
      "Iteration  1400, loss = 0.472715\n",
      "Iteration  1500, loss = 0.472701\n",
      "Iteration  1600, loss = 0.472688\n",
      "Iteration  1700, loss = 0.472676\n",
      "Iteration  1800, loss = 0.472665\n",
      "Iteration  1900, loss = 0.472655\n",
      "Iteration  2000, loss = 0.472645\n",
      "Iteration  2100, loss = 0.472636\n",
      "Iteration  2200, loss = 0.472628\n",
      "Iteration  2300, loss = 0.472620\n",
      "Iteration  2400, loss = 0.472612\n",
      "Iteration  2500, loss = 0.472605\n",
      "Iteration  2600, loss = 0.472598\n",
      "Iteration  2700, loss = 0.472592\n",
      "Iteration  2800, loss = 0.472586\n",
      "Iteration  2900, loss = 0.472580\n",
      "Iteration  3000, loss = 0.472574\n",
      "Iteration  3100, loss = 0.472569\n",
      "Iteration  3200, loss = 0.472564\n",
      "Iteration  3300, loss = 0.472559\n",
      "Iteration  3400, loss = 0.472554\n",
      "Iteration  3500, loss = 0.472549\n",
      "Iteration  3600, loss = 0.472544\n",
      "Iteration  3700, loss = 0.472540\n",
      "Iteration  3800, loss = 0.472536\n",
      "Iteration  3900, loss = 0.472532\n",
      "Iteration  4000, loss = 0.472528\n",
      "Iteration  4100, loss = 0.472524\n",
      "Iteration  4200, loss = 0.472520\n",
      "Iteration  4300, loss = 0.472517\n",
      "Iteration  4400, loss = 0.472513\n",
      "Iteration  4500, loss = 0.472510\n",
      "Iteration  4600, loss = 0.472506\n",
      "Iteration  4700, loss = 0.472503\n",
      "Iteration  4800, loss = 0.472500\n",
      "Iteration  4900, loss = 0.472497\n",
      "Iteration  5000, loss = 0.472494\n",
      "Iteration  5100, loss = 0.472491\n",
      "Iteration  5200, loss = 0.472488\n",
      "Iteration  5300, loss = 0.472485\n",
      "Iteration  5400, loss = 0.472483\n",
      "Iteration  5500, loss = 0.472480\n",
      "Iteration  5600, loss = 0.472477\n",
      "Iteration  5700, loss = 0.472475\n",
      "Iteration  5800, loss = 0.472472\n",
      "Iteration  5900, loss = 0.472470\n",
      "Iteration  6000, loss = 0.472467\n",
      "Iteration  6100, loss = 0.472465\n",
      "Iteration  6200, loss = 0.472463\n",
      "Iteration  6300, loss = 0.472460\n",
      "Iteration  6400, loss = 0.472458\n",
      "Iteration  6500, loss = 0.472456\n",
      "Iteration  6600, loss = 0.472454\n",
      "Iteration  6700, loss = 0.472452\n",
      "Iteration  6800, loss = 0.472450\n",
      "Iteration  6900, loss = 0.472448\n",
      "Iteration  7000, loss = 0.472446\n",
      "Iteration  7100, loss = 0.472444\n",
      "Iteration  7200, loss = 0.472442\n",
      "Iteration  7300, loss = 0.472440\n",
      "Iteration  7400, loss = 0.472438\n",
      "Iteration  7500, loss = 0.472436\n",
      "Iteration  7600, loss = 0.472434\n",
      "Iteration  7700, loss = 0.472432\n",
      "Iteration  7800, loss = 0.472431\n",
      "Iteration  7900, loss = 0.472429\n",
      "Iteration  8000, loss = 0.472427\n",
      "Iteration  8100, loss = 0.472425\n",
      "Iteration  8200, loss = 0.472424\n",
      "Iteration  8300, loss = 0.472422\n",
      "Iteration  8400, loss = 0.472420\n",
      "Iteration  8500, loss = 0.472419\n",
      "Iteration  8600, loss = 0.472417\n",
      "Iteration  8700, loss = 0.472416\n",
      "Iteration  8800, loss = 0.472414\n",
      "Iteration  8900, loss = 0.472412\n",
      "Iteration  9000, loss = 0.472411\n",
      "Iteration  9100, loss = 0.472409\n",
      "Iteration  9200, loss = 0.472408\n",
      "Iteration  9300, loss = 0.472406\n",
      "Iteration  9400, loss = 0.472405\n",
      "Iteration  9500, loss = 0.472403\n",
      "Iteration  9600, loss = 0.472402\n",
      "Iteration  9700, loss = 0.472401\n",
      "Iteration  9800, loss = 0.472399\n",
      "Iteration  9900, loss = 0.472398\n",
      " Accuracy: 85.53%\n",
      " F1 Score: 0.4083\n",
      "\n",
      "Validation loss: 0.48614819702136003 f1 score 0.40825230615806485 with data size of 26250\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473792\n",
      "Iteration   200, loss = 0.472781\n",
      "Iteration   300, loss = 0.472463\n",
      "Iteration   400, loss = 0.472296\n",
      "Iteration   500, loss = 0.472193\n",
      "Iteration   600, loss = 0.472125\n",
      "Iteration   700, loss = 0.472076\n",
      "Iteration   800, loss = 0.472039\n",
      "Iteration   900, loss = 0.472010\n",
      "Iteration  1000, loss = 0.471987\n",
      "Iteration  1100, loss = 0.471967\n",
      "Iteration  1200, loss = 0.471950\n",
      "Iteration  1300, loss = 0.471935\n",
      "Iteration  1400, loss = 0.471922\n",
      "Iteration  1500, loss = 0.471910\n",
      "Iteration  1600, loss = 0.471900\n",
      "Iteration  1700, loss = 0.471890\n",
      "Iteration  1800, loss = 0.471881\n",
      "Iteration  1900, loss = 0.471872\n",
      "Iteration  2000, loss = 0.471864\n",
      "Iteration  2100, loss = 0.471857\n",
      "Iteration  2200, loss = 0.471850\n",
      "Iteration  2300, loss = 0.471843\n",
      "Iteration  2400, loss = 0.471837\n",
      "Iteration  2500, loss = 0.471831\n",
      "Iteration  2600, loss = 0.471825\n",
      "Iteration  2700, loss = 0.471820\n",
      "Iteration  2800, loss = 0.471814\n",
      "Iteration  2900, loss = 0.471809\n",
      "Iteration  3000, loss = 0.471804\n",
      "Iteration  3100, loss = 0.471800\n",
      "Iteration  3200, loss = 0.471795\n",
      "Iteration  3300, loss = 0.471791\n",
      "Iteration  3400, loss = 0.471787\n",
      "Iteration  3500, loss = 0.471783\n",
      "Iteration  3600, loss = 0.471779\n",
      "Iteration  3700, loss = 0.471775\n",
      "Iteration  3800, loss = 0.471772\n",
      "Iteration  3900, loss = 0.471768\n",
      "Iteration  4000, loss = 0.471765\n",
      "Iteration  4100, loss = 0.471761\n",
      "Iteration  4200, loss = 0.471758\n",
      "Iteration  4300, loss = 0.471755\n",
      "Iteration  4400, loss = 0.471752\n",
      "Iteration  4500, loss = 0.471749\n",
      "Iteration  4600, loss = 0.471746\n",
      "Iteration  4700, loss = 0.471744\n",
      "Iteration  4800, loss = 0.471741\n",
      "Iteration  4900, loss = 0.471738\n",
      "Iteration  5000, loss = 0.471736\n",
      "Iteration  5100, loss = 0.471733\n",
      "Iteration  5200, loss = 0.471731\n",
      "Iteration  5300, loss = 0.471728\n",
      "Iteration  5400, loss = 0.471726\n",
      "Iteration  5500, loss = 0.471724\n",
      "Iteration  5600, loss = 0.471722\n",
      "Iteration  5700, loss = 0.471719\n",
      "Iteration  5800, loss = 0.471717\n",
      "Iteration  5900, loss = 0.471715\n",
      "Iteration  6000, loss = 0.471713\n",
      "Iteration  6100, loss = 0.471711\n",
      "Iteration  6200, loss = 0.471709\n",
      "Iteration  6300, loss = 0.471707\n",
      "Iteration  6400, loss = 0.471705\n",
      "Iteration  6500, loss = 0.471703\n",
      "Iteration  6600, loss = 0.471702\n",
      "Iteration  6700, loss = 0.471700\n",
      "Iteration  6800, loss = 0.471698\n",
      "Iteration  6900, loss = 0.471696\n",
      "Iteration  7000, loss = 0.471695\n",
      "Iteration  7100, loss = 0.471693\n",
      "Iteration  7200, loss = 0.471691\n",
      "Iteration  7300, loss = 0.471690\n",
      "Iteration  7400, loss = 0.471688\n",
      "Iteration  7500, loss = 0.471687\n",
      "Iteration  7600, loss = 0.471685\n",
      "Iteration  7700, loss = 0.471684\n",
      "Iteration  7800, loss = 0.471682\n",
      "Iteration  7900, loss = 0.471681\n",
      "Iteration  8000, loss = 0.471679\n",
      "Iteration  8100, loss = 0.471678\n",
      "Iteration  8200, loss = 0.471676\n",
      "Iteration  8300, loss = 0.471675\n",
      "Iteration  8400, loss = 0.471674\n",
      "Iteration  8500, loss = 0.471672\n",
      "Iteration  8600, loss = 0.471671\n",
      "Iteration  8700, loss = 0.471670\n",
      "Iteration  8800, loss = 0.471668\n",
      "Iteration  8900, loss = 0.471667\n",
      "Iteration  9000, loss = 0.471666\n",
      "Iteration  9100, loss = 0.471664\n",
      "Iteration  9200, loss = 0.471663\n",
      "Iteration  9300, loss = 0.471662\n",
      "Iteration  9400, loss = 0.471661\n",
      "Iteration  9500, loss = 0.471659\n",
      "Iteration  9600, loss = 0.471658\n",
      "Iteration  9700, loss = 0.471657\n",
      "Iteration  9800, loss = 0.471656\n",
      "Iteration  9900, loss = 0.471655\n",
      " Accuracy: 85.49%\n",
      " F1 Score: 0.4071\n",
      "\n",
      "Validation loss: 0.48541424063189603 f1 score 0.4070752366716488 with data size of 29167\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476160\n",
      "Iteration   200, loss = 0.475196\n",
      "Iteration   300, loss = 0.474899\n",
      "Iteration   400, loss = 0.474745\n",
      "Iteration   500, loss = 0.474651\n",
      "Iteration   600, loss = 0.474588\n",
      "Iteration   700, loss = 0.474543\n",
      "Iteration   800, loss = 0.474508\n",
      "Iteration   900, loss = 0.474480\n",
      "Iteration  1000, loss = 0.474456\n",
      "Iteration  1100, loss = 0.474437\n",
      "Iteration  1200, loss = 0.474419\n",
      "Iteration  1300, loss = 0.474404\n",
      "Iteration  1400, loss = 0.474390\n",
      "Iteration  1500, loss = 0.474377\n",
      "Iteration  1600, loss = 0.474365\n",
      "Iteration  1700, loss = 0.474354\n",
      "Iteration  1800, loss = 0.474343\n",
      "Iteration  1900, loss = 0.474333\n",
      "Iteration  2000, loss = 0.474324\n",
      "Iteration  2100, loss = 0.474315\n",
      "Iteration  2200, loss = 0.474307\n",
      "Iteration  2300, loss = 0.474299\n",
      "Iteration  2400, loss = 0.474291\n",
      "Iteration  2500, loss = 0.474284\n",
      "Iteration  2600, loss = 0.474277\n",
      "Iteration  2700, loss = 0.474270\n",
      "Iteration  2800, loss = 0.474264\n",
      "Iteration  2900, loss = 0.474258\n",
      "Iteration  3000, loss = 0.474252\n",
      "Iteration  3100, loss = 0.474246\n",
      "Iteration  3200, loss = 0.474240\n",
      "Iteration  3300, loss = 0.474235\n",
      "Iteration  3400, loss = 0.474230\n",
      "Iteration  3500, loss = 0.474225\n",
      "Iteration  3600, loss = 0.474220\n",
      "Iteration  3700, loss = 0.474215\n",
      "Iteration  3800, loss = 0.474211\n",
      "Iteration  3900, loss = 0.474206\n",
      "Iteration  4000, loss = 0.474202\n",
      "Iteration  4100, loss = 0.474198\n",
      "Iteration  4200, loss = 0.474194\n",
      "Iteration  4300, loss = 0.474190\n",
      "Iteration  4400, loss = 0.474186\n",
      "Iteration  4500, loss = 0.474183\n",
      "Iteration  4600, loss = 0.474179\n",
      "Iteration  4700, loss = 0.474176\n",
      "Iteration  4800, loss = 0.474172\n",
      "Iteration  4900, loss = 0.474169\n",
      "Iteration  5000, loss = 0.474166\n",
      "Iteration  5100, loss = 0.474163\n",
      "Iteration  5200, loss = 0.474160\n",
      "Iteration  5300, loss = 0.474157\n",
      "Iteration  5400, loss = 0.474154\n",
      "Iteration  5500, loss = 0.474151\n",
      "Iteration  5600, loss = 0.474148\n",
      "Iteration  5700, loss = 0.474145\n",
      "Iteration  5800, loss = 0.474143\n",
      "Iteration  5900, loss = 0.474140\n",
      "Iteration  6000, loss = 0.474138\n",
      "Iteration  6100, loss = 0.474135\n",
      "Iteration  6200, loss = 0.474133\n",
      "Iteration  6300, loss = 0.474131\n",
      "Iteration  6400, loss = 0.474128\n",
      "Iteration  6500, loss = 0.474126\n",
      "Iteration  6600, loss = 0.474124\n",
      "Iteration  6700, loss = 0.474122\n",
      "Iteration  6800, loss = 0.474120\n",
      "Iteration  6900, loss = 0.474118\n",
      "Iteration  7000, loss = 0.474116\n",
      "Iteration  7100, loss = 0.474114\n",
      "Iteration  7200, loss = 0.474112\n",
      "Iteration  7300, loss = 0.474110\n",
      "Iteration  7400, loss = 0.474108\n",
      "Iteration  7500, loss = 0.474106\n",
      "Iteration  7600, loss = 0.474104\n",
      "Iteration  7700, loss = 0.474102\n",
      "Iteration  7800, loss = 0.474101\n",
      "Iteration  7900, loss = 0.474099\n",
      "Iteration  8000, loss = 0.474097\n",
      "Iteration  8100, loss = 0.474096\n",
      "Iteration  8200, loss = 0.474094\n",
      "Iteration  8300, loss = 0.474092\n",
      "Iteration  8400, loss = 0.474091\n",
      "Iteration  8500, loss = 0.474089\n",
      "Iteration  8600, loss = 0.474088\n",
      "Iteration  8700, loss = 0.474086\n",
      "Iteration  8800, loss = 0.474085\n",
      "Iteration  8900, loss = 0.474083\n",
      "Iteration  9000, loss = 0.474082\n",
      "Iteration  9100, loss = 0.474080\n",
      "Iteration  9200, loss = 0.474079\n",
      "Iteration  9300, loss = 0.474077\n",
      "Iteration  9400, loss = 0.474076\n",
      "Iteration  9500, loss = 0.474075\n",
      "Iteration  9600, loss = 0.474073\n",
      "Iteration  9700, loss = 0.474072\n",
      "Iteration  9800, loss = 0.474071\n",
      "Iteration  9900, loss = 0.474069\n",
      " Accuracy: 85.58%\n",
      " F1 Score: 0.4091\n",
      "\n",
      "Validation loss: 0.48565439187930043 f1 score 0.4090681988508614 with data size of 32813\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476318\n",
      "Iteration   200, loss = 0.475335\n",
      "Iteration   300, loss = 0.475026\n",
      "Iteration   400, loss = 0.474863\n",
      "Iteration   500, loss = 0.474764\n",
      "Iteration   600, loss = 0.474699\n",
      "Iteration   700, loss = 0.474652\n",
      "Iteration   800, loss = 0.474617\n",
      "Iteration   900, loss = 0.474589\n",
      "Iteration  1000, loss = 0.474567\n",
      "Iteration  1100, loss = 0.474548\n",
      "Iteration  1200, loss = 0.474531\n",
      "Iteration  1300, loss = 0.474516\n",
      "Iteration  1400, loss = 0.474503\n",
      "Iteration  1500, loss = 0.474491\n",
      "Iteration  1600, loss = 0.474480\n",
      "Iteration  1700, loss = 0.474470\n",
      "Iteration  1800, loss = 0.474461\n",
      "Iteration  1900, loss = 0.474452\n",
      "Iteration  2000, loss = 0.474444\n",
      "Iteration  2100, loss = 0.474436\n",
      "Iteration  2200, loss = 0.474428\n",
      "Iteration  2300, loss = 0.474421\n",
      "Iteration  2400, loss = 0.474415\n",
      "Iteration  2500, loss = 0.474408\n",
      "Iteration  2600, loss = 0.474402\n",
      "Iteration  2700, loss = 0.474396\n",
      "Iteration  2800, loss = 0.474391\n",
      "Iteration  2900, loss = 0.474386\n",
      "Iteration  3000, loss = 0.474380\n",
      "Iteration  3100, loss = 0.474375\n",
      "Iteration  3200, loss = 0.474371\n",
      "Iteration  3300, loss = 0.474366\n",
      "Iteration  3400, loss = 0.474362\n",
      "Iteration  3500, loss = 0.474358\n",
      "Iteration  3600, loss = 0.474354\n",
      "Iteration  3700, loss = 0.474350\n",
      "Iteration  3800, loss = 0.474346\n",
      "Iteration  3900, loss = 0.474342\n",
      "Iteration  4000, loss = 0.474339\n",
      "Iteration  4100, loss = 0.474335\n",
      "Iteration  4200, loss = 0.474332\n",
      "Iteration  4300, loss = 0.474329\n",
      "Iteration  4400, loss = 0.474326\n",
      "Iteration  4500, loss = 0.474323\n",
      "Iteration  4600, loss = 0.474320\n",
      "Iteration  4700, loss = 0.474317\n",
      "Iteration  4800, loss = 0.474314\n",
      "Iteration  4900, loss = 0.474311\n",
      "Iteration  5000, loss = 0.474309\n",
      "Iteration  5100, loss = 0.474306\n",
      "Iteration  5200, loss = 0.474304\n",
      "Iteration  5300, loss = 0.474301\n",
      "Iteration  5400, loss = 0.474299\n",
      "Iteration  5500, loss = 0.474297\n",
      "Iteration  5600, loss = 0.474295\n",
      "Iteration  5700, loss = 0.474292\n",
      "Iteration  5800, loss = 0.474290\n",
      "Iteration  5900, loss = 0.474288\n",
      "Iteration  6000, loss = 0.474286\n",
      "Iteration  6100, loss = 0.474284\n",
      "Iteration  6200, loss = 0.474282\n",
      "Iteration  6300, loss = 0.474280\n",
      "Iteration  6400, loss = 0.474279\n",
      "Iteration  6500, loss = 0.474277\n",
      "Iteration  6600, loss = 0.474275\n",
      "Iteration  6700, loss = 0.474273\n",
      "Iteration  6800, loss = 0.474272\n",
      "Iteration  6900, loss = 0.474270\n",
      "Iteration  7000, loss = 0.474268\n",
      "Iteration  7100, loss = 0.474267\n",
      "Iteration  7200, loss = 0.474265\n",
      "Iteration  7300, loss = 0.474264\n",
      "Iteration  7400, loss = 0.474262\n",
      "Iteration  7500, loss = 0.474261\n",
      "Iteration  7600, loss = 0.474259\n",
      "Iteration  7700, loss = 0.474258\n",
      "Iteration  7800, loss = 0.474257\n",
      "Iteration  7900, loss = 0.474255\n",
      "Iteration  8000, loss = 0.474254\n",
      "Iteration  8100, loss = 0.474253\n",
      "Iteration  8200, loss = 0.474251\n",
      "Iteration  8300, loss = 0.474250\n",
      "Iteration  8400, loss = 0.474249\n",
      "Iteration  8500, loss = 0.474247\n",
      "Iteration  8600, loss = 0.474246\n",
      "Iteration  8700, loss = 0.474245\n",
      "Iteration  8800, loss = 0.474244\n",
      "Iteration  8900, loss = 0.474243\n",
      "Iteration  9000, loss = 0.474241\n",
      "Iteration  9100, loss = 0.474240\n",
      "Iteration  9200, loss = 0.474239\n",
      "Iteration  9300, loss = 0.474238\n",
      "Iteration  9400, loss = 0.474237\n",
      "Iteration  9500, loss = 0.474236\n",
      "Iteration  9600, loss = 0.474235\n",
      "Iteration  9700, loss = 0.474234\n",
      "Iteration  9800, loss = 0.474233\n",
      "Iteration  9900, loss = 0.474232\n",
      " Accuracy: 85.49%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.48800283896335417 f1 score 0.4075640706643439 with data size of 37501\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476303\n",
      "Iteration   200, loss = 0.475291\n",
      "Iteration   300, loss = 0.474963\n",
      "Iteration   400, loss = 0.474792\n",
      "Iteration   500, loss = 0.474689\n",
      "Iteration   600, loss = 0.474623\n",
      "Iteration   700, loss = 0.474577\n",
      "Iteration   800, loss = 0.474543\n",
      "Iteration   900, loss = 0.474517\n",
      "Iteration  1000, loss = 0.474496\n",
      "Iteration  1100, loss = 0.474479\n",
      "Iteration  1200, loss = 0.474465\n",
      "Iteration  1300, loss = 0.474453\n",
      "Iteration  1400, loss = 0.474442\n",
      "Iteration  1500, loss = 0.474432\n",
      "Iteration  1600, loss = 0.474424\n",
      "Iteration  1700, loss = 0.474416\n",
      "Iteration  1800, loss = 0.474409\n",
      "Iteration  1900, loss = 0.474402\n",
      "Iteration  2000, loss = 0.474396\n",
      "Iteration  2100, loss = 0.474390\n",
      "Iteration  2200, loss = 0.474385\n",
      "Iteration  2300, loss = 0.474380\n",
      "Iteration  2400, loss = 0.474375\n",
      "Iteration  2500, loss = 0.474370\n",
      "Iteration  2600, loss = 0.474366\n",
      "Iteration  2700, loss = 0.474362\n",
      "Iteration  2800, loss = 0.474358\n",
      "Iteration  2900, loss = 0.474354\n",
      "Iteration  3000, loss = 0.474350\n",
      "Iteration  3100, loss = 0.474347\n",
      "Iteration  3200, loss = 0.474343\n",
      "Iteration  3300, loss = 0.474340\n",
      "Iteration  3400, loss = 0.474337\n",
      "Iteration  3500, loss = 0.474334\n",
      "Iteration  3600, loss = 0.474331\n",
      "Iteration  3700, loss = 0.474328\n",
      "Iteration  3800, loss = 0.474325\n",
      "Iteration  3900, loss = 0.474322\n",
      "Iteration  4000, loss = 0.474320\n",
      "Iteration  4100, loss = 0.474317\n",
      "Iteration  4200, loss = 0.474315\n",
      "Iteration  4300, loss = 0.474313\n",
      "Iteration  4400, loss = 0.474310\n",
      "Iteration  4500, loss = 0.474308\n",
      "Iteration  4600, loss = 0.474306\n",
      "Iteration  4700, loss = 0.474304\n",
      "Iteration  4800, loss = 0.474302\n",
      "Iteration  4900, loss = 0.474300\n",
      "Iteration  5000, loss = 0.474298\n",
      "Iteration  5100, loss = 0.474296\n",
      "Iteration  5200, loss = 0.474294\n",
      "Iteration  5300, loss = 0.474292\n",
      "Iteration  5400, loss = 0.474290\n",
      "Iteration  5500, loss = 0.474288\n",
      "Iteration  5600, loss = 0.474287\n",
      "Iteration  5700, loss = 0.474285\n",
      "Iteration  5800, loss = 0.474283\n",
      "Iteration  5900, loss = 0.474282\n",
      "Iteration  6000, loss = 0.474280\n",
      "Iteration  6100, loss = 0.474278\n",
      "Iteration  6200, loss = 0.474277\n",
      "Iteration  6300, loss = 0.474275\n",
      "Iteration  6400, loss = 0.474274\n",
      "Iteration  6500, loss = 0.474273\n",
      "Iteration  6600, loss = 0.474271\n",
      "Iteration  6700, loss = 0.474270\n",
      "Iteration  6800, loss = 0.474268\n",
      "Iteration  6900, loss = 0.474267\n",
      "Iteration  7000, loss = 0.474266\n",
      "Iteration  7100, loss = 0.474264\n",
      "Iteration  7200, loss = 0.474263\n",
      "Iteration  7300, loss = 0.474262\n",
      "Iteration  7400, loss = 0.474260\n",
      "Iteration  7500, loss = 0.474259\n",
      "Iteration  7600, loss = 0.474258\n",
      "Iteration  7700, loss = 0.474257\n",
      "Iteration  7800, loss = 0.474256\n",
      "Iteration  7900, loss = 0.474254\n",
      "Iteration  8000, loss = 0.474253\n",
      "Iteration  8100, loss = 0.474252\n",
      "Iteration  8200, loss = 0.474251\n",
      "Iteration  8300, loss = 0.474250\n",
      "Iteration  8400, loss = 0.474249\n",
      "Iteration  8500, loss = 0.474248\n",
      "Iteration  8600, loss = 0.474247\n",
      "Iteration  8700, loss = 0.474246\n",
      "Iteration  8800, loss = 0.474245\n",
      "Iteration  8900, loss = 0.474244\n",
      "Iteration  9000, loss = 0.474242\n",
      "Iteration  9100, loss = 0.474241\n",
      "Iteration  9200, loss = 0.474240\n",
      "Converged at iteration 9237\n",
      " Accuracy: 85.54%\n",
      " F1 Score: 0.4095\n",
      "\n",
      "Validation loss: 0.4879241618382999 f1 score 0.4094840998195279 with data size of 43751\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476176\n",
      "Iteration   200, loss = 0.475209\n",
      "Iteration   300, loss = 0.474908\n",
      "Iteration   400, loss = 0.474754\n",
      "Iteration   500, loss = 0.474662\n",
      "Iteration   600, loss = 0.474603\n",
      "Iteration   700, loss = 0.474562\n",
      "Iteration   800, loss = 0.474532\n",
      "Iteration   900, loss = 0.474508\n",
      "Iteration  1000, loss = 0.474490\n",
      "Iteration  1100, loss = 0.474474\n",
      "Iteration  1200, loss = 0.474461\n",
      "Iteration  1300, loss = 0.474450\n",
      "Iteration  1400, loss = 0.474440\n",
      "Iteration  1500, loss = 0.474432\n",
      "Iteration  1600, loss = 0.474424\n",
      "Iteration  1700, loss = 0.474417\n",
      "Iteration  1800, loss = 0.474410\n",
      "Iteration  1900, loss = 0.474404\n",
      "Iteration  2000, loss = 0.474399\n",
      "Iteration  2100, loss = 0.474393\n",
      "Iteration  2200, loss = 0.474388\n",
      "Iteration  2300, loss = 0.474384\n",
      "Iteration  2400, loss = 0.474380\n",
      "Iteration  2500, loss = 0.474375\n",
      "Iteration  2600, loss = 0.474372\n",
      "Iteration  2700, loss = 0.474368\n",
      "Iteration  2800, loss = 0.474364\n",
      "Iteration  2900, loss = 0.474361\n",
      "Iteration  3000, loss = 0.474358\n",
      "Iteration  3100, loss = 0.474355\n",
      "Iteration  3200, loss = 0.474352\n",
      "Iteration  3300, loss = 0.474349\n",
      "Iteration  3400, loss = 0.474346\n",
      "Iteration  3500, loss = 0.474343\n",
      "Iteration  3600, loss = 0.474341\n",
      "Iteration  3700, loss = 0.474338\n",
      "Iteration  3800, loss = 0.474336\n",
      "Iteration  3900, loss = 0.474333\n",
      "Iteration  4000, loss = 0.474331\n",
      "Iteration  4100, loss = 0.474329\n",
      "Iteration  4200, loss = 0.474326\n",
      "Iteration  4300, loss = 0.474324\n",
      "Iteration  4400, loss = 0.474322\n",
      "Iteration  4500, loss = 0.474320\n",
      "Iteration  4600, loss = 0.474318\n",
      "Iteration  4700, loss = 0.474316\n",
      "Iteration  4800, loss = 0.474314\n",
      "Iteration  4900, loss = 0.474312\n",
      "Iteration  5000, loss = 0.474311\n",
      "Iteration  5100, loss = 0.474309\n",
      "Iteration  5200, loss = 0.474307\n",
      "Iteration  5300, loss = 0.474305\n",
      "Iteration  5400, loss = 0.474304\n",
      "Iteration  5500, loss = 0.474302\n",
      "Iteration  5600, loss = 0.474301\n",
      "Iteration  5700, loss = 0.474299\n",
      "Iteration  5800, loss = 0.474297\n",
      "Iteration  5900, loss = 0.474296\n",
      "Iteration  6000, loss = 0.474294\n",
      "Iteration  6100, loss = 0.474293\n",
      "Iteration  6200, loss = 0.474291\n",
      "Iteration  6300, loss = 0.474290\n",
      "Iteration  6400, loss = 0.474289\n",
      "Iteration  6500, loss = 0.474287\n",
      "Iteration  6600, loss = 0.474286\n",
      "Iteration  6700, loss = 0.474285\n",
      "Iteration  6800, loss = 0.474283\n",
      "Iteration  6900, loss = 0.474282\n",
      "Iteration  7000, loss = 0.474281\n",
      "Iteration  7100, loss = 0.474279\n",
      "Iteration  7200, loss = 0.474278\n",
      "Iteration  7300, loss = 0.474277\n",
      "Iteration  7400, loss = 0.474276\n",
      "Iteration  7500, loss = 0.474274\n",
      "Iteration  7600, loss = 0.474273\n",
      "Iteration  7700, loss = 0.474272\n",
      "Iteration  7800, loss = 0.474271\n",
      "Iteration  7900, loss = 0.474270\n",
      "Iteration  8000, loss = 0.474269\n",
      "Iteration  8100, loss = 0.474267\n",
      "Iteration  8200, loss = 0.474266\n",
      "Iteration  8300, loss = 0.474265\n",
      "Iteration  8400, loss = 0.474264\n",
      "Iteration  8500, loss = 0.474263\n",
      "Iteration  8600, loss = 0.474262\n",
      "Iteration  8700, loss = 0.474261\n",
      "Iteration  8800, loss = 0.474260\n",
      "Iteration  8900, loss = 0.474259\n",
      "Iteration  9000, loss = 0.474258\n",
      "Iteration  9100, loss = 0.474257\n",
      "Iteration  9200, loss = 0.474256\n",
      "Iteration  9300, loss = 0.474255\n",
      "Converged at iteration 9338\n",
      " Accuracy: 85.51%\n",
      " F1 Score: 0.4102\n",
      "\n",
      "Validation loss: 0.4887490605694057 f1 score 0.41022142281213125 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476176\n",
      "Iteration   200, loss = 0.475209\n",
      "Iteration   300, loss = 0.474908\n",
      "Iteration   400, loss = 0.474754\n",
      "Iteration   500, loss = 0.474662\n",
      "Iteration   600, loss = 0.474603\n",
      "Iteration   700, loss = 0.474562\n",
      "Iteration   800, loss = 0.474532\n",
      "Iteration   900, loss = 0.474508\n",
      "Iteration  1000, loss = 0.474490\n",
      "Iteration  1100, loss = 0.474474\n",
      "Iteration  1200, loss = 0.474461\n",
      "Iteration  1300, loss = 0.474450\n",
      "Iteration  1400, loss = 0.474440\n",
      "Iteration  1500, loss = 0.474432\n",
      "Iteration  1600, loss = 0.474424\n",
      "Iteration  1700, loss = 0.474417\n",
      "Iteration  1800, loss = 0.474410\n",
      "Iteration  1900, loss = 0.474404\n",
      "Iteration  2000, loss = 0.474399\n",
      "Iteration  2100, loss = 0.474393\n",
      "Iteration  2200, loss = 0.474388\n",
      "Iteration  2300, loss = 0.474384\n",
      "Iteration  2400, loss = 0.474380\n",
      "Iteration  2500, loss = 0.474375\n",
      "Iteration  2600, loss = 0.474372\n",
      "Iteration  2700, loss = 0.474368\n",
      "Iteration  2800, loss = 0.474364\n",
      "Iteration  2900, loss = 0.474361\n",
      "Iteration  3000, loss = 0.474358\n",
      "Iteration  3100, loss = 0.474355\n",
      "Iteration  3200, loss = 0.474352\n",
      "Iteration  3300, loss = 0.474349\n",
      "Iteration  3400, loss = 0.474346\n",
      "Iteration  3500, loss = 0.474343\n",
      "Iteration  3600, loss = 0.474341\n",
      "Iteration  3700, loss = 0.474338\n",
      "Iteration  3800, loss = 0.474336\n",
      "Iteration  3900, loss = 0.474333\n",
      "Iteration  4000, loss = 0.474331\n",
      "Iteration  4100, loss = 0.474329\n",
      "Iteration  4200, loss = 0.474326\n",
      "Iteration  4300, loss = 0.474324\n",
      "Iteration  4400, loss = 0.474322\n",
      "Iteration  4500, loss = 0.474320\n",
      "Iteration  4600, loss = 0.474318\n",
      "Iteration  4700, loss = 0.474316\n",
      "Iteration  4800, loss = 0.474314\n",
      "Iteration  4900, loss = 0.474312\n",
      "Iteration  5000, loss = 0.474311\n",
      "Iteration  5100, loss = 0.474309\n",
      "Iteration  5200, loss = 0.474307\n",
      "Iteration  5300, loss = 0.474305\n",
      "Iteration  5400, loss = 0.474304\n",
      "Iteration  5500, loss = 0.474302\n",
      "Iteration  5600, loss = 0.474301\n",
      "Iteration  5700, loss = 0.474299\n",
      "Iteration  5800, loss = 0.474297\n",
      "Iteration  5900, loss = 0.474296\n",
      "Iteration  6000, loss = 0.474294\n",
      "Iteration  6100, loss = 0.474293\n",
      "Iteration  6200, loss = 0.474291\n",
      "Iteration  6300, loss = 0.474290\n",
      "Iteration  6400, loss = 0.474289\n",
      "Iteration  6500, loss = 0.474287\n",
      "Iteration  6600, loss = 0.474286\n",
      "Iteration  6700, loss = 0.474285\n",
      "Iteration  6800, loss = 0.474283\n",
      "Iteration  6900, loss = 0.474282\n",
      "Iteration  7000, loss = 0.474281\n",
      "Iteration  7100, loss = 0.474279\n",
      "Iteration  7200, loss = 0.474278\n",
      "Iteration  7300, loss = 0.474277\n",
      "Iteration  7400, loss = 0.474276\n",
      "Iteration  7500, loss = 0.474274\n",
      "Iteration  7600, loss = 0.474273\n",
      "Iteration  7700, loss = 0.474272\n",
      "Iteration  7800, loss = 0.474271\n",
      "Iteration  7900, loss = 0.474270\n",
      "Iteration  8000, loss = 0.474269\n",
      "Iteration  8100, loss = 0.474267\n",
      "Iteration  8200, loss = 0.474266\n",
      "Iteration  8300, loss = 0.474265\n",
      "Iteration  8400, loss = 0.474264\n",
      "Iteration  8500, loss = 0.474263\n",
      "Iteration  8600, loss = 0.474262\n",
      "Iteration  8700, loss = 0.474261\n",
      "Iteration  8800, loss = 0.474260\n",
      "Iteration  8900, loss = 0.474259\n",
      "Iteration  9000, loss = 0.474258\n",
      "Iteration  9100, loss = 0.474257\n",
      "Iteration  9200, loss = 0.474256\n",
      "Iteration  9300, loss = 0.474255\n",
      "Converged at iteration 9338\n",
      " Accuracy: 85.51%\n",
      " F1 Score: 0.4102\n",
      "\n",
      "Validation loss: 0.4887490605694057 f1 score 0.41022142281213125 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476176\n",
      "Iteration   200, loss = 0.475209\n",
      "Iteration   300, loss = 0.474908\n",
      "Iteration   400, loss = 0.474754\n",
      "Iteration   500, loss = 0.474662\n",
      "Iteration   600, loss = 0.474603\n",
      "Iteration   700, loss = 0.474562\n",
      "Iteration   800, loss = 0.474532\n",
      "Iteration   900, loss = 0.474508\n",
      "Iteration  1000, loss = 0.474490\n",
      "Iteration  1100, loss = 0.474474\n",
      "Iteration  1200, loss = 0.474461\n",
      "Iteration  1300, loss = 0.474450\n",
      "Iteration  1400, loss = 0.474440\n",
      "Iteration  1500, loss = 0.474432\n",
      "Iteration  1600, loss = 0.474424\n",
      "Iteration  1700, loss = 0.474417\n",
      "Iteration  1800, loss = 0.474410\n",
      "Iteration  1900, loss = 0.474404\n",
      "Iteration  2000, loss = 0.474399\n",
      "Iteration  2100, loss = 0.474393\n",
      "Iteration  2200, loss = 0.474388\n",
      "Iteration  2300, loss = 0.474384\n",
      "Iteration  2400, loss = 0.474380\n",
      "Iteration  2500, loss = 0.474375\n",
      "Iteration  2600, loss = 0.474372\n",
      "Iteration  2700, loss = 0.474368\n",
      "Iteration  2800, loss = 0.474364\n",
      "Iteration  2900, loss = 0.474361\n",
      "Iteration  3000, loss = 0.474358\n",
      "Iteration  3100, loss = 0.474355\n",
      "Iteration  3200, loss = 0.474352\n",
      "Iteration  3300, loss = 0.474349\n",
      "Iteration  3400, loss = 0.474346\n",
      "Iteration  3500, loss = 0.474343\n",
      "Iteration  3600, loss = 0.474341\n",
      "Iteration  3700, loss = 0.474338\n",
      "Iteration  3800, loss = 0.474336\n",
      "Iteration  3900, loss = 0.474333\n",
      "Iteration  4000, loss = 0.474331\n",
      "Iteration  4100, loss = 0.474329\n",
      "Iteration  4200, loss = 0.474326\n",
      "Iteration  4300, loss = 0.474324\n",
      "Iteration  4400, loss = 0.474322\n",
      "Iteration  4500, loss = 0.474320\n",
      "Iteration  4600, loss = 0.474318\n",
      "Iteration  4700, loss = 0.474316\n",
      "Iteration  4800, loss = 0.474314\n",
      "Iteration  4900, loss = 0.474312\n",
      "Iteration  5000, loss = 0.474311\n",
      "Iteration  5100, loss = 0.474309\n",
      "Iteration  5200, loss = 0.474307\n",
      "Iteration  5300, loss = 0.474305\n",
      "Iteration  5400, loss = 0.474304\n",
      "Iteration  5500, loss = 0.474302\n",
      "Iteration  5600, loss = 0.474301\n",
      "Iteration  5700, loss = 0.474299\n",
      "Iteration  5800, loss = 0.474297\n",
      "Iteration  5900, loss = 0.474296\n",
      "Iteration  6000, loss = 0.474294\n",
      "Iteration  6100, loss = 0.474293\n",
      "Iteration  6200, loss = 0.474291\n",
      "Iteration  6300, loss = 0.474290\n",
      "Iteration  6400, loss = 0.474289\n",
      "Iteration  6500, loss = 0.474287\n",
      "Iteration  6600, loss = 0.474286\n",
      "Iteration  6700, loss = 0.474285\n",
      "Iteration  6800, loss = 0.474283\n",
      "Iteration  6900, loss = 0.474282\n",
      "Iteration  7000, loss = 0.474281\n",
      "Iteration  7100, loss = 0.474279\n",
      "Iteration  7200, loss = 0.474278\n",
      "Iteration  7300, loss = 0.474277\n",
      "Iteration  7400, loss = 0.474276\n",
      "Iteration  7500, loss = 0.474274\n",
      "Iteration  7600, loss = 0.474273\n",
      "Iteration  7700, loss = 0.474272\n",
      "Iteration  7800, loss = 0.474271\n",
      "Iteration  7900, loss = 0.474270\n",
      "Iteration  8000, loss = 0.474269\n",
      "Iteration  8100, loss = 0.474267\n",
      "Iteration  8200, loss = 0.474266\n",
      "Iteration  8300, loss = 0.474265\n",
      "Iteration  8400, loss = 0.474264\n",
      "Iteration  8500, loss = 0.474263\n",
      "Iteration  8600, loss = 0.474262\n",
      "Iteration  8700, loss = 0.474261\n",
      "Iteration  8800, loss = 0.474260\n",
      "Iteration  8900, loss = 0.474259\n",
      "Iteration  9000, loss = 0.474258\n",
      "Iteration  9100, loss = 0.474257\n",
      "Iteration  9200, loss = 0.474256\n",
      "Iteration  9300, loss = 0.474255\n",
      "Converged at iteration 9338\n",
      " Accuracy: 85.51%\n",
      " F1 Score: 0.4102\n",
      "\n",
      "Validation loss: 0.4887490605694057 f1 score 0.41022142281213125 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476176\n",
      "Iteration   200, loss = 0.475209\n",
      "Iteration   300, loss = 0.474908\n",
      "Iteration   400, loss = 0.474754\n",
      "Iteration   500, loss = 0.474662\n",
      "Iteration   600, loss = 0.474603\n",
      "Iteration   700, loss = 0.474562\n",
      "Iteration   800, loss = 0.474532\n",
      "Iteration   900, loss = 0.474508\n",
      "Iteration  1000, loss = 0.474490\n",
      "Iteration  1100, loss = 0.474474\n",
      "Iteration  1200, loss = 0.474461\n",
      "Iteration  1300, loss = 0.474450\n",
      "Iteration  1400, loss = 0.474440\n",
      "Iteration  1500, loss = 0.474432\n",
      "Iteration  1600, loss = 0.474424\n",
      "Iteration  1700, loss = 0.474417\n",
      "Iteration  1800, loss = 0.474410\n",
      "Iteration  1900, loss = 0.474404\n",
      "Iteration  2000, loss = 0.474399\n",
      "Iteration  2100, loss = 0.474393\n",
      "Iteration  2200, loss = 0.474388\n",
      "Iteration  2300, loss = 0.474384\n",
      "Iteration  2400, loss = 0.474380\n",
      "Iteration  2500, loss = 0.474375\n",
      "Iteration  2600, loss = 0.474372\n",
      "Iteration  2700, loss = 0.474368\n",
      "Iteration  2800, loss = 0.474364\n",
      "Iteration  2900, loss = 0.474361\n",
      "Iteration  3000, loss = 0.474358\n",
      "Iteration  3100, loss = 0.474355\n",
      "Iteration  3200, loss = 0.474352\n",
      "Iteration  3300, loss = 0.474349\n",
      "Iteration  3400, loss = 0.474346\n",
      "Iteration  3500, loss = 0.474343\n",
      "Iteration  3600, loss = 0.474341\n",
      "Iteration  3700, loss = 0.474338\n",
      "Iteration  3800, loss = 0.474336\n",
      "Iteration  3900, loss = 0.474333\n",
      "Iteration  4000, loss = 0.474331\n",
      "Iteration  4100, loss = 0.474329\n",
      "Iteration  4200, loss = 0.474326\n",
      "Iteration  4300, loss = 0.474324\n",
      "Iteration  4400, loss = 0.474322\n",
      "Iteration  4500, loss = 0.474320\n",
      "Iteration  4600, loss = 0.474318\n",
      "Iteration  4700, loss = 0.474316\n",
      "Iteration  4800, loss = 0.474314\n",
      "Iteration  4900, loss = 0.474312\n",
      "Iteration  5000, loss = 0.474311\n",
      "Iteration  5100, loss = 0.474309\n",
      "Iteration  5200, loss = 0.474307\n",
      "Iteration  5300, loss = 0.474305\n",
      "Iteration  5400, loss = 0.474304\n",
      "Iteration  5500, loss = 0.474302\n",
      "Iteration  5600, loss = 0.474301\n",
      "Iteration  5700, loss = 0.474299\n",
      "Iteration  5800, loss = 0.474297\n",
      "Iteration  5900, loss = 0.474296\n",
      "Iteration  6000, loss = 0.474294\n",
      "Iteration  6100, loss = 0.474293\n",
      "Iteration  6200, loss = 0.474291\n",
      "Iteration  6300, loss = 0.474290\n",
      "Iteration  6400, loss = 0.474289\n",
      "Iteration  6500, loss = 0.474287\n",
      "Iteration  6600, loss = 0.474286\n",
      "Iteration  6700, loss = 0.474285\n",
      "Iteration  6800, loss = 0.474283\n",
      "Iteration  6900, loss = 0.474282\n",
      "Iteration  7000, loss = 0.474281\n",
      "Iteration  7100, loss = 0.474279\n",
      "Iteration  7200, loss = 0.474278\n",
      "Iteration  7300, loss = 0.474277\n",
      "Iteration  7400, loss = 0.474276\n",
      "Iteration  7500, loss = 0.474274\n",
      "Iteration  7600, loss = 0.474273\n",
      "Iteration  7700, loss = 0.474272\n",
      "Iteration  7800, loss = 0.474271\n",
      "Iteration  7900, loss = 0.474270\n",
      "Iteration  8000, loss = 0.474269\n",
      "Iteration  8100, loss = 0.474267\n",
      "Iteration  8200, loss = 0.474266\n",
      "Iteration  8300, loss = 0.474265\n",
      "Iteration  8400, loss = 0.474264\n",
      "Iteration  8500, loss = 0.474263\n",
      "Iteration  8600, loss = 0.474262\n",
      "Iteration  8700, loss = 0.474261\n",
      "Iteration  8800, loss = 0.474260\n",
      "Iteration  8900, loss = 0.474259\n",
      "Iteration  9000, loss = 0.474258\n",
      "Iteration  9100, loss = 0.474257\n",
      "Iteration  9200, loss = 0.474256\n",
      "Iteration  9300, loss = 0.474255\n",
      "Converged at iteration 9338\n",
      " Accuracy: 85.51%\n",
      " F1 Score: 0.4102\n",
      "\n",
      "Validation loss: 0.4887490605694057 f1 score 0.41022142281213125 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476176\n",
      "Iteration   200, loss = 0.475209\n",
      "Iteration   300, loss = 0.474908\n",
      "Iteration   400, loss = 0.474754\n",
      "Iteration   500, loss = 0.474662\n",
      "Iteration   600, loss = 0.474603\n",
      "Iteration   700, loss = 0.474562\n",
      "Iteration   800, loss = 0.474532\n",
      "Iteration   900, loss = 0.474508\n",
      "Iteration  1000, loss = 0.474490\n",
      "Iteration  1100, loss = 0.474474\n",
      "Iteration  1200, loss = 0.474461\n",
      "Iteration  1300, loss = 0.474450\n",
      "Iteration  1400, loss = 0.474440\n",
      "Iteration  1500, loss = 0.474432\n",
      "Iteration  1600, loss = 0.474424\n",
      "Iteration  1700, loss = 0.474417\n",
      "Iteration  1800, loss = 0.474410\n",
      "Iteration  1900, loss = 0.474404\n",
      "Iteration  2000, loss = 0.474399\n",
      "Iteration  2100, loss = 0.474393\n",
      "Iteration  2200, loss = 0.474388\n",
      "Iteration  2300, loss = 0.474384\n",
      "Iteration  2400, loss = 0.474380\n",
      "Iteration  2500, loss = 0.474375\n",
      "Iteration  2600, loss = 0.474372\n",
      "Iteration  2700, loss = 0.474368\n",
      "Iteration  2800, loss = 0.474364\n",
      "Iteration  2900, loss = 0.474361\n",
      "Iteration  3000, loss = 0.474358\n",
      "Iteration  3100, loss = 0.474355\n",
      "Iteration  3200, loss = 0.474352\n",
      "Iteration  3300, loss = 0.474349\n",
      "Iteration  3400, loss = 0.474346\n",
      "Iteration  3500, loss = 0.474343\n",
      "Iteration  3600, loss = 0.474341\n",
      "Iteration  3700, loss = 0.474338\n",
      "Iteration  3800, loss = 0.474336\n",
      "Iteration  3900, loss = 0.474333\n",
      "Iteration  4000, loss = 0.474331\n",
      "Iteration  4100, loss = 0.474329\n",
      "Iteration  4200, loss = 0.474326\n",
      "Iteration  4300, loss = 0.474324\n",
      "Iteration  4400, loss = 0.474322\n",
      "Iteration  4500, loss = 0.474320\n",
      "Iteration  4600, loss = 0.474318\n",
      "Iteration  4700, loss = 0.474316\n",
      "Iteration  4800, loss = 0.474314\n",
      "Iteration  4900, loss = 0.474312\n",
      "Iteration  5000, loss = 0.474311\n",
      "Iteration  5100, loss = 0.474309\n",
      "Iteration  5200, loss = 0.474307\n",
      "Iteration  5300, loss = 0.474305\n",
      "Iteration  5400, loss = 0.474304\n",
      "Iteration  5500, loss = 0.474302\n",
      "Iteration  5600, loss = 0.474301\n",
      "Iteration  5700, loss = 0.474299\n",
      "Iteration  5800, loss = 0.474297\n",
      "Iteration  5900, loss = 0.474296\n",
      "Iteration  6000, loss = 0.474294\n",
      "Iteration  6100, loss = 0.474293\n",
      "Iteration  6200, loss = 0.474291\n",
      "Iteration  6300, loss = 0.474290\n",
      "Iteration  6400, loss = 0.474289\n",
      "Iteration  6500, loss = 0.474287\n",
      "Iteration  6600, loss = 0.474286\n",
      "Iteration  6700, loss = 0.474285\n",
      "Iteration  6800, loss = 0.474283\n",
      "Iteration  6900, loss = 0.474282\n",
      "Iteration  7000, loss = 0.474281\n",
      "Iteration  7100, loss = 0.474279\n",
      "Iteration  7200, loss = 0.474278\n",
      "Iteration  7300, loss = 0.474277\n",
      "Iteration  7400, loss = 0.474276\n",
      "Iteration  7500, loss = 0.474274\n",
      "Iteration  7600, loss = 0.474273\n",
      "Iteration  7700, loss = 0.474272\n",
      "Iteration  7800, loss = 0.474271\n",
      "Iteration  7900, loss = 0.474270\n",
      "Iteration  8000, loss = 0.474269\n",
      "Iteration  8100, loss = 0.474267\n",
      "Iteration  8200, loss = 0.474266\n",
      "Iteration  8300, loss = 0.474265\n",
      "Iteration  8400, loss = 0.474264\n",
      "Iteration  8500, loss = 0.474263\n",
      "Iteration  8600, loss = 0.474262\n",
      "Iteration  8700, loss = 0.474261\n",
      "Iteration  8800, loss = 0.474260\n",
      "Iteration  8900, loss = 0.474259\n",
      "Iteration  9000, loss = 0.474258\n",
      "Iteration  9100, loss = 0.474257\n",
      "Iteration  9200, loss = 0.474256\n",
      "Iteration  9300, loss = 0.474255\n",
      "Converged at iteration 9338\n",
      " Accuracy: 85.51%\n",
      " F1 Score: 0.4102\n",
      "\n",
      "Validation loss: 0.4887490605694057 f1 score 0.41022142281213125 with data size of 46564\n",
      "For lambda: 1e-06 best f1: 0.41022142281213125\n",
      "Before preprocess (262508, 321) (262508,)\n",
      "Number of removes features due to NaN values: 117\n",
      "After preprocess (46564, 204) (46564,)\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.469541\n",
      "Iteration   200, loss = 0.468464\n",
      "Iteration   300, loss = 0.468142\n",
      "Iteration   400, loss = 0.467993\n",
      "Iteration   500, loss = 0.467915\n",
      "Iteration   600, loss = 0.467871\n",
      "Iteration   700, loss = 0.467844\n",
      "Iteration   800, loss = 0.467827\n",
      "Iteration   900, loss = 0.467816\n",
      "Iteration  1000, loss = 0.467809\n",
      "Iteration  1100, loss = 0.467804\n",
      "Iteration  1200, loss = 0.467800\n",
      "Iteration  1300, loss = 0.467797\n",
      "Iteration  1400, loss = 0.467795\n",
      "Iteration  1500, loss = 0.467794\n",
      "Converged at iteration 1565\n",
      " Accuracy: 84.97%\n",
      " F1 Score: 0.4015\n",
      "\n",
      "Validation loss: 0.4975659857783748 f1 score 0.40150503701905527 with data size of 13125\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.470834\n",
      "Iteration   200, loss = 0.469848\n",
      "Iteration   300, loss = 0.469563\n",
      "Iteration   400, loss = 0.469434\n",
      "Iteration   500, loss = 0.469366\n",
      "Iteration   600, loss = 0.469328\n",
      "Iteration   700, loss = 0.469305\n",
      "Iteration   800, loss = 0.469291\n",
      "Iteration   900, loss = 0.469281\n",
      "Iteration  1000, loss = 0.469275\n",
      "Iteration  1100, loss = 0.469270\n",
      "Iteration  1200, loss = 0.469267\n",
      "Iteration  1300, loss = 0.469265\n",
      "Iteration  1400, loss = 0.469263\n",
      "Iteration  1500, loss = 0.469262\n",
      "Converged at iteration 1517\n",
      " Accuracy: 85.06%\n",
      " F1 Score: 0.4014\n",
      "\n",
      "Validation loss: 0.4964837955213607 f1 score 0.4014406934863557 with data size of 13816\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.471229\n",
      "Iteration   200, loss = 0.470279\n",
      "Iteration   300, loss = 0.470004\n",
      "Iteration   400, loss = 0.469879\n",
      "Iteration   500, loss = 0.469814\n",
      "Iteration   600, loss = 0.469778\n",
      "Iteration   700, loss = 0.469757\n",
      "Iteration   800, loss = 0.469744\n",
      "Iteration   900, loss = 0.469735\n",
      "Iteration  1000, loss = 0.469729\n",
      "Iteration  1100, loss = 0.469725\n",
      "Iteration  1200, loss = 0.469722\n",
      "Iteration  1300, loss = 0.469720\n",
      "Iteration  1400, loss = 0.469718\n",
      "Converged at iteration 1492\n",
      " Accuracy: 85.09%\n",
      " F1 Score: 0.4037\n",
      "\n",
      "Validation loss: 0.49639051949674273 f1 score 0.403680906819428 with data size of 14583\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472209\n",
      "Iteration   200, loss = 0.471226\n",
      "Iteration   300, loss = 0.470933\n",
      "Iteration   400, loss = 0.470800\n",
      "Iteration   500, loss = 0.470732\n",
      "Iteration   600, loss = 0.470694\n",
      "Iteration   700, loss = 0.470671\n",
      "Iteration   800, loss = 0.470657\n",
      "Iteration   900, loss = 0.470647\n",
      "Iteration  1000, loss = 0.470641\n",
      "Iteration  1100, loss = 0.470636\n",
      "Iteration  1200, loss = 0.470633\n",
      "Iteration  1300, loss = 0.470631\n",
      "Iteration  1400, loss = 0.470629\n",
      "Iteration  1500, loss = 0.470628\n",
      "Converged at iteration 1517\n",
      " Accuracy: 85.23%\n",
      " F1 Score: 0.4041\n",
      "\n",
      "Validation loss: 0.49460304909378294 f1 score 0.40413106288805506 with data size of 15441\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472484\n",
      "Iteration   200, loss = 0.471486\n",
      "Iteration   300, loss = 0.471197\n",
      "Iteration   400, loss = 0.471069\n",
      "Iteration   500, loss = 0.471003\n",
      "Iteration   600, loss = 0.470967\n",
      "Iteration   700, loss = 0.470946\n",
      "Iteration   800, loss = 0.470933\n",
      "Iteration   900, loss = 0.470924\n",
      "Iteration  1000, loss = 0.470918\n",
      "Iteration  1100, loss = 0.470914\n",
      "Iteration  1200, loss = 0.470911\n",
      "Iteration  1300, loss = 0.470909\n",
      "Iteration  1400, loss = 0.470907\n",
      "Converged at iteration 1498\n",
      " Accuracy: 85.25%\n",
      " F1 Score: 0.4037\n",
      "\n",
      "Validation loss: 0.493137018390451 f1 score 0.4037217327007205 with data size of 16406\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473617\n",
      "Iteration   200, loss = 0.472692\n",
      "Iteration   300, loss = 0.472432\n",
      "Iteration   400, loss = 0.472317\n",
      "Iteration   500, loss = 0.472259\n",
      "Iteration   600, loss = 0.472228\n",
      "Iteration   700, loss = 0.472209\n",
      "Iteration   800, loss = 0.472197\n",
      "Iteration   900, loss = 0.472189\n",
      "Iteration  1000, loss = 0.472184\n",
      "Iteration  1100, loss = 0.472180\n",
      "Iteration  1200, loss = 0.472178\n",
      "Iteration  1300, loss = 0.472176\n",
      "Iteration  1400, loss = 0.472175\n",
      "Converged at iteration 1457\n",
      " Accuracy: 85.27%\n",
      " F1 Score: 0.4039\n",
      "\n",
      "Validation loss: 0.49319467859538474 f1 score 0.4038983469035278 with data size of 17500\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473521\n",
      "Iteration   200, loss = 0.472671\n",
      "Iteration   300, loss = 0.472448\n",
      "Iteration   400, loss = 0.472353\n",
      "Iteration   500, loss = 0.472306\n",
      "Iteration   600, loss = 0.472279\n",
      "Iteration   700, loss = 0.472264\n",
      "Iteration   800, loss = 0.472254\n",
      "Iteration   900, loss = 0.472248\n",
      "Iteration  1000, loss = 0.472244\n",
      "Iteration  1100, loss = 0.472241\n",
      "Iteration  1200, loss = 0.472238\n",
      "Iteration  1300, loss = 0.472237\n",
      "Iteration  1400, loss = 0.472235\n",
      "Converged at iteration 1415\n",
      " Accuracy: 85.42%\n",
      " F1 Score: 0.4049\n",
      "\n",
      "Validation loss: 0.49008101153598105 f1 score 0.4048759251197209 with data size of 18750\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473824\n",
      "Iteration   200, loss = 0.472995\n",
      "Iteration   300, loss = 0.472780\n",
      "Iteration   400, loss = 0.472689\n",
      "Iteration   500, loss = 0.472645\n",
      "Iteration   600, loss = 0.472622\n",
      "Iteration   700, loss = 0.472609\n",
      "Iteration   800, loss = 0.472600\n",
      "Iteration   900, loss = 0.472595\n",
      "Iteration  1000, loss = 0.472592\n",
      "Iteration  1100, loss = 0.472589\n",
      "Iteration  1200, loss = 0.472587\n",
      "Iteration  1300, loss = 0.472586\n",
      "Converged at iteration 1328\n",
      " Accuracy: 85.41%\n",
      " F1 Score: 0.4055\n",
      "\n",
      "Validation loss: 0.49100327787991327 f1 score 0.4054624456859089 with data size of 20192\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475450\n",
      "Iteration   200, loss = 0.474632\n",
      "Iteration   300, loss = 0.474414\n",
      "Iteration   400, loss = 0.474322\n",
      "Iteration   500, loss = 0.474278\n",
      "Iteration   600, loss = 0.474255\n",
      "Iteration   700, loss = 0.474241\n",
      "Iteration   800, loss = 0.474233\n",
      "Iteration   900, loss = 0.474228\n",
      "Iteration  1000, loss = 0.474224\n",
      "Iteration  1100, loss = 0.474222\n",
      "Iteration  1200, loss = 0.474220\n",
      "Iteration  1300, loss = 0.474219\n",
      "Converged at iteration 1332\n",
      " Accuracy: 85.48%\n",
      " F1 Score: 0.4058\n",
      "\n",
      "Validation loss: 0.4897509789251876 f1 score 0.4058115607657288 with data size of 21875\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475696\n",
      "Iteration   200, loss = 0.474911\n",
      "Iteration   300, loss = 0.474704\n",
      "Iteration   400, loss = 0.474617\n",
      "Iteration   500, loss = 0.474575\n",
      "Iteration   600, loss = 0.474553\n",
      "Iteration   700, loss = 0.474541\n",
      "Iteration   800, loss = 0.474533\n",
      "Iteration   900, loss = 0.474529\n",
      "Iteration  1000, loss = 0.474525\n",
      "Iteration  1100, loss = 0.474523\n",
      "Iteration  1200, loss = 0.474521\n",
      "Iteration  1300, loss = 0.474520\n",
      "Converged at iteration 1301\n",
      " Accuracy: 85.46%\n",
      " F1 Score: 0.4065\n",
      "\n",
      "Validation loss: 0.49162885664459954 f1 score 0.40651822365965873 with data size of 23864\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475591\n",
      "Iteration   200, loss = 0.474805\n",
      "Iteration   300, loss = 0.474600\n",
      "Iteration   400, loss = 0.474515\n",
      "Iteration   500, loss = 0.474474\n",
      "Iteration   600, loss = 0.474453\n",
      "Iteration   700, loss = 0.474441\n",
      "Iteration   800, loss = 0.474433\n",
      "Iteration   900, loss = 0.474428\n",
      "Iteration  1000, loss = 0.474425\n",
      "Iteration  1100, loss = 0.474423\n",
      "Iteration  1200, loss = 0.474421\n",
      "Iteration  1300, loss = 0.474420\n",
      "Converged at iteration 1310\n",
      " Accuracy: 85.45%\n",
      " F1 Score: 0.4059\n",
      "\n",
      "Validation loss: 0.49165061452913456 f1 score 0.40592334494773474 with data size of 26250\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475527\n",
      "Iteration   200, loss = 0.474757\n",
      "Iteration   300, loss = 0.474556\n",
      "Iteration   400, loss = 0.474473\n",
      "Iteration   500, loss = 0.474434\n",
      "Iteration   600, loss = 0.474413\n",
      "Iteration   700, loss = 0.474402\n",
      "Iteration   800, loss = 0.474395\n",
      "Iteration   900, loss = 0.474390\n",
      "Iteration  1000, loss = 0.474388\n",
      "Iteration  1100, loss = 0.474386\n",
      "Iteration  1200, loss = 0.474384\n",
      "Converged at iteration 1257\n",
      " Accuracy: 85.41%\n",
      " F1 Score: 0.4066\n",
      "\n",
      "Validation loss: 0.4920635900101649 f1 score 0.40659272569551974 with data size of 29167\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477016\n",
      "Iteration   200, loss = 0.476266\n",
      "Iteration   300, loss = 0.476072\n",
      "Iteration   400, loss = 0.475993\n",
      "Iteration   500, loss = 0.475956\n",
      "Iteration   600, loss = 0.475937\n",
      "Iteration   700, loss = 0.475927\n",
      "Iteration   800, loss = 0.475921\n",
      "Iteration   900, loss = 0.475917\n",
      "Iteration  1000, loss = 0.475915\n",
      "Iteration  1100, loss = 0.475913\n",
      "Converged at iteration 1177\n",
      " Accuracy: 85.46%\n",
      " F1 Score: 0.4075\n",
      "\n",
      "Validation loss: 0.49284007385461837 f1 score 0.40754763825957374 with data size of 32813\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478060\n",
      "Iteration   200, loss = 0.477324\n",
      "Iteration   300, loss = 0.477132\n",
      "Iteration   400, loss = 0.477051\n",
      "Iteration   500, loss = 0.477013\n",
      "Iteration   600, loss = 0.476994\n",
      "Iteration   700, loss = 0.476983\n",
      "Iteration   800, loss = 0.476977\n",
      "Iteration   900, loss = 0.476973\n",
      "Iteration  1000, loss = 0.476971\n",
      "Iteration  1100, loss = 0.476969\n",
      "Converged at iteration 1199\n",
      " Accuracy: 85.48%\n",
      " F1 Score: 0.4073\n",
      "\n",
      "Validation loss: 0.4934755218567446 f1 score 0.40728765078970236 with data size of 37501\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479620\n",
      "Iteration   200, loss = 0.478913\n",
      "Iteration   300, loss = 0.478730\n",
      "Iteration   400, loss = 0.478654\n",
      "Iteration   500, loss = 0.478618\n",
      "Iteration   600, loss = 0.478600\n",
      "Iteration   700, loss = 0.478589\n",
      "Iteration   800, loss = 0.478583\n",
      "Iteration   900, loss = 0.478579\n",
      "Iteration  1000, loss = 0.478577\n",
      "Iteration  1100, loss = 0.478575\n",
      "Iteration  1200, loss = 0.478574\n",
      "Converged at iteration 1217\n",
      " Accuracy: 85.53%\n",
      " F1 Score: 0.4087\n",
      "\n",
      "Validation loss: 0.49218357374453264 f1 score 0.4087145969498906 with data size of 43751\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479763\n",
      "Iteration   200, loss = 0.479076\n",
      "Iteration   300, loss = 0.478898\n",
      "Iteration   400, loss = 0.478823\n",
      "Iteration   500, loss = 0.478787\n",
      "Iteration   600, loss = 0.478768\n",
      "Iteration   700, loss = 0.478757\n",
      "Iteration   800, loss = 0.478751\n",
      "Iteration   900, loss = 0.478747\n",
      "Iteration  1000, loss = 0.478744\n",
      "Iteration  1100, loss = 0.478742\n",
      "Iteration  1200, loss = 0.478741\n",
      "Converged at iteration 1239\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4094\n",
      "\n",
      "Validation loss: 0.49285419470044584 f1 score 0.4094252586959227 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479763\n",
      "Iteration   200, loss = 0.479076\n",
      "Iteration   300, loss = 0.478898\n",
      "Iteration   400, loss = 0.478823\n",
      "Iteration   500, loss = 0.478787\n",
      "Iteration   600, loss = 0.478768\n",
      "Iteration   700, loss = 0.478757\n",
      "Iteration   800, loss = 0.478751\n",
      "Iteration   900, loss = 0.478747\n",
      "Iteration  1000, loss = 0.478744\n",
      "Iteration  1100, loss = 0.478742\n",
      "Iteration  1200, loss = 0.478741\n",
      "Converged at iteration 1239\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4094\n",
      "\n",
      "Validation loss: 0.49285419470044584 f1 score 0.4094252586959227 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479763\n",
      "Iteration   200, loss = 0.479076\n",
      "Iteration   300, loss = 0.478898\n",
      "Iteration   400, loss = 0.478823\n",
      "Iteration   500, loss = 0.478787\n",
      "Iteration   600, loss = 0.478768\n",
      "Iteration   700, loss = 0.478757\n",
      "Iteration   800, loss = 0.478751\n",
      "Iteration   900, loss = 0.478747\n",
      "Iteration  1000, loss = 0.478744\n",
      "Iteration  1100, loss = 0.478742\n",
      "Iteration  1200, loss = 0.478741\n",
      "Converged at iteration 1239\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4094\n",
      "\n",
      "Validation loss: 0.49285419470044584 f1 score 0.4094252586959227 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479763\n",
      "Iteration   200, loss = 0.479076\n",
      "Iteration   300, loss = 0.478898\n",
      "Iteration   400, loss = 0.478823\n",
      "Iteration   500, loss = 0.478787\n",
      "Iteration   600, loss = 0.478768\n",
      "Iteration   700, loss = 0.478757\n",
      "Iteration   800, loss = 0.478751\n",
      "Iteration   900, loss = 0.478747\n",
      "Iteration  1000, loss = 0.478744\n",
      "Iteration  1100, loss = 0.478742\n",
      "Iteration  1200, loss = 0.478741\n",
      "Converged at iteration 1239\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4094\n",
      "\n",
      "Validation loss: 0.49285419470044584 f1 score 0.4094252586959227 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479763\n",
      "Iteration   200, loss = 0.479076\n",
      "Iteration   300, loss = 0.478898\n",
      "Iteration   400, loss = 0.478823\n",
      "Iteration   500, loss = 0.478787\n",
      "Iteration   600, loss = 0.478768\n",
      "Iteration   700, loss = 0.478757\n",
      "Iteration   800, loss = 0.478751\n",
      "Iteration   900, loss = 0.478747\n",
      "Iteration  1000, loss = 0.478744\n",
      "Iteration  1100, loss = 0.478742\n",
      "Iteration  1200, loss = 0.478741\n",
      "Converged at iteration 1239\n",
      " Accuracy: 85.56%\n",
      " F1 Score: 0.4094\n",
      "\n",
      "Validation loss: 0.49285419470044584 f1 score 0.4094252586959227 with data size of 46564\n",
      "For lambda: 0.001 best f1: 0.4094252586959227\n",
      "Before preprocess (262508, 321) (262508,)\n",
      "Number of removes features due to NaN values: 117\n",
      "After preprocess (46564, 204) (46564,)\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.356835\n",
      "Iteration   200, loss = 1.356835\n",
      "Iteration   300, loss = 1.356835\n",
      "Iteration   400, loss = 1.356835\n",
      "Iteration   500, loss = 1.356835\n",
      "Iteration   600, loss = 1.356835\n",
      "Iteration   700, loss = 1.356835\n",
      "Iteration   800, loss = 1.356835\n",
      "Iteration   900, loss = 1.356835\n",
      "Iteration  1000, loss = 1.356835\n",
      "Iteration  1100, loss = 1.356835\n",
      "Iteration  1200, loss = 1.356835\n",
      "Iteration  1300, loss = 1.356835\n",
      "Iteration  1400, loss = 1.356835\n",
      "Iteration  1500, loss = 1.356835\n",
      "Iteration  1600, loss = 1.356835\n",
      "Iteration  1700, loss = 1.356835\n",
      "Iteration  1800, loss = 1.356835\n",
      "Iteration  1900, loss = 1.356835\n",
      "Iteration  2000, loss = 1.356835\n",
      "Iteration  2100, loss = 1.356835\n",
      "Iteration  2200, loss = 1.356835\n",
      "Iteration  2300, loss = 1.356835\n",
      "Iteration  2400, loss = 1.356835\n",
      "Iteration  2500, loss = 1.356835\n",
      "Iteration  2600, loss = 1.356835\n",
      "Iteration  2700, loss = 1.356835\n",
      "Iteration  2800, loss = 1.356835\n",
      "Iteration  2900, loss = 1.356835\n",
      "Iteration  3000, loss = 1.356835\n",
      "Iteration  3100, loss = 1.356835\n",
      "Iteration  3200, loss = 1.356835\n",
      "Iteration  3300, loss = 1.356835\n",
      "Iteration  3400, loss = 1.356835\n",
      "Iteration  3500, loss = 1.356835\n",
      "Iteration  3600, loss = 1.356835\n",
      "Iteration  3700, loss = 1.356835\n",
      "Iteration  3800, loss = 1.356835\n",
      "Iteration  3900, loss = 1.356835\n",
      "Iteration  4000, loss = 1.356835\n",
      "Iteration  4100, loss = 1.356835\n",
      "Iteration  4200, loss = 1.356835\n",
      "Iteration  4300, loss = 1.356835\n",
      "Iteration  4400, loss = 1.356835\n",
      "Iteration  4500, loss = 1.356835\n",
      "Iteration  4600, loss = 1.356835\n",
      "Iteration  4700, loss = 1.356835\n",
      "Iteration  4800, loss = 1.356835\n",
      "Iteration  4900, loss = 1.356835\n",
      "Iteration  5000, loss = 1.356835\n",
      "Iteration  5100, loss = 1.356835\n",
      "Iteration  5200, loss = 1.356835\n",
      "Iteration  5300, loss = 1.356835\n",
      "Iteration  5400, loss = 1.356835\n",
      "Iteration  5500, loss = 1.356835\n",
      "Iteration  5600, loss = 1.356835\n",
      "Iteration  5700, loss = 1.356835\n",
      "Iteration  5800, loss = 1.356835\n",
      "Iteration  5900, loss = 1.356835\n",
      "Iteration  6000, loss = 1.356835\n",
      "Iteration  6100, loss = 1.356835\n",
      "Iteration  6200, loss = 1.356835\n",
      "Iteration  6300, loss = 1.356835\n",
      "Iteration  6400, loss = 1.356835\n",
      "Iteration  6500, loss = 1.356835\n",
      "Iteration  6600, loss = 1.356835\n",
      "Iteration  6700, loss = 1.356835\n",
      "Iteration  6800, loss = 1.356835\n",
      "Iteration  6900, loss = 1.356835\n",
      "Iteration  7000, loss = 1.356835\n",
      "Iteration  7100, loss = 1.356835\n",
      "Iteration  7200, loss = 1.356835\n",
      "Iteration  7300, loss = 1.356835\n",
      "Iteration  7400, loss = 1.356835\n",
      "Iteration  7500, loss = 1.356835\n",
      "Iteration  7600, loss = 1.356835\n",
      "Iteration  7700, loss = 1.356835\n",
      "Iteration  7800, loss = 1.356835\n",
      "Iteration  7900, loss = 1.356835\n",
      "Iteration  8000, loss = 1.356835\n",
      "Iteration  8100, loss = 1.356835\n",
      "Iteration  8200, loss = 1.356835\n",
      "Iteration  8300, loss = 1.356835\n",
      "Iteration  8400, loss = 1.356835\n",
      "Iteration  8500, loss = 1.356835\n",
      "Iteration  8600, loss = 1.356835\n",
      "Iteration  8700, loss = 1.356835\n",
      "Iteration  8800, loss = 1.356835\n",
      "Iteration  8900, loss = 1.356835\n",
      "Iteration  9000, loss = 1.356835\n",
      "Iteration  9100, loss = 1.356835\n",
      "Iteration  9200, loss = 1.356835\n",
      "Iteration  9300, loss = 1.356835\n",
      "Iteration  9400, loss = 1.356835\n",
      "Iteration  9500, loss = 1.356835\n",
      "Iteration  9600, loss = 1.356835\n",
      "Iteration  9700, loss = 1.356835\n",
      "Iteration  9800, loss = 1.356835\n",
      "Iteration  9900, loss = 1.356835\n",
      " Accuracy: 79.67%\n",
      " F1 Score: 0.0985\n",
      "\n",
      "Validation loss: 1.3063475183939013 f1 score 0.09853348651753686 with data size of 13125\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.362750\n",
      "Iteration   200, loss = 1.362750\n",
      "Iteration   300, loss = 1.362750\n",
      "Iteration   400, loss = 1.362750\n",
      "Iteration   500, loss = 1.362750\n",
      "Iteration   600, loss = 1.362750\n",
      "Iteration   700, loss = 1.362750\n",
      "Iteration   800, loss = 1.362750\n",
      "Iteration   900, loss = 1.362750\n",
      "Iteration  1000, loss = 1.362750\n",
      "Iteration  1100, loss = 1.362750\n",
      "Iteration  1200, loss = 1.362750\n",
      "Iteration  1300, loss = 1.362750\n",
      "Iteration  1400, loss = 1.362750\n",
      "Iteration  1500, loss = 1.362750\n",
      "Iteration  1600, loss = 1.362750\n",
      "Iteration  1700, loss = 1.362750\n",
      "Iteration  1800, loss = 1.362750\n",
      "Iteration  1900, loss = 1.362750\n",
      "Iteration  2000, loss = 1.362750\n",
      "Iteration  2100, loss = 1.362750\n",
      "Iteration  2200, loss = 1.362750\n",
      "Iteration  2300, loss = 1.362750\n",
      "Iteration  2400, loss = 1.362750\n",
      "Iteration  2500, loss = 1.362750\n",
      "Iteration  2600, loss = 1.362750\n",
      "Iteration  2700, loss = 1.362750\n",
      "Iteration  2800, loss = 1.362750\n",
      "Iteration  2900, loss = 1.362750\n",
      "Iteration  3000, loss = 1.362750\n",
      "Iteration  3100, loss = 1.362750\n",
      "Iteration  3200, loss = 1.362750\n",
      "Iteration  3300, loss = 1.362750\n",
      "Iteration  3400, loss = 1.362750\n",
      "Iteration  3500, loss = 1.362750\n",
      "Iteration  3600, loss = 1.362750\n",
      "Iteration  3700, loss = 1.362750\n",
      "Iteration  3800, loss = 1.362750\n",
      "Iteration  3900, loss = 1.362750\n",
      "Iteration  4000, loss = 1.362750\n",
      "Iteration  4100, loss = 1.362750\n",
      "Iteration  4200, loss = 1.362750\n",
      "Iteration  4300, loss = 1.362750\n",
      "Iteration  4400, loss = 1.362750\n",
      "Iteration  4500, loss = 1.362750\n",
      "Iteration  4600, loss = 1.362750\n",
      "Iteration  4700, loss = 1.362750\n",
      "Iteration  4800, loss = 1.362750\n",
      "Iteration  4900, loss = 1.362750\n",
      "Iteration  5000, loss = 1.362750\n",
      "Iteration  5100, loss = 1.362750\n",
      "Iteration  5200, loss = 1.362750\n",
      "Iteration  5300, loss = 1.362750\n",
      "Iteration  5400, loss = 1.362750\n",
      "Iteration  5500, loss = 1.362750\n",
      "Iteration  5600, loss = 1.362750\n",
      "Iteration  5700, loss = 1.362750\n",
      "Iteration  5800, loss = 1.362750\n",
      "Iteration  5900, loss = 1.362750\n",
      "Iteration  6000, loss = 1.362750\n",
      "Iteration  6100, loss = 1.362750\n",
      "Iteration  6200, loss = 1.362750\n",
      "Iteration  6300, loss = 1.362750\n",
      "Iteration  6400, loss = 1.362750\n",
      "Iteration  6500, loss = 1.362750\n",
      "Iteration  6600, loss = 1.362750\n",
      "Iteration  6700, loss = 1.362750\n",
      "Iteration  6800, loss = 1.362750\n",
      "Iteration  6900, loss = 1.362750\n",
      "Iteration  7000, loss = 1.362750\n",
      "Iteration  7100, loss = 1.362750\n",
      "Iteration  7200, loss = 1.362750\n",
      "Iteration  7300, loss = 1.362750\n",
      "Iteration  7400, loss = 1.362750\n",
      "Iteration  7500, loss = 1.362750\n",
      "Iteration  7600, loss = 1.362750\n",
      "Iteration  7700, loss = 1.362750\n",
      "Iteration  7800, loss = 1.362750\n",
      "Iteration  7900, loss = 1.362750\n",
      "Iteration  8000, loss = 1.362750\n",
      "Iteration  8100, loss = 1.362750\n",
      "Iteration  8200, loss = 1.362750\n",
      "Iteration  8300, loss = 1.362750\n",
      "Iteration  8400, loss = 1.362750\n",
      "Iteration  8500, loss = 1.362750\n",
      "Iteration  8600, loss = 1.362750\n",
      "Iteration  8700, loss = 1.362750\n",
      "Iteration  8800, loss = 1.362750\n",
      "Iteration  8900, loss = 1.362750\n",
      "Iteration  9000, loss = 1.362750\n",
      "Iteration  9100, loss = 1.362750\n",
      "Iteration  9200, loss = 1.362750\n",
      "Iteration  9300, loss = 1.362750\n",
      "Iteration  9400, loss = 1.362750\n",
      "Iteration  9500, loss = 1.362750\n",
      "Iteration  9600, loss = 1.362750\n",
      "Iteration  9700, loss = 1.362750\n",
      "Iteration  9800, loss = 1.362750\n",
      "Iteration  9900, loss = 1.362750\n",
      " Accuracy: 79.63%\n",
      " F1 Score: 0.0993\n",
      "\n",
      "Validation loss: 1.3166309353059191 f1 score 0.09932614555256017 with data size of 13816\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.365473\n",
      "Iteration   200, loss = 1.365473\n",
      "Iteration   300, loss = 1.365473\n",
      "Iteration   400, loss = 1.365473\n",
      "Iteration   500, loss = 1.365473\n",
      "Iteration   600, loss = 1.365473\n",
      "Iteration   700, loss = 1.365473\n",
      "Iteration   800, loss = 1.365473\n",
      "Iteration   900, loss = 1.365473\n",
      "Iteration  1000, loss = 1.365473\n",
      "Iteration  1100, loss = 1.365473\n",
      "Iteration  1200, loss = 1.365473\n",
      "Iteration  1300, loss = 1.365473\n",
      "Iteration  1400, loss = 1.365473\n",
      "Iteration  1500, loss = 1.365473\n",
      "Iteration  1600, loss = 1.365473\n",
      "Iteration  1700, loss = 1.365473\n",
      "Iteration  1800, loss = 1.365473\n",
      "Iteration  1900, loss = 1.365473\n",
      "Iteration  2000, loss = 1.365473\n",
      "Iteration  2100, loss = 1.365473\n",
      "Iteration  2200, loss = 1.365473\n",
      "Iteration  2300, loss = 1.365473\n",
      "Iteration  2400, loss = 1.365473\n",
      "Iteration  2500, loss = 1.365473\n",
      "Iteration  2600, loss = 1.365473\n",
      "Iteration  2700, loss = 1.365473\n",
      "Iteration  2800, loss = 1.365473\n",
      "Iteration  2900, loss = 1.365473\n",
      "Iteration  3000, loss = 1.365473\n",
      "Iteration  3100, loss = 1.365473\n",
      "Iteration  3200, loss = 1.365473\n",
      "Iteration  3300, loss = 1.365473\n",
      "Iteration  3400, loss = 1.365473\n",
      "Iteration  3500, loss = 1.365473\n",
      "Iteration  3600, loss = 1.365473\n",
      "Iteration  3700, loss = 1.365473\n",
      "Iteration  3800, loss = 1.365473\n",
      "Iteration  3900, loss = 1.365473\n",
      "Iteration  4000, loss = 1.365473\n",
      "Iteration  4100, loss = 1.365473\n",
      "Iteration  4200, loss = 1.365473\n",
      "Iteration  4300, loss = 1.365473\n",
      "Iteration  4400, loss = 1.365473\n",
      "Iteration  4500, loss = 1.365473\n",
      "Iteration  4600, loss = 1.365473\n",
      "Iteration  4700, loss = 1.365473\n",
      "Iteration  4800, loss = 1.365473\n",
      "Iteration  4900, loss = 1.365473\n",
      "Iteration  5000, loss = 1.365473\n",
      "Iteration  5100, loss = 1.365473\n",
      "Iteration  5200, loss = 1.365473\n",
      "Iteration  5300, loss = 1.365473\n",
      "Iteration  5400, loss = 1.365473\n",
      "Iteration  5500, loss = 1.365473\n",
      "Iteration  5600, loss = 1.365473\n",
      "Iteration  5700, loss = 1.365473\n",
      "Iteration  5800, loss = 1.365473\n",
      "Iteration  5900, loss = 1.365473\n",
      "Iteration  6000, loss = 1.365473\n",
      "Iteration  6100, loss = 1.365473\n",
      "Iteration  6200, loss = 1.365473\n",
      "Iteration  6300, loss = 1.365473\n",
      "Iteration  6400, loss = 1.365473\n",
      "Iteration  6500, loss = 1.365473\n",
      "Iteration  6600, loss = 1.365473\n",
      "Iteration  6700, loss = 1.365473\n",
      "Iteration  6800, loss = 1.365473\n",
      "Iteration  6900, loss = 1.365473\n",
      "Iteration  7000, loss = 1.365473\n",
      "Iteration  7100, loss = 1.365473\n",
      "Iteration  7200, loss = 1.365473\n",
      "Iteration  7300, loss = 1.365473\n",
      "Iteration  7400, loss = 1.365473\n",
      "Iteration  7500, loss = 1.365473\n",
      "Iteration  7600, loss = 1.365473\n",
      "Iteration  7700, loss = 1.365473\n",
      "Iteration  7800, loss = 1.365473\n",
      "Iteration  7900, loss = 1.365473\n",
      "Iteration  8000, loss = 1.365473\n",
      "Iteration  8100, loss = 1.365473\n",
      "Iteration  8200, loss = 1.365473\n",
      "Iteration  8300, loss = 1.365473\n",
      "Iteration  8400, loss = 1.365473\n",
      "Iteration  8500, loss = 1.365473\n",
      "Iteration  8600, loss = 1.365473\n",
      "Iteration  8700, loss = 1.365473\n",
      "Iteration  8800, loss = 1.365473\n",
      "Iteration  8900, loss = 1.365473\n",
      "Iteration  9000, loss = 1.365473\n",
      "Iteration  9100, loss = 1.365473\n",
      "Iteration  9200, loss = 1.365473\n",
      "Iteration  9300, loss = 1.365473\n",
      "Iteration  9400, loss = 1.365473\n",
      "Iteration  9500, loss = 1.365473\n",
      "Iteration  9600, loss = 1.365473\n",
      "Iteration  9700, loss = 1.365473\n",
      "Iteration  9800, loss = 1.365473\n",
      "Iteration  9900, loss = 1.365473\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0997\n",
      "\n",
      "Validation loss: 1.3156831524113692 f1 score 0.09969056908381495 with data size of 14583\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.368429\n",
      "Iteration   200, loss = 1.368429\n",
      "Iteration   300, loss = 1.368429\n",
      "Iteration   400, loss = 1.368429\n",
      "Iteration   500, loss = 1.368429\n",
      "Iteration   600, loss = 1.368429\n",
      "Iteration   700, loss = 1.368429\n",
      "Iteration   800, loss = 1.368429\n",
      "Iteration   900, loss = 1.368429\n",
      "Iteration  1000, loss = 1.368429\n",
      "Iteration  1100, loss = 1.368429\n",
      "Iteration  1200, loss = 1.368429\n",
      "Iteration  1300, loss = 1.368429\n",
      "Iteration  1400, loss = 1.368429\n",
      "Iteration  1500, loss = 1.368429\n",
      "Iteration  1600, loss = 1.368429\n",
      "Iteration  1700, loss = 1.368429\n",
      "Iteration  1800, loss = 1.368429\n",
      "Iteration  1900, loss = 1.368429\n",
      "Iteration  2000, loss = 1.368429\n",
      "Iteration  2100, loss = 1.368429\n",
      "Iteration  2200, loss = 1.368429\n",
      "Iteration  2300, loss = 1.368429\n",
      "Iteration  2400, loss = 1.368429\n",
      "Iteration  2500, loss = 1.368429\n",
      "Iteration  2600, loss = 1.368429\n",
      "Iteration  2700, loss = 1.368429\n",
      "Iteration  2800, loss = 1.368429\n",
      "Iteration  2900, loss = 1.368429\n",
      "Iteration  3000, loss = 1.368429\n",
      "Iteration  3100, loss = 1.368429\n",
      "Iteration  3200, loss = 1.368429\n",
      "Iteration  3300, loss = 1.368429\n",
      "Iteration  3400, loss = 1.368429\n",
      "Iteration  3500, loss = 1.368429\n",
      "Iteration  3600, loss = 1.368429\n",
      "Iteration  3700, loss = 1.368429\n",
      "Iteration  3800, loss = 1.368429\n",
      "Iteration  3900, loss = 1.368429\n",
      "Iteration  4000, loss = 1.368429\n",
      "Iteration  4100, loss = 1.368429\n",
      "Iteration  4200, loss = 1.368429\n",
      "Iteration  4300, loss = 1.368429\n",
      "Iteration  4400, loss = 1.368429\n",
      "Iteration  4500, loss = 1.368429\n",
      "Iteration  4600, loss = 1.368429\n",
      "Iteration  4700, loss = 1.368429\n",
      "Iteration  4800, loss = 1.368429\n",
      "Iteration  4900, loss = 1.368429\n",
      "Iteration  5000, loss = 1.368429\n",
      "Iteration  5100, loss = 1.368429\n",
      "Iteration  5200, loss = 1.368429\n",
      "Iteration  5300, loss = 1.368429\n",
      "Iteration  5400, loss = 1.368429\n",
      "Iteration  5500, loss = 1.368429\n",
      "Iteration  5600, loss = 1.368429\n",
      "Iteration  5700, loss = 1.368429\n",
      "Iteration  5800, loss = 1.368429\n",
      "Iteration  5900, loss = 1.368429\n",
      "Iteration  6000, loss = 1.368429\n",
      "Iteration  6100, loss = 1.368429\n",
      "Iteration  6200, loss = 1.368429\n",
      "Iteration  6300, loss = 1.368429\n",
      "Iteration  6400, loss = 1.368429\n",
      "Iteration  6500, loss = 1.368429\n",
      "Iteration  6600, loss = 1.368429\n",
      "Iteration  6700, loss = 1.368429\n",
      "Iteration  6800, loss = 1.368429\n",
      "Iteration  6900, loss = 1.368429\n",
      "Iteration  7000, loss = 1.368429\n",
      "Iteration  7100, loss = 1.368429\n",
      "Iteration  7200, loss = 1.368429\n",
      "Iteration  7300, loss = 1.368429\n",
      "Iteration  7400, loss = 1.368429\n",
      "Iteration  7500, loss = 1.368429\n",
      "Iteration  7600, loss = 1.368429\n",
      "Iteration  7700, loss = 1.368429\n",
      "Iteration  7800, loss = 1.368429\n",
      "Iteration  7900, loss = 1.368429\n",
      "Iteration  8000, loss = 1.368429\n",
      "Iteration  8100, loss = 1.368429\n",
      "Iteration  8200, loss = 1.368429\n",
      "Iteration  8300, loss = 1.368429\n",
      "Iteration  8400, loss = 1.368429\n",
      "Iteration  8500, loss = 1.368429\n",
      "Iteration  8600, loss = 1.368429\n",
      "Iteration  8700, loss = 1.368429\n",
      "Iteration  8800, loss = 1.368429\n",
      "Iteration  8900, loss = 1.368429\n",
      "Iteration  9000, loss = 1.368429\n",
      "Iteration  9100, loss = 1.368429\n",
      "Iteration  9200, loss = 1.368429\n",
      "Iteration  9300, loss = 1.368429\n",
      "Iteration  9400, loss = 1.368429\n",
      "Iteration  9500, loss = 1.368429\n",
      "Iteration  9600, loss = 1.368429\n",
      "Iteration  9700, loss = 1.368429\n",
      "Iteration  9800, loss = 1.368429\n",
      "Iteration  9900, loss = 1.368429\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0996\n",
      "\n",
      "Validation loss: 1.316450377142647 f1 score 0.0995694294940792 with data size of 15441\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.355549\n",
      "Iteration   200, loss = 1.355549\n",
      "Iteration   300, loss = 1.355549\n",
      "Iteration   400, loss = 1.355549\n",
      "Iteration   500, loss = 1.355549\n",
      "Iteration   600, loss = 1.355549\n",
      "Iteration   700, loss = 1.355549\n",
      "Iteration   800, loss = 1.355549\n",
      "Iteration   900, loss = 1.355549\n",
      "Iteration  1000, loss = 1.355549\n",
      "Iteration  1100, loss = 1.355549\n",
      "Iteration  1200, loss = 1.355549\n",
      "Iteration  1300, loss = 1.355549\n",
      "Iteration  1400, loss = 1.355549\n",
      "Iteration  1500, loss = 1.355549\n",
      "Iteration  1600, loss = 1.355549\n",
      "Iteration  1700, loss = 1.355549\n",
      "Iteration  1800, loss = 1.355549\n",
      "Iteration  1900, loss = 1.355549\n",
      "Iteration  2000, loss = 1.355549\n",
      "Iteration  2100, loss = 1.355549\n",
      "Iteration  2200, loss = 1.355549\n",
      "Iteration  2300, loss = 1.355549\n",
      "Iteration  2400, loss = 1.355549\n",
      "Iteration  2500, loss = 1.355549\n",
      "Iteration  2600, loss = 1.355549\n",
      "Iteration  2700, loss = 1.355549\n",
      "Iteration  2800, loss = 1.355549\n",
      "Iteration  2900, loss = 1.355549\n",
      "Iteration  3000, loss = 1.355549\n",
      "Iteration  3100, loss = 1.355549\n",
      "Iteration  3200, loss = 1.355549\n",
      "Iteration  3300, loss = 1.355549\n",
      "Iteration  3400, loss = 1.355549\n",
      "Iteration  3500, loss = 1.355549\n",
      "Iteration  3600, loss = 1.355549\n",
      "Iteration  3700, loss = 1.355549\n",
      "Iteration  3800, loss = 1.355549\n",
      "Iteration  3900, loss = 1.355549\n",
      "Iteration  4000, loss = 1.355549\n",
      "Iteration  4100, loss = 1.355549\n",
      "Iteration  4200, loss = 1.355549\n",
      "Iteration  4300, loss = 1.355549\n",
      "Iteration  4400, loss = 1.355549\n",
      "Iteration  4500, loss = 1.355549\n",
      "Iteration  4600, loss = 1.355549\n",
      "Iteration  4700, loss = 1.355549\n",
      "Iteration  4800, loss = 1.355549\n",
      "Iteration  4900, loss = 1.355549\n",
      "Iteration  5000, loss = 1.355549\n",
      "Iteration  5100, loss = 1.355549\n",
      "Iteration  5200, loss = 1.355549\n",
      "Iteration  5300, loss = 1.355549\n",
      "Iteration  5400, loss = 1.355549\n",
      "Iteration  5500, loss = 1.355549\n",
      "Iteration  5600, loss = 1.355549\n",
      "Iteration  5700, loss = 1.355549\n",
      "Iteration  5800, loss = 1.355549\n",
      "Iteration  5900, loss = 1.355549\n",
      "Iteration  6000, loss = 1.355549\n",
      "Iteration  6100, loss = 1.355549\n",
      "Iteration  6200, loss = 1.355549\n",
      "Iteration  6300, loss = 1.355549\n",
      "Iteration  6400, loss = 1.355549\n",
      "Iteration  6500, loss = 1.355549\n",
      "Iteration  6600, loss = 1.355549\n",
      "Iteration  6700, loss = 1.355549\n",
      "Iteration  6800, loss = 1.355549\n",
      "Iteration  6900, loss = 1.355549\n",
      "Iteration  7000, loss = 1.355549\n",
      "Iteration  7100, loss = 1.355549\n",
      "Iteration  7200, loss = 1.355549\n",
      "Iteration  7300, loss = 1.355549\n",
      "Iteration  7400, loss = 1.355549\n",
      "Iteration  7500, loss = 1.355549\n",
      "Iteration  7600, loss = 1.355549\n",
      "Iteration  7700, loss = 1.355549\n",
      "Iteration  7800, loss = 1.355549\n",
      "Iteration  7900, loss = 1.355549\n",
      "Iteration  8000, loss = 1.355549\n",
      "Iteration  8100, loss = 1.355549\n",
      "Iteration  8200, loss = 1.355549\n",
      "Iteration  8300, loss = 1.355549\n",
      "Iteration  8400, loss = 1.355549\n",
      "Iteration  8500, loss = 1.355549\n",
      "Iteration  8600, loss = 1.355549\n",
      "Iteration  8700, loss = 1.355549\n",
      "Iteration  8800, loss = 1.355549\n",
      "Iteration  8900, loss = 1.355549\n",
      "Iteration  9000, loss = 1.355549\n",
      "Iteration  9100, loss = 1.355549\n",
      "Iteration  9200, loss = 1.355549\n",
      "Iteration  9300, loss = 1.355549\n",
      "Iteration  9400, loss = 1.355549\n",
      "Iteration  9500, loss = 1.355549\n",
      "Iteration  9600, loss = 1.355549\n",
      "Iteration  9700, loss = 1.355549\n",
      "Iteration  9800, loss = 1.355549\n",
      "Iteration  9900, loss = 1.355549\n",
      " Accuracy: 79.64%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3052277282354074 f1 score 0.09946091644204803 with data size of 16406\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.346948\n",
      "Iteration   200, loss = 1.346948\n",
      "Iteration   300, loss = 1.346948\n",
      "Iteration   400, loss = 1.346948\n",
      "Iteration   500, loss = 1.346948\n",
      "Iteration   600, loss = 1.346948\n",
      "Iteration   700, loss = 1.346948\n",
      "Iteration   800, loss = 1.346948\n",
      "Iteration   900, loss = 1.346948\n",
      "Iteration  1000, loss = 1.346948\n",
      "Iteration  1100, loss = 1.346948\n",
      "Iteration  1200, loss = 1.346948\n",
      "Iteration  1300, loss = 1.346948\n",
      "Iteration  1400, loss = 1.346948\n",
      "Iteration  1500, loss = 1.346948\n",
      "Iteration  1600, loss = 1.346948\n",
      "Iteration  1700, loss = 1.346948\n",
      "Iteration  1800, loss = 1.346948\n",
      "Iteration  1900, loss = 1.346948\n",
      "Iteration  2000, loss = 1.346948\n",
      "Iteration  2100, loss = 1.346948\n",
      "Iteration  2200, loss = 1.346948\n",
      "Iteration  2300, loss = 1.346948\n",
      "Iteration  2400, loss = 1.346948\n",
      "Iteration  2500, loss = 1.346948\n",
      "Iteration  2600, loss = 1.346948\n",
      "Iteration  2700, loss = 1.346948\n",
      "Iteration  2800, loss = 1.346948\n",
      "Iteration  2900, loss = 1.346948\n",
      "Iteration  3000, loss = 1.346948\n",
      "Iteration  3100, loss = 1.346948\n",
      "Iteration  3200, loss = 1.346948\n",
      "Iteration  3300, loss = 1.346948\n",
      "Iteration  3400, loss = 1.346948\n",
      "Iteration  3500, loss = 1.346948\n",
      "Iteration  3600, loss = 1.346948\n",
      "Iteration  3700, loss = 1.346948\n",
      "Iteration  3800, loss = 1.346948\n",
      "Iteration  3900, loss = 1.346948\n",
      "Iteration  4000, loss = 1.346948\n",
      "Iteration  4100, loss = 1.346948\n",
      "Iteration  4200, loss = 1.346948\n",
      "Iteration  4300, loss = 1.346948\n",
      "Iteration  4400, loss = 1.346948\n",
      "Iteration  4500, loss = 1.346948\n",
      "Iteration  4600, loss = 1.346948\n",
      "Iteration  4700, loss = 1.346948\n",
      "Iteration  4800, loss = 1.346948\n",
      "Iteration  4900, loss = 1.346948\n",
      "Iteration  5000, loss = 1.346948\n",
      "Iteration  5100, loss = 1.346948\n",
      "Iteration  5200, loss = 1.346948\n",
      "Iteration  5300, loss = 1.346948\n",
      "Iteration  5400, loss = 1.346948\n",
      "Iteration  5500, loss = 1.346948\n",
      "Iteration  5600, loss = 1.346948\n",
      "Iteration  5700, loss = 1.346948\n",
      "Iteration  5800, loss = 1.346948\n",
      "Iteration  5900, loss = 1.346948\n",
      "Iteration  6000, loss = 1.346948\n",
      "Iteration  6100, loss = 1.346948\n",
      "Iteration  6200, loss = 1.346948\n",
      "Iteration  6300, loss = 1.346948\n",
      "Iteration  6400, loss = 1.346948\n",
      "Iteration  6500, loss = 1.346948\n",
      "Iteration  6600, loss = 1.346948\n",
      "Iteration  6700, loss = 1.346948\n",
      "Iteration  6800, loss = 1.346948\n",
      "Iteration  6900, loss = 1.346948\n",
      "Iteration  7000, loss = 1.346948\n",
      "Iteration  7100, loss = 1.346948\n",
      "Iteration  7200, loss = 1.346948\n",
      "Iteration  7300, loss = 1.346948\n",
      "Iteration  7400, loss = 1.346948\n",
      "Iteration  7500, loss = 1.346948\n",
      "Iteration  7600, loss = 1.346948\n",
      "Iteration  7700, loss = 1.346948\n",
      "Iteration  7800, loss = 1.346948\n",
      "Iteration  7900, loss = 1.346948\n",
      "Iteration  8000, loss = 1.346948\n",
      "Iteration  8100, loss = 1.346948\n",
      "Iteration  8200, loss = 1.346948\n",
      "Iteration  8300, loss = 1.346948\n",
      "Iteration  8400, loss = 1.346948\n",
      "Iteration  8500, loss = 1.346948\n",
      "Iteration  8600, loss = 1.346948\n",
      "Iteration  8700, loss = 1.346948\n",
      "Iteration  8800, loss = 1.346948\n",
      "Iteration  8900, loss = 1.346948\n",
      "Iteration  9000, loss = 1.346948\n",
      "Iteration  9100, loss = 1.346948\n",
      "Iteration  9200, loss = 1.346948\n",
      "Iteration  9300, loss = 1.346948\n",
      "Iteration  9400, loss = 1.346948\n",
      "Iteration  9500, loss = 1.346948\n",
      "Iteration  9600, loss = 1.346948\n",
      "Iteration  9700, loss = 1.346948\n",
      "Iteration  9800, loss = 1.346948\n",
      "Iteration  9900, loss = 1.346948\n",
      " Accuracy: 79.67%\n",
      " F1 Score: 0.0990\n",
      "\n",
      "Validation loss: 1.295325245563282 f1 score 0.09898717083051944 with data size of 17500\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.351506\n",
      "Iteration   200, loss = 1.351506\n",
      "Iteration   300, loss = 1.351506\n",
      "Iteration   400, loss = 1.351506\n",
      "Iteration   500, loss = 1.351506\n",
      "Iteration   600, loss = 1.351506\n",
      "Iteration   700, loss = 1.351506\n",
      "Iteration   800, loss = 1.351506\n",
      "Iteration   900, loss = 1.351506\n",
      "Iteration  1000, loss = 1.351506\n",
      "Iteration  1100, loss = 1.351506\n",
      "Iteration  1200, loss = 1.351506\n",
      "Iteration  1300, loss = 1.351506\n",
      "Iteration  1400, loss = 1.351506\n",
      "Iteration  1500, loss = 1.351506\n",
      "Iteration  1600, loss = 1.351506\n",
      "Iteration  1700, loss = 1.351506\n",
      "Iteration  1800, loss = 1.351506\n",
      "Iteration  1900, loss = 1.351506\n",
      "Iteration  2000, loss = 1.351506\n",
      "Iteration  2100, loss = 1.351506\n",
      "Iteration  2200, loss = 1.351506\n",
      "Iteration  2300, loss = 1.351506\n",
      "Iteration  2400, loss = 1.351506\n",
      "Iteration  2500, loss = 1.351506\n",
      "Iteration  2600, loss = 1.351506\n",
      "Iteration  2700, loss = 1.351506\n",
      "Iteration  2800, loss = 1.351506\n",
      "Iteration  2900, loss = 1.351506\n",
      "Iteration  3000, loss = 1.351506\n",
      "Iteration  3100, loss = 1.351506\n",
      "Iteration  3200, loss = 1.351506\n",
      "Iteration  3300, loss = 1.351506\n",
      "Iteration  3400, loss = 1.351506\n",
      "Iteration  3500, loss = 1.351506\n",
      "Iteration  3600, loss = 1.351506\n",
      "Iteration  3700, loss = 1.351506\n",
      "Iteration  3800, loss = 1.351506\n",
      "Iteration  3900, loss = 1.351506\n",
      "Iteration  4000, loss = 1.351506\n",
      "Iteration  4100, loss = 1.351506\n",
      "Iteration  4200, loss = 1.351506\n",
      "Iteration  4300, loss = 1.351506\n",
      "Iteration  4400, loss = 1.351506\n",
      "Iteration  4500, loss = 1.351506\n",
      "Iteration  4600, loss = 1.351506\n",
      "Iteration  4700, loss = 1.351506\n",
      "Iteration  4800, loss = 1.351506\n",
      "Iteration  4900, loss = 1.351506\n",
      "Iteration  5000, loss = 1.351506\n",
      "Iteration  5100, loss = 1.351506\n",
      "Iteration  5200, loss = 1.351506\n",
      "Iteration  5300, loss = 1.351506\n",
      "Iteration  5400, loss = 1.351506\n",
      "Iteration  5500, loss = 1.351506\n",
      "Iteration  5600, loss = 1.351506\n",
      "Iteration  5700, loss = 1.351506\n",
      "Iteration  5800, loss = 1.351506\n",
      "Iteration  5900, loss = 1.351506\n",
      "Iteration  6000, loss = 1.351506\n",
      "Iteration  6100, loss = 1.351506\n",
      "Iteration  6200, loss = 1.351506\n",
      "Iteration  6300, loss = 1.351506\n",
      "Iteration  6400, loss = 1.351506\n",
      "Iteration  6500, loss = 1.351506\n",
      "Iteration  6600, loss = 1.351506\n",
      "Iteration  6700, loss = 1.351506\n",
      "Iteration  6800, loss = 1.351506\n",
      "Iteration  6900, loss = 1.351506\n",
      "Iteration  7000, loss = 1.351506\n",
      "Iteration  7100, loss = 1.351506\n",
      "Iteration  7200, loss = 1.351506\n",
      "Iteration  7300, loss = 1.351506\n",
      "Iteration  7400, loss = 1.351506\n",
      "Iteration  7500, loss = 1.351506\n",
      "Iteration  7600, loss = 1.351506\n",
      "Iteration  7700, loss = 1.351506\n",
      "Iteration  7800, loss = 1.351506\n",
      "Iteration  7900, loss = 1.351506\n",
      "Iteration  8000, loss = 1.351506\n",
      "Iteration  8100, loss = 1.351506\n",
      "Iteration  8200, loss = 1.351506\n",
      "Iteration  8300, loss = 1.351506\n",
      "Iteration  8400, loss = 1.351506\n",
      "Iteration  8500, loss = 1.351506\n",
      "Iteration  8600, loss = 1.351506\n",
      "Iteration  8700, loss = 1.351506\n",
      "Iteration  8800, loss = 1.351506\n",
      "Iteration  8900, loss = 1.351506\n",
      "Iteration  9000, loss = 1.351506\n",
      "Iteration  9100, loss = 1.351506\n",
      "Iteration  9200, loss = 1.351506\n",
      "Iteration  9300, loss = 1.351506\n",
      "Iteration  9400, loss = 1.351506\n",
      "Iteration  9500, loss = 1.351506\n",
      "Iteration  9600, loss = 1.351506\n",
      "Iteration  9700, loss = 1.351506\n",
      "Iteration  9800, loss = 1.351506\n",
      "Iteration  9900, loss = 1.351506\n",
      " Accuracy: 79.65%\n",
      " F1 Score: 0.0993\n",
      "\n",
      "Validation loss: 1.3030556511244946 f1 score 0.09927834356241944 with data size of 18750\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.355507\n",
      "Iteration   200, loss = 1.355507\n",
      "Iteration   300, loss = 1.355507\n",
      "Iteration   400, loss = 1.355507\n",
      "Iteration   500, loss = 1.355507\n",
      "Iteration   600, loss = 1.355507\n",
      "Iteration   700, loss = 1.355507\n",
      "Iteration   800, loss = 1.355507\n",
      "Iteration   900, loss = 1.355507\n",
      "Iteration  1000, loss = 1.355507\n",
      "Iteration  1100, loss = 1.355507\n",
      "Iteration  1200, loss = 1.355507\n",
      "Iteration  1300, loss = 1.355507\n",
      "Iteration  1400, loss = 1.355507\n",
      "Iteration  1500, loss = 1.355507\n",
      "Iteration  1600, loss = 1.355507\n",
      "Iteration  1700, loss = 1.355507\n",
      "Iteration  1800, loss = 1.355507\n",
      "Iteration  1900, loss = 1.355507\n",
      "Iteration  2000, loss = 1.355507\n",
      "Iteration  2100, loss = 1.355507\n",
      "Iteration  2200, loss = 1.355507\n",
      "Iteration  2300, loss = 1.355507\n",
      "Iteration  2400, loss = 1.355507\n",
      "Iteration  2500, loss = 1.355507\n",
      "Iteration  2600, loss = 1.355507\n",
      "Iteration  2700, loss = 1.355507\n",
      "Iteration  2800, loss = 1.355507\n",
      "Iteration  2900, loss = 1.355507\n",
      "Iteration  3000, loss = 1.355507\n",
      "Iteration  3100, loss = 1.355507\n",
      "Iteration  3200, loss = 1.355507\n",
      "Iteration  3300, loss = 1.355507\n",
      "Iteration  3400, loss = 1.355507\n",
      "Iteration  3500, loss = 1.355507\n",
      "Iteration  3600, loss = 1.355507\n",
      "Iteration  3700, loss = 1.355507\n",
      "Iteration  3800, loss = 1.355507\n",
      "Iteration  3900, loss = 1.355507\n",
      "Iteration  4000, loss = 1.355507\n",
      "Iteration  4100, loss = 1.355507\n",
      "Iteration  4200, loss = 1.355507\n",
      "Iteration  4300, loss = 1.355507\n",
      "Iteration  4400, loss = 1.355507\n",
      "Iteration  4500, loss = 1.355507\n",
      "Iteration  4600, loss = 1.355507\n",
      "Iteration  4700, loss = 1.355507\n",
      "Iteration  4800, loss = 1.355507\n",
      "Iteration  4900, loss = 1.355507\n",
      "Iteration  5000, loss = 1.355507\n",
      "Iteration  5100, loss = 1.355507\n",
      "Iteration  5200, loss = 1.355507\n",
      "Iteration  5300, loss = 1.355507\n",
      "Iteration  5400, loss = 1.355507\n",
      "Iteration  5500, loss = 1.355507\n",
      "Iteration  5600, loss = 1.355507\n",
      "Iteration  5700, loss = 1.355507\n",
      "Iteration  5800, loss = 1.355507\n",
      "Iteration  5900, loss = 1.355507\n",
      "Iteration  6000, loss = 1.355507\n",
      "Iteration  6100, loss = 1.355507\n",
      "Iteration  6200, loss = 1.355507\n",
      "Iteration  6300, loss = 1.355507\n",
      "Iteration  6400, loss = 1.355507\n",
      "Iteration  6500, loss = 1.355507\n",
      "Iteration  6600, loss = 1.355507\n",
      "Iteration  6700, loss = 1.355507\n",
      "Iteration  6800, loss = 1.355507\n",
      "Iteration  6900, loss = 1.355507\n",
      "Iteration  7000, loss = 1.355507\n",
      "Iteration  7100, loss = 1.355507\n",
      "Iteration  7200, loss = 1.355507\n",
      "Iteration  7300, loss = 1.355507\n",
      "Iteration  7400, loss = 1.355507\n",
      "Iteration  7500, loss = 1.355507\n",
      "Iteration  7600, loss = 1.355507\n",
      "Iteration  7700, loss = 1.355507\n",
      "Iteration  7800, loss = 1.355507\n",
      "Iteration  7900, loss = 1.355507\n",
      "Iteration  8000, loss = 1.355507\n",
      "Iteration  8100, loss = 1.355507\n",
      "Iteration  8200, loss = 1.355507\n",
      "Iteration  8300, loss = 1.355507\n",
      "Iteration  8400, loss = 1.355507\n",
      "Iteration  8500, loss = 1.355507\n",
      "Iteration  8600, loss = 1.355507\n",
      "Iteration  8700, loss = 1.355507\n",
      "Iteration  8800, loss = 1.355507\n",
      "Iteration  8900, loss = 1.355507\n",
      "Iteration  9000, loss = 1.355507\n",
      "Iteration  9100, loss = 1.355507\n",
      "Iteration  9200, loss = 1.355507\n",
      "Iteration  9300, loss = 1.355507\n",
      "Iteration  9400, loss = 1.355507\n",
      "Iteration  9500, loss = 1.355507\n",
      "Iteration  9600, loss = 1.355507\n",
      "Iteration  9700, loss = 1.355507\n",
      "Iteration  9800, loss = 1.355507\n",
      "Iteration  9900, loss = 1.355507\n",
      " Accuracy: 79.63%\n",
      " F1 Score: 0.0991\n",
      "\n",
      "Validation loss: 1.3078287770162782 f1 score 0.0990632791967109 with data size of 20192\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.369776\n",
      "Iteration   200, loss = 1.369776\n",
      "Iteration   300, loss = 1.369776\n",
      "Iteration   400, loss = 1.369776\n",
      "Iteration   500, loss = 1.369776\n",
      "Iteration   600, loss = 1.369776\n",
      "Iteration   700, loss = 1.369776\n",
      "Iteration   800, loss = 1.369776\n",
      "Iteration   900, loss = 1.369776\n",
      "Iteration  1000, loss = 1.369776\n",
      "Iteration  1100, loss = 1.369776\n",
      "Iteration  1200, loss = 1.369776\n",
      "Iteration  1300, loss = 1.369776\n",
      "Iteration  1400, loss = 1.369776\n",
      "Iteration  1500, loss = 1.369776\n",
      "Iteration  1600, loss = 1.369776\n",
      "Iteration  1700, loss = 1.369776\n",
      "Iteration  1800, loss = 1.369776\n",
      "Iteration  1900, loss = 1.369776\n",
      "Iteration  2000, loss = 1.369776\n",
      "Iteration  2100, loss = 1.369776\n",
      "Iteration  2200, loss = 1.369776\n",
      "Iteration  2300, loss = 1.369776\n",
      "Iteration  2400, loss = 1.369776\n",
      "Iteration  2500, loss = 1.369776\n",
      "Iteration  2600, loss = 1.369776\n",
      "Iteration  2700, loss = 1.369776\n",
      "Iteration  2800, loss = 1.369776\n",
      "Iteration  2900, loss = 1.369776\n",
      "Iteration  3000, loss = 1.369776\n",
      "Iteration  3100, loss = 1.369776\n",
      "Iteration  3200, loss = 1.369776\n",
      "Iteration  3300, loss = 1.369776\n",
      "Iteration  3400, loss = 1.369776\n",
      "Iteration  3500, loss = 1.369776\n",
      "Iteration  3600, loss = 1.369776\n",
      "Iteration  3700, loss = 1.369776\n",
      "Iteration  3800, loss = 1.369776\n",
      "Iteration  3900, loss = 1.369776\n",
      "Iteration  4000, loss = 1.369776\n",
      "Iteration  4100, loss = 1.369776\n",
      "Iteration  4200, loss = 1.369776\n",
      "Iteration  4300, loss = 1.369776\n",
      "Iteration  4400, loss = 1.369776\n",
      "Iteration  4500, loss = 1.369776\n",
      "Iteration  4600, loss = 1.369776\n",
      "Iteration  4700, loss = 1.369776\n",
      "Iteration  4800, loss = 1.369776\n",
      "Iteration  4900, loss = 1.369776\n",
      "Iteration  5000, loss = 1.369776\n",
      "Iteration  5100, loss = 1.369776\n",
      "Iteration  5200, loss = 1.369776\n",
      "Iteration  5300, loss = 1.369776\n",
      "Iteration  5400, loss = 1.369776\n",
      "Iteration  5500, loss = 1.369776\n",
      "Iteration  5600, loss = 1.369776\n",
      "Iteration  5700, loss = 1.369776\n",
      "Iteration  5800, loss = 1.369776\n",
      "Iteration  5900, loss = 1.369776\n",
      "Iteration  6000, loss = 1.369776\n",
      "Iteration  6100, loss = 1.369776\n",
      "Iteration  6200, loss = 1.369776\n",
      "Iteration  6300, loss = 1.369776\n",
      "Iteration  6400, loss = 1.369776\n",
      "Iteration  6500, loss = 1.369776\n",
      "Iteration  6600, loss = 1.369776\n",
      "Iteration  6700, loss = 1.369776\n",
      "Iteration  6800, loss = 1.369776\n",
      "Iteration  6900, loss = 1.369776\n",
      "Iteration  7000, loss = 1.369776\n",
      "Iteration  7100, loss = 1.369776\n",
      "Iteration  7200, loss = 1.369776\n",
      "Iteration  7300, loss = 1.369776\n",
      "Iteration  7400, loss = 1.369776\n",
      "Iteration  7500, loss = 1.369776\n",
      "Iteration  7600, loss = 1.369776\n",
      "Iteration  7700, loss = 1.369776\n",
      "Iteration  7800, loss = 1.369776\n",
      "Iteration  7900, loss = 1.369776\n",
      "Iteration  8000, loss = 1.369776\n",
      "Iteration  8100, loss = 1.369776\n",
      "Iteration  8200, loss = 1.369776\n",
      "Iteration  8300, loss = 1.369776\n",
      "Iteration  8400, loss = 1.369776\n",
      "Iteration  8500, loss = 1.369776\n",
      "Iteration  8600, loss = 1.369776\n",
      "Iteration  8700, loss = 1.369776\n",
      "Iteration  8800, loss = 1.369776\n",
      "Iteration  8900, loss = 1.369776\n",
      "Iteration  9000, loss = 1.369776\n",
      "Iteration  9100, loss = 1.369776\n",
      "Iteration  9200, loss = 1.369776\n",
      "Iteration  9300, loss = 1.369776\n",
      "Iteration  9400, loss = 1.369776\n",
      "Iteration  9500, loss = 1.369776\n",
      "Iteration  9600, loss = 1.369776\n",
      "Iteration  9700, loss = 1.369776\n",
      "Iteration  9800, loss = 1.369776\n",
      "Iteration  9900, loss = 1.369776\n",
      " Accuracy: 79.58%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3191735410985332 f1 score 0.09946236559139737 with data size of 21875\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.363188\n",
      "Iteration   200, loss = 1.363188\n",
      "Iteration   300, loss = 1.363188\n",
      "Iteration   400, loss = 1.363188\n",
      "Iteration   500, loss = 1.363188\n",
      "Iteration   600, loss = 1.363188\n",
      "Iteration   700, loss = 1.363188\n",
      "Iteration   800, loss = 1.363188\n",
      "Iteration   900, loss = 1.363188\n",
      "Iteration  1000, loss = 1.363188\n",
      "Iteration  1100, loss = 1.363188\n",
      "Iteration  1200, loss = 1.363188\n",
      "Iteration  1300, loss = 1.363188\n",
      "Iteration  1400, loss = 1.363188\n",
      "Iteration  1500, loss = 1.363188\n",
      "Iteration  1600, loss = 1.363188\n",
      "Iteration  1700, loss = 1.363188\n",
      "Iteration  1800, loss = 1.363188\n",
      "Iteration  1900, loss = 1.363188\n",
      "Iteration  2000, loss = 1.363188\n",
      "Iteration  2100, loss = 1.363188\n",
      "Iteration  2200, loss = 1.363188\n",
      "Iteration  2300, loss = 1.363188\n",
      "Iteration  2400, loss = 1.363188\n",
      "Iteration  2500, loss = 1.363188\n",
      "Iteration  2600, loss = 1.363188\n",
      "Iteration  2700, loss = 1.363188\n",
      "Iteration  2800, loss = 1.363188\n",
      "Iteration  2900, loss = 1.363188\n",
      "Iteration  3000, loss = 1.363188\n",
      "Iteration  3100, loss = 1.363188\n",
      "Iteration  3200, loss = 1.363188\n",
      "Iteration  3300, loss = 1.363188\n",
      "Iteration  3400, loss = 1.363188\n",
      "Iteration  3500, loss = 1.363188\n",
      "Iteration  3600, loss = 1.363188\n",
      "Iteration  3700, loss = 1.363188\n",
      "Iteration  3800, loss = 1.363188\n",
      "Iteration  3900, loss = 1.363188\n",
      "Iteration  4000, loss = 1.363188\n",
      "Iteration  4100, loss = 1.363188\n",
      "Iteration  4200, loss = 1.363188\n",
      "Iteration  4300, loss = 1.363188\n",
      "Iteration  4400, loss = 1.363188\n",
      "Iteration  4500, loss = 1.363188\n",
      "Iteration  4600, loss = 1.363188\n",
      "Iteration  4700, loss = 1.363188\n",
      "Iteration  4800, loss = 1.363188\n",
      "Iteration  4900, loss = 1.363188\n",
      "Iteration  5000, loss = 1.363188\n",
      "Iteration  5100, loss = 1.363188\n",
      "Iteration  5200, loss = 1.363188\n",
      "Iteration  5300, loss = 1.363188\n",
      "Iteration  5400, loss = 1.363188\n",
      "Iteration  5500, loss = 1.363188\n",
      "Iteration  5600, loss = 1.363188\n",
      "Iteration  5700, loss = 1.363188\n",
      "Iteration  5800, loss = 1.363188\n",
      "Iteration  5900, loss = 1.363188\n",
      "Iteration  6000, loss = 1.363188\n",
      "Iteration  6100, loss = 1.363188\n",
      "Iteration  6200, loss = 1.363188\n",
      "Iteration  6300, loss = 1.363188\n",
      "Iteration  6400, loss = 1.363188\n",
      "Iteration  6500, loss = 1.363188\n",
      "Iteration  6600, loss = 1.363188\n",
      "Iteration  6700, loss = 1.363188\n",
      "Iteration  6800, loss = 1.363188\n",
      "Iteration  6900, loss = 1.363188\n",
      "Iteration  7000, loss = 1.363188\n",
      "Iteration  7100, loss = 1.363188\n",
      "Iteration  7200, loss = 1.363188\n",
      "Iteration  7300, loss = 1.363188\n",
      "Iteration  7400, loss = 1.363188\n",
      "Iteration  7500, loss = 1.363188\n",
      "Iteration  7600, loss = 1.363188\n",
      "Iteration  7700, loss = 1.363188\n",
      "Iteration  7800, loss = 1.363188\n",
      "Iteration  7900, loss = 1.363188\n",
      "Iteration  8000, loss = 1.363188\n",
      "Iteration  8100, loss = 1.363188\n",
      "Iteration  8200, loss = 1.363188\n",
      "Iteration  8300, loss = 1.363188\n",
      "Iteration  8400, loss = 1.363188\n",
      "Iteration  8500, loss = 1.363188\n",
      "Iteration  8600, loss = 1.363188\n",
      "Iteration  8700, loss = 1.363188\n",
      "Iteration  8800, loss = 1.363188\n",
      "Iteration  8900, loss = 1.363188\n",
      "Iteration  9000, loss = 1.363188\n",
      "Iteration  9100, loss = 1.363188\n",
      "Iteration  9200, loss = 1.363188\n",
      "Iteration  9300, loss = 1.363188\n",
      "Iteration  9400, loss = 1.363188\n",
      "Iteration  9500, loss = 1.363188\n",
      "Iteration  9600, loss = 1.363188\n",
      "Iteration  9700, loss = 1.363188\n",
      "Iteration  9800, loss = 1.363188\n",
      "Iteration  9900, loss = 1.363188\n",
      " Accuracy: 79.62%\n",
      " F1 Score: 0.0991\n",
      "\n",
      "Validation loss: 1.309332219003748 f1 score 0.09913125462994095 with data size of 23864\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.365327\n",
      "Iteration   200, loss = 1.365327\n",
      "Iteration   300, loss = 1.365327\n",
      "Iteration   400, loss = 1.365327\n",
      "Iteration   500, loss = 1.365327\n",
      "Iteration   600, loss = 1.365327\n",
      "Iteration   700, loss = 1.365327\n",
      "Iteration   800, loss = 1.365327\n",
      "Iteration   900, loss = 1.365327\n",
      "Iteration  1000, loss = 1.365327\n",
      "Iteration  1100, loss = 1.365327\n",
      "Iteration  1200, loss = 1.365327\n",
      "Iteration  1300, loss = 1.365327\n",
      "Iteration  1400, loss = 1.365327\n",
      "Iteration  1500, loss = 1.365327\n",
      "Iteration  1600, loss = 1.365327\n",
      "Iteration  1700, loss = 1.365327\n",
      "Iteration  1800, loss = 1.365327\n",
      "Iteration  1900, loss = 1.365327\n",
      "Iteration  2000, loss = 1.365327\n",
      "Iteration  2100, loss = 1.365327\n",
      "Iteration  2200, loss = 1.365327\n",
      "Iteration  2300, loss = 1.365327\n",
      "Iteration  2400, loss = 1.365327\n",
      "Iteration  2500, loss = 1.365327\n",
      "Iteration  2600, loss = 1.365327\n",
      "Iteration  2700, loss = 1.365327\n",
      "Iteration  2800, loss = 1.365327\n",
      "Iteration  2900, loss = 1.365327\n",
      "Iteration  3000, loss = 1.365327\n",
      "Iteration  3100, loss = 1.365327\n",
      "Iteration  3200, loss = 1.365327\n",
      "Iteration  3300, loss = 1.365327\n",
      "Iteration  3400, loss = 1.365327\n",
      "Iteration  3500, loss = 1.365327\n",
      "Iteration  3600, loss = 1.365327\n",
      "Iteration  3700, loss = 1.365327\n",
      "Iteration  3800, loss = 1.365327\n",
      "Iteration  3900, loss = 1.365327\n",
      "Iteration  4000, loss = 1.365327\n",
      "Iteration  4100, loss = 1.365327\n",
      "Iteration  4200, loss = 1.365327\n",
      "Iteration  4300, loss = 1.365327\n",
      "Iteration  4400, loss = 1.365327\n",
      "Iteration  4500, loss = 1.365327\n",
      "Iteration  4600, loss = 1.365327\n",
      "Iteration  4700, loss = 1.365327\n",
      "Iteration  4800, loss = 1.365327\n",
      "Iteration  4900, loss = 1.365327\n",
      "Iteration  5000, loss = 1.365327\n",
      "Iteration  5100, loss = 1.365327\n",
      "Iteration  5200, loss = 1.365327\n",
      "Iteration  5300, loss = 1.365327\n",
      "Iteration  5400, loss = 1.365327\n",
      "Iteration  5500, loss = 1.365327\n",
      "Iteration  5600, loss = 1.365327\n",
      "Iteration  5700, loss = 1.365327\n",
      "Iteration  5800, loss = 1.365327\n",
      "Iteration  5900, loss = 1.365327\n",
      "Iteration  6000, loss = 1.365327\n",
      "Iteration  6100, loss = 1.365327\n",
      "Iteration  6200, loss = 1.365327\n",
      "Iteration  6300, loss = 1.365327\n",
      "Iteration  6400, loss = 1.365327\n",
      "Iteration  6500, loss = 1.365327\n",
      "Iteration  6600, loss = 1.365327\n",
      "Iteration  6700, loss = 1.365327\n",
      "Iteration  6800, loss = 1.365327\n",
      "Iteration  6900, loss = 1.365327\n",
      "Iteration  7000, loss = 1.365327\n",
      "Iteration  7100, loss = 1.365327\n",
      "Iteration  7200, loss = 1.365327\n",
      "Iteration  7300, loss = 1.365327\n",
      "Iteration  7400, loss = 1.365327\n",
      "Iteration  7500, loss = 1.365327\n",
      "Iteration  7600, loss = 1.365327\n",
      "Iteration  7700, loss = 1.365327\n",
      "Iteration  7800, loss = 1.365327\n",
      "Iteration  7900, loss = 1.365327\n",
      "Iteration  8000, loss = 1.365327\n",
      "Iteration  8100, loss = 1.365327\n",
      "Iteration  8200, loss = 1.365327\n",
      "Iteration  8300, loss = 1.365327\n",
      "Iteration  8400, loss = 1.365327\n",
      "Iteration  8500, loss = 1.365327\n",
      "Iteration  8600, loss = 1.365327\n",
      "Iteration  8700, loss = 1.365327\n",
      "Iteration  8800, loss = 1.365327\n",
      "Iteration  8900, loss = 1.365327\n",
      "Iteration  9000, loss = 1.365327\n",
      "Iteration  9100, loss = 1.365327\n",
      "Iteration  9200, loss = 1.365327\n",
      "Iteration  9300, loss = 1.365327\n",
      "Iteration  9400, loss = 1.365327\n",
      "Iteration  9500, loss = 1.365327\n",
      "Iteration  9600, loss = 1.365327\n",
      "Iteration  9700, loss = 1.365327\n",
      "Iteration  9800, loss = 1.365327\n",
      "Iteration  9900, loss = 1.365327\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0993\n",
      "\n",
      "Validation loss: 1.3093415497960634 f1 score 0.09932705248990532 with data size of 26250\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.367828\n",
      "Iteration   200, loss = 1.367828\n",
      "Iteration   300, loss = 1.367828\n",
      "Iteration   400, loss = 1.367828\n",
      "Iteration   500, loss = 1.367828\n",
      "Iteration   600, loss = 1.367828\n",
      "Iteration   700, loss = 1.367828\n",
      "Iteration   800, loss = 1.367828\n",
      "Iteration   900, loss = 1.367828\n",
      "Iteration  1000, loss = 1.367828\n",
      "Iteration  1100, loss = 1.367828\n",
      "Iteration  1200, loss = 1.367828\n",
      "Iteration  1300, loss = 1.367828\n",
      "Iteration  1400, loss = 1.367828\n",
      "Iteration  1500, loss = 1.367828\n",
      "Iteration  1600, loss = 1.367828\n",
      "Iteration  1700, loss = 1.367828\n",
      "Iteration  1800, loss = 1.367828\n",
      "Iteration  1900, loss = 1.367828\n",
      "Iteration  2000, loss = 1.367828\n",
      "Iteration  2100, loss = 1.367828\n",
      "Iteration  2200, loss = 1.367828\n",
      "Iteration  2300, loss = 1.367828\n",
      "Iteration  2400, loss = 1.367828\n",
      "Iteration  2500, loss = 1.367828\n",
      "Iteration  2600, loss = 1.367828\n",
      "Iteration  2700, loss = 1.367828\n",
      "Iteration  2800, loss = 1.367828\n",
      "Iteration  2900, loss = 1.367828\n",
      "Iteration  3000, loss = 1.367828\n",
      "Iteration  3100, loss = 1.367828\n",
      "Iteration  3200, loss = 1.367828\n",
      "Iteration  3300, loss = 1.367828\n",
      "Iteration  3400, loss = 1.367828\n",
      "Iteration  3500, loss = 1.367828\n",
      "Iteration  3600, loss = 1.367828\n",
      "Iteration  3700, loss = 1.367828\n",
      "Iteration  3800, loss = 1.367828\n",
      "Iteration  3900, loss = 1.367828\n",
      "Iteration  4000, loss = 1.367828\n",
      "Iteration  4100, loss = 1.367828\n",
      "Iteration  4200, loss = 1.367828\n",
      "Iteration  4300, loss = 1.367828\n",
      "Iteration  4400, loss = 1.367828\n",
      "Iteration  4500, loss = 1.367828\n",
      "Iteration  4600, loss = 1.367828\n",
      "Iteration  4700, loss = 1.367828\n",
      "Iteration  4800, loss = 1.367828\n",
      "Iteration  4900, loss = 1.367828\n",
      "Iteration  5000, loss = 1.367828\n",
      "Iteration  5100, loss = 1.367828\n",
      "Iteration  5200, loss = 1.367828\n",
      "Iteration  5300, loss = 1.367828\n",
      "Iteration  5400, loss = 1.367828\n",
      "Iteration  5500, loss = 1.367828\n",
      "Iteration  5600, loss = 1.367828\n",
      "Iteration  5700, loss = 1.367828\n",
      "Iteration  5800, loss = 1.367828\n",
      "Iteration  5900, loss = 1.367828\n",
      "Iteration  6000, loss = 1.367828\n",
      "Iteration  6100, loss = 1.367828\n",
      "Iteration  6200, loss = 1.367828\n",
      "Iteration  6300, loss = 1.367828\n",
      "Iteration  6400, loss = 1.367828\n",
      "Iteration  6500, loss = 1.367828\n",
      "Iteration  6600, loss = 1.367828\n",
      "Iteration  6700, loss = 1.367828\n",
      "Iteration  6800, loss = 1.367828\n",
      "Iteration  6900, loss = 1.367828\n",
      "Iteration  7000, loss = 1.367828\n",
      "Iteration  7100, loss = 1.367828\n",
      "Iteration  7200, loss = 1.367828\n",
      "Iteration  7300, loss = 1.367828\n",
      "Iteration  7400, loss = 1.367828\n",
      "Iteration  7500, loss = 1.367828\n",
      "Iteration  7600, loss = 1.367828\n",
      "Iteration  7700, loss = 1.367828\n",
      "Iteration  7800, loss = 1.367828\n",
      "Iteration  7900, loss = 1.367828\n",
      "Iteration  8000, loss = 1.367828\n",
      "Iteration  8100, loss = 1.367828\n",
      "Iteration  8200, loss = 1.367828\n",
      "Iteration  8300, loss = 1.367828\n",
      "Iteration  8400, loss = 1.367828\n",
      "Iteration  8500, loss = 1.367828\n",
      "Iteration  8600, loss = 1.367828\n",
      "Iteration  8700, loss = 1.367828\n",
      "Iteration  8800, loss = 1.367828\n",
      "Iteration  8900, loss = 1.367828\n",
      "Iteration  9000, loss = 1.367828\n",
      "Iteration  9100, loss = 1.367828\n",
      "Iteration  9200, loss = 1.367828\n",
      "Iteration  9300, loss = 1.367828\n",
      "Iteration  9400, loss = 1.367828\n",
      "Iteration  9500, loss = 1.367828\n",
      "Iteration  9600, loss = 1.367828\n",
      "Iteration  9700, loss = 1.367828\n",
      "Iteration  9800, loss = 1.367828\n",
      "Iteration  9900, loss = 1.367828\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0992\n",
      "\n",
      "Validation loss: 1.3088523848940936 f1 score 0.0992058150491313 with data size of 29167\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.360218\n",
      "Iteration   200, loss = 1.360218\n",
      "Iteration   300, loss = 1.360218\n",
      "Iteration   400, loss = 1.360218\n",
      "Iteration   500, loss = 1.360218\n",
      "Iteration   600, loss = 1.360218\n",
      "Iteration   700, loss = 1.360218\n",
      "Iteration   800, loss = 1.360218\n",
      "Iteration   900, loss = 1.360218\n",
      "Iteration  1000, loss = 1.360218\n",
      "Iteration  1100, loss = 1.360218\n",
      "Iteration  1200, loss = 1.360218\n",
      "Iteration  1300, loss = 1.360218\n",
      "Iteration  1400, loss = 1.360218\n",
      "Iteration  1500, loss = 1.360218\n",
      "Iteration  1600, loss = 1.360218\n",
      "Iteration  1700, loss = 1.360218\n",
      "Iteration  1800, loss = 1.360218\n",
      "Iteration  1900, loss = 1.360218\n",
      "Iteration  2000, loss = 1.360218\n",
      "Iteration  2100, loss = 1.360218\n",
      "Iteration  2200, loss = 1.360218\n",
      "Iteration  2300, loss = 1.360218\n",
      "Iteration  2400, loss = 1.360218\n",
      "Iteration  2500, loss = 1.360218\n",
      "Iteration  2600, loss = 1.360218\n",
      "Iteration  2700, loss = 1.360218\n",
      "Iteration  2800, loss = 1.360218\n",
      "Iteration  2900, loss = 1.360218\n",
      "Iteration  3000, loss = 1.360218\n",
      "Iteration  3100, loss = 1.360218\n",
      "Iteration  3200, loss = 1.360218\n",
      "Iteration  3300, loss = 1.360218\n",
      "Iteration  3400, loss = 1.360218\n",
      "Iteration  3500, loss = 1.360218\n",
      "Iteration  3600, loss = 1.360218\n",
      "Iteration  3700, loss = 1.360218\n",
      "Iteration  3800, loss = 1.360218\n",
      "Iteration  3900, loss = 1.360218\n",
      "Iteration  4000, loss = 1.360218\n",
      "Iteration  4100, loss = 1.360218\n",
      "Iteration  4200, loss = 1.360218\n",
      "Iteration  4300, loss = 1.360218\n",
      "Iteration  4400, loss = 1.360218\n",
      "Iteration  4500, loss = 1.360218\n",
      "Iteration  4600, loss = 1.360218\n",
      "Iteration  4700, loss = 1.360218\n",
      "Iteration  4800, loss = 1.360218\n",
      "Iteration  4900, loss = 1.360218\n",
      "Iteration  5000, loss = 1.360218\n",
      "Iteration  5100, loss = 1.360218\n",
      "Iteration  5200, loss = 1.360218\n",
      "Iteration  5300, loss = 1.360218\n",
      "Iteration  5400, loss = 1.360218\n",
      "Iteration  5500, loss = 1.360218\n",
      "Iteration  5600, loss = 1.360218\n",
      "Iteration  5700, loss = 1.360218\n",
      "Iteration  5800, loss = 1.360218\n",
      "Iteration  5900, loss = 1.360218\n",
      "Iteration  6000, loss = 1.360218\n",
      "Iteration  6100, loss = 1.360218\n",
      "Iteration  6200, loss = 1.360218\n",
      "Iteration  6300, loss = 1.360218\n",
      "Iteration  6400, loss = 1.360218\n",
      "Iteration  6500, loss = 1.360218\n",
      "Iteration  6600, loss = 1.360218\n",
      "Iteration  6700, loss = 1.360218\n",
      "Iteration  6800, loss = 1.360218\n",
      "Iteration  6900, loss = 1.360218\n",
      "Iteration  7000, loss = 1.360218\n",
      "Iteration  7100, loss = 1.360218\n",
      "Iteration  7200, loss = 1.360218\n",
      "Iteration  7300, loss = 1.360218\n",
      "Iteration  7400, loss = 1.360218\n",
      "Iteration  7500, loss = 1.360218\n",
      "Iteration  7600, loss = 1.360218\n",
      "Iteration  7700, loss = 1.360218\n",
      "Iteration  7800, loss = 1.360218\n",
      "Iteration  7900, loss = 1.360218\n",
      "Iteration  8000, loss = 1.360218\n",
      "Iteration  8100, loss = 1.360218\n",
      "Iteration  8200, loss = 1.360218\n",
      "Iteration  8300, loss = 1.360218\n",
      "Iteration  8400, loss = 1.360218\n",
      "Iteration  8500, loss = 1.360218\n",
      "Iteration  8600, loss = 1.360218\n",
      "Iteration  8700, loss = 1.360218\n",
      "Iteration  8800, loss = 1.360218\n",
      "Iteration  8900, loss = 1.360218\n",
      "Iteration  9000, loss = 1.360218\n",
      "Iteration  9100, loss = 1.360218\n",
      "Iteration  9200, loss = 1.360218\n",
      "Iteration  9300, loss = 1.360218\n",
      "Iteration  9400, loss = 1.360218\n",
      "Iteration  9500, loss = 1.360218\n",
      "Iteration  9600, loss = 1.360218\n",
      "Iteration  9700, loss = 1.360218\n",
      "Iteration  9800, loss = 1.360218\n",
      "Iteration  9900, loss = 1.360218\n",
      " Accuracy: 79.65%\n",
      " F1 Score: 0.0990\n",
      "\n",
      "Validation loss: 1.299719680666388 f1 score 0.09904864718979779 with data size of 32813\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.358742\n",
      "Iteration   200, loss = 1.358742\n",
      "Iteration   300, loss = 1.358742\n",
      "Iteration   400, loss = 1.358742\n",
      "Iteration   500, loss = 1.358742\n",
      "Iteration   600, loss = 1.358742\n",
      "Iteration   700, loss = 1.358742\n",
      "Iteration   800, loss = 1.358742\n",
      "Iteration   900, loss = 1.358742\n",
      "Iteration  1000, loss = 1.358742\n",
      "Iteration  1100, loss = 1.358742\n",
      "Iteration  1200, loss = 1.358742\n",
      "Iteration  1300, loss = 1.358742\n",
      "Iteration  1400, loss = 1.358742\n",
      "Iteration  1500, loss = 1.358742\n",
      "Iteration  1600, loss = 1.358742\n",
      "Iteration  1700, loss = 1.358742\n",
      "Iteration  1800, loss = 1.358742\n",
      "Iteration  1900, loss = 1.358742\n",
      "Iteration  2000, loss = 1.358742\n",
      "Iteration  2100, loss = 1.358742\n",
      "Iteration  2200, loss = 1.358742\n",
      "Iteration  2300, loss = 1.358742\n",
      "Iteration  2400, loss = 1.358742\n",
      "Iteration  2500, loss = 1.358742\n",
      "Iteration  2600, loss = 1.358742\n",
      "Iteration  2700, loss = 1.358742\n",
      "Iteration  2800, loss = 1.358742\n",
      "Iteration  2900, loss = 1.358742\n",
      "Iteration  3000, loss = 1.358742\n",
      "Iteration  3100, loss = 1.358742\n",
      "Iteration  3200, loss = 1.358742\n",
      "Iteration  3300, loss = 1.358742\n",
      "Iteration  3400, loss = 1.358742\n",
      "Iteration  3500, loss = 1.358742\n",
      "Iteration  3600, loss = 1.358742\n",
      "Iteration  3700, loss = 1.358742\n",
      "Iteration  3800, loss = 1.358742\n",
      "Iteration  3900, loss = 1.358742\n",
      "Iteration  4000, loss = 1.358742\n",
      "Iteration  4100, loss = 1.358742\n",
      "Iteration  4200, loss = 1.358742\n",
      "Iteration  4300, loss = 1.358742\n",
      "Iteration  4400, loss = 1.358742\n",
      "Iteration  4500, loss = 1.358742\n",
      "Iteration  4600, loss = 1.358742\n",
      "Iteration  4700, loss = 1.358742\n",
      "Iteration  4800, loss = 1.358742\n",
      "Iteration  4900, loss = 1.358742\n",
      "Iteration  5000, loss = 1.358742\n",
      "Iteration  5100, loss = 1.358742\n",
      "Iteration  5200, loss = 1.358742\n",
      "Iteration  5300, loss = 1.358742\n",
      "Iteration  5400, loss = 1.358742\n",
      "Iteration  5500, loss = 1.358742\n",
      "Iteration  5600, loss = 1.358742\n",
      "Iteration  5700, loss = 1.358742\n",
      "Iteration  5800, loss = 1.358742\n",
      "Iteration  5900, loss = 1.358742\n",
      "Iteration  6000, loss = 1.358742\n",
      "Iteration  6100, loss = 1.358742\n",
      "Iteration  6200, loss = 1.358742\n",
      "Iteration  6300, loss = 1.358742\n",
      "Iteration  6400, loss = 1.358742\n",
      "Iteration  6500, loss = 1.358742\n",
      "Iteration  6600, loss = 1.358742\n",
      "Iteration  6700, loss = 1.358742\n",
      "Iteration  6800, loss = 1.358742\n",
      "Iteration  6900, loss = 1.358742\n",
      "Iteration  7000, loss = 1.358742\n",
      "Iteration  7100, loss = 1.358742\n",
      "Iteration  7200, loss = 1.358742\n",
      "Iteration  7300, loss = 1.358742\n",
      "Iteration  7400, loss = 1.358742\n",
      "Iteration  7500, loss = 1.358742\n",
      "Iteration  7600, loss = 1.358742\n",
      "Iteration  7700, loss = 1.358742\n",
      "Iteration  7800, loss = 1.358742\n",
      "Iteration  7900, loss = 1.358742\n",
      "Iteration  8000, loss = 1.358742\n",
      "Iteration  8100, loss = 1.358742\n",
      "Iteration  8200, loss = 1.358742\n",
      "Iteration  8300, loss = 1.358742\n",
      "Iteration  8400, loss = 1.358742\n",
      "Iteration  8500, loss = 1.358742\n",
      "Iteration  8600, loss = 1.358742\n",
      "Iteration  8700, loss = 1.358742\n",
      "Iteration  8800, loss = 1.358742\n",
      "Iteration  8900, loss = 1.358742\n",
      "Iteration  9000, loss = 1.358742\n",
      "Iteration  9100, loss = 1.358742\n",
      "Iteration  9200, loss = 1.358742\n",
      "Iteration  9300, loss = 1.358742\n",
      "Iteration  9400, loss = 1.358742\n",
      "Iteration  9500, loss = 1.358742\n",
      "Iteration  9600, loss = 1.358742\n",
      "Iteration  9700, loss = 1.358742\n",
      "Iteration  9800, loss = 1.358742\n",
      "Iteration  9900, loss = 1.358742\n",
      " Accuracy: 79.65%\n",
      " F1 Score: 0.0988\n",
      "\n",
      "Validation loss: 1.2973170925333588 f1 score 0.09881209503239692 with data size of 37501\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.364221\n",
      "Iteration   200, loss = 1.364221\n",
      "Iteration   300, loss = 1.364221\n",
      "Iteration   400, loss = 1.364221\n",
      "Iteration   500, loss = 1.364221\n",
      "Iteration   600, loss = 1.364221\n",
      "Iteration   700, loss = 1.364221\n",
      "Iteration   800, loss = 1.364221\n",
      "Iteration   900, loss = 1.364221\n",
      "Iteration  1000, loss = 1.364221\n",
      "Iteration  1100, loss = 1.364221\n",
      "Iteration  1200, loss = 1.364221\n",
      "Iteration  1300, loss = 1.364221\n",
      "Iteration  1400, loss = 1.364221\n",
      "Iteration  1500, loss = 1.364221\n",
      "Iteration  1600, loss = 1.364221\n",
      "Iteration  1700, loss = 1.364221\n",
      "Iteration  1800, loss = 1.364221\n",
      "Iteration  1900, loss = 1.364221\n",
      "Iteration  2000, loss = 1.364221\n",
      "Iteration  2100, loss = 1.364221\n",
      "Iteration  2200, loss = 1.364221\n",
      "Iteration  2300, loss = 1.364221\n",
      "Iteration  2400, loss = 1.364221\n",
      "Iteration  2500, loss = 1.364221\n",
      "Iteration  2600, loss = 1.364221\n",
      "Iteration  2700, loss = 1.364221\n",
      "Iteration  2800, loss = 1.364221\n",
      "Iteration  2900, loss = 1.364221\n",
      "Iteration  3000, loss = 1.364221\n",
      "Iteration  3100, loss = 1.364221\n",
      "Iteration  3200, loss = 1.364221\n",
      "Iteration  3300, loss = 1.364221\n",
      "Iteration  3400, loss = 1.364221\n",
      "Iteration  3500, loss = 1.364221\n",
      "Iteration  3600, loss = 1.364221\n",
      "Iteration  3700, loss = 1.364221\n",
      "Iteration  3800, loss = 1.364221\n",
      "Iteration  3900, loss = 1.364221\n",
      "Iteration  4000, loss = 1.364221\n",
      "Iteration  4100, loss = 1.364221\n",
      "Iteration  4200, loss = 1.364221\n",
      "Iteration  4300, loss = 1.364221\n",
      "Iteration  4400, loss = 1.364221\n",
      "Iteration  4500, loss = 1.364221\n",
      "Iteration  4600, loss = 1.364221\n",
      "Iteration  4700, loss = 1.364221\n",
      "Iteration  4800, loss = 1.364221\n",
      "Iteration  4900, loss = 1.364221\n",
      "Iteration  5000, loss = 1.364221\n",
      "Iteration  5100, loss = 1.364221\n",
      "Iteration  5200, loss = 1.364221\n",
      "Iteration  5300, loss = 1.364221\n",
      "Iteration  5400, loss = 1.364221\n",
      "Iteration  5500, loss = 1.364221\n",
      "Iteration  5600, loss = 1.364221\n",
      "Iteration  5700, loss = 1.364221\n",
      "Iteration  5800, loss = 1.364221\n",
      "Iteration  5900, loss = 1.364221\n",
      "Iteration  6000, loss = 1.364221\n",
      "Iteration  6100, loss = 1.364221\n",
      "Iteration  6200, loss = 1.364221\n",
      "Iteration  6300, loss = 1.364221\n",
      "Iteration  6400, loss = 1.364221\n",
      "Iteration  6500, loss = 1.364221\n",
      "Iteration  6600, loss = 1.364221\n",
      "Iteration  6700, loss = 1.364221\n",
      "Iteration  6800, loss = 1.364221\n",
      "Iteration  6900, loss = 1.364221\n",
      "Iteration  7000, loss = 1.364221\n",
      "Iteration  7100, loss = 1.364221\n",
      "Iteration  7200, loss = 1.364221\n",
      "Iteration  7300, loss = 1.364221\n",
      "Iteration  7400, loss = 1.364221\n",
      "Iteration  7500, loss = 1.364221\n",
      "Iteration  7600, loss = 1.364221\n",
      "Iteration  7700, loss = 1.364221\n",
      "Iteration  7800, loss = 1.364221\n",
      "Iteration  7900, loss = 1.364221\n",
      "Iteration  8000, loss = 1.364221\n",
      "Iteration  8100, loss = 1.364221\n",
      "Iteration  8200, loss = 1.364221\n",
      "Iteration  8300, loss = 1.364221\n",
      "Iteration  8400, loss = 1.364221\n",
      "Iteration  8500, loss = 1.364221\n",
      "Iteration  8600, loss = 1.364221\n",
      "Iteration  8700, loss = 1.364221\n",
      "Iteration  8800, loss = 1.364221\n",
      "Iteration  8900, loss = 1.364221\n",
      "Iteration  9000, loss = 1.364221\n",
      "Iteration  9100, loss = 1.364221\n",
      "Iteration  9200, loss = 1.364221\n",
      "Iteration  9300, loss = 1.364221\n",
      "Iteration  9400, loss = 1.364221\n",
      "Iteration  9500, loss = 1.364221\n",
      "Iteration  9600, loss = 1.364221\n",
      "Iteration  9700, loss = 1.364221\n",
      "Iteration  9800, loss = 1.364221\n",
      "Iteration  9900, loss = 1.364221\n",
      " Accuracy: 79.62%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3050343578390213 f1 score 0.09952861952861904 with data size of 43751\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.371632\n",
      "Iteration   200, loss = 1.371632\n",
      "Iteration   300, loss = 1.371632\n",
      "Iteration   400, loss = 1.371632\n",
      "Iteration   500, loss = 1.371632\n",
      "Iteration   600, loss = 1.371632\n",
      "Iteration   700, loss = 1.371632\n",
      "Iteration   800, loss = 1.371632\n",
      "Iteration   900, loss = 1.371632\n",
      "Iteration  1000, loss = 1.371632\n",
      "Iteration  1100, loss = 1.371632\n",
      "Iteration  1200, loss = 1.371632\n",
      "Iteration  1300, loss = 1.371632\n",
      "Iteration  1400, loss = 1.371632\n",
      "Iteration  1500, loss = 1.371632\n",
      "Iteration  1600, loss = 1.371632\n",
      "Iteration  1700, loss = 1.371632\n",
      "Iteration  1800, loss = 1.371632\n",
      "Iteration  1900, loss = 1.371632\n",
      "Iteration  2000, loss = 1.371632\n",
      "Iteration  2100, loss = 1.371632\n",
      "Iteration  2200, loss = 1.371632\n",
      "Iteration  2300, loss = 1.371632\n",
      "Iteration  2400, loss = 1.371632\n",
      "Iteration  2500, loss = 1.371632\n",
      "Iteration  2600, loss = 1.371632\n",
      "Iteration  2700, loss = 1.371632\n",
      "Iteration  2800, loss = 1.371632\n",
      "Iteration  2900, loss = 1.371632\n",
      "Iteration  3000, loss = 1.371632\n",
      "Iteration  3100, loss = 1.371632\n",
      "Iteration  3200, loss = 1.371632\n",
      "Iteration  3300, loss = 1.371632\n",
      "Iteration  3400, loss = 1.371632\n",
      "Iteration  3500, loss = 1.371632\n",
      "Iteration  3600, loss = 1.371632\n",
      "Iteration  3700, loss = 1.371632\n",
      "Iteration  3800, loss = 1.371632\n",
      "Iteration  3900, loss = 1.371632\n",
      "Iteration  4000, loss = 1.371632\n",
      "Iteration  4100, loss = 1.371632\n",
      "Iteration  4200, loss = 1.371632\n",
      "Iteration  4300, loss = 1.371632\n",
      "Iteration  4400, loss = 1.371632\n",
      "Iteration  4500, loss = 1.371632\n",
      "Iteration  4600, loss = 1.371632\n",
      "Iteration  4700, loss = 1.371632\n",
      "Iteration  4800, loss = 1.371632\n",
      "Iteration  4900, loss = 1.371632\n",
      "Iteration  5000, loss = 1.371632\n",
      "Iteration  5100, loss = 1.371632\n",
      "Iteration  5200, loss = 1.371632\n",
      "Iteration  5300, loss = 1.371632\n",
      "Iteration  5400, loss = 1.371632\n",
      "Iteration  5500, loss = 1.371632\n",
      "Iteration  5600, loss = 1.371632\n",
      "Iteration  5700, loss = 1.371632\n",
      "Iteration  5800, loss = 1.371632\n",
      "Iteration  5900, loss = 1.371632\n",
      "Iteration  6000, loss = 1.371632\n",
      "Iteration  6100, loss = 1.371632\n",
      "Iteration  6200, loss = 1.371632\n",
      "Iteration  6300, loss = 1.371632\n",
      "Iteration  6400, loss = 1.371632\n",
      "Iteration  6500, loss = 1.371632\n",
      "Iteration  6600, loss = 1.371632\n",
      "Iteration  6700, loss = 1.371632\n",
      "Iteration  6800, loss = 1.371632\n",
      "Iteration  6900, loss = 1.371632\n",
      "Iteration  7000, loss = 1.371632\n",
      "Iteration  7100, loss = 1.371632\n",
      "Iteration  7200, loss = 1.371632\n",
      "Iteration  7300, loss = 1.371632\n",
      "Iteration  7400, loss = 1.371632\n",
      "Iteration  7500, loss = 1.371632\n",
      "Iteration  7600, loss = 1.371632\n",
      "Iteration  7700, loss = 1.371632\n",
      "Iteration  7800, loss = 1.371632\n",
      "Iteration  7900, loss = 1.371632\n",
      "Iteration  8000, loss = 1.371632\n",
      "Iteration  8100, loss = 1.371632\n",
      "Iteration  8200, loss = 1.371632\n",
      "Iteration  8300, loss = 1.371632\n",
      "Iteration  8400, loss = 1.371632\n",
      "Iteration  8500, loss = 1.371632\n",
      "Iteration  8600, loss = 1.371632\n",
      "Iteration  8700, loss = 1.371632\n",
      "Iteration  8800, loss = 1.371632\n",
      "Iteration  8900, loss = 1.371632\n",
      "Iteration  9000, loss = 1.371632\n",
      "Iteration  9100, loss = 1.371632\n",
      "Iteration  9200, loss = 1.371632\n",
      "Iteration  9300, loss = 1.371632\n",
      "Iteration  9400, loss = 1.371632\n",
      "Iteration  9500, loss = 1.371632\n",
      "Iteration  9600, loss = 1.371632\n",
      "Iteration  9700, loss = 1.371632\n",
      "Iteration  9800, loss = 1.371632\n",
      "Iteration  9900, loss = 1.371632\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3114848245079949 f1 score 0.09947503028671377 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.371632\n",
      "Iteration   200, loss = 1.371632\n",
      "Iteration   300, loss = 1.371632\n",
      "Iteration   400, loss = 1.371632\n",
      "Iteration   500, loss = 1.371632\n",
      "Iteration   600, loss = 1.371632\n",
      "Iteration   700, loss = 1.371632\n",
      "Iteration   800, loss = 1.371632\n",
      "Iteration   900, loss = 1.371632\n",
      "Iteration  1000, loss = 1.371632\n",
      "Iteration  1100, loss = 1.371632\n",
      "Iteration  1200, loss = 1.371632\n",
      "Iteration  1300, loss = 1.371632\n",
      "Iteration  1400, loss = 1.371632\n",
      "Iteration  1500, loss = 1.371632\n",
      "Iteration  1600, loss = 1.371632\n",
      "Iteration  1700, loss = 1.371632\n",
      "Iteration  1800, loss = 1.371632\n",
      "Iteration  1900, loss = 1.371632\n",
      "Iteration  2000, loss = 1.371632\n",
      "Iteration  2100, loss = 1.371632\n",
      "Iteration  2200, loss = 1.371632\n",
      "Iteration  2300, loss = 1.371632\n",
      "Iteration  2400, loss = 1.371632\n",
      "Iteration  2500, loss = 1.371632\n",
      "Iteration  2600, loss = 1.371632\n",
      "Iteration  2700, loss = 1.371632\n",
      "Iteration  2800, loss = 1.371632\n",
      "Iteration  2900, loss = 1.371632\n",
      "Iteration  3000, loss = 1.371632\n",
      "Iteration  3100, loss = 1.371632\n",
      "Iteration  3200, loss = 1.371632\n",
      "Iteration  3300, loss = 1.371632\n",
      "Iteration  3400, loss = 1.371632\n",
      "Iteration  3500, loss = 1.371632\n",
      "Iteration  3600, loss = 1.371632\n",
      "Iteration  3700, loss = 1.371632\n",
      "Iteration  3800, loss = 1.371632\n",
      "Iteration  3900, loss = 1.371632\n",
      "Iteration  4000, loss = 1.371632\n",
      "Iteration  4100, loss = 1.371632\n",
      "Iteration  4200, loss = 1.371632\n",
      "Iteration  4300, loss = 1.371632\n",
      "Iteration  4400, loss = 1.371632\n",
      "Iteration  4500, loss = 1.371632\n",
      "Iteration  4600, loss = 1.371632\n",
      "Iteration  4700, loss = 1.371632\n",
      "Iteration  4800, loss = 1.371632\n",
      "Iteration  4900, loss = 1.371632\n",
      "Iteration  5000, loss = 1.371632\n",
      "Iteration  5100, loss = 1.371632\n",
      "Iteration  5200, loss = 1.371632\n",
      "Iteration  5300, loss = 1.371632\n",
      "Iteration  5400, loss = 1.371632\n",
      "Iteration  5500, loss = 1.371632\n",
      "Iteration  5600, loss = 1.371632\n",
      "Iteration  5700, loss = 1.371632\n",
      "Iteration  5800, loss = 1.371632\n",
      "Iteration  5900, loss = 1.371632\n",
      "Iteration  6000, loss = 1.371632\n",
      "Iteration  6100, loss = 1.371632\n",
      "Iteration  6200, loss = 1.371632\n",
      "Iteration  6300, loss = 1.371632\n",
      "Iteration  6400, loss = 1.371632\n",
      "Iteration  6500, loss = 1.371632\n",
      "Iteration  6600, loss = 1.371632\n",
      "Iteration  6700, loss = 1.371632\n",
      "Iteration  6800, loss = 1.371632\n",
      "Iteration  6900, loss = 1.371632\n",
      "Iteration  7000, loss = 1.371632\n",
      "Iteration  7100, loss = 1.371632\n",
      "Iteration  7200, loss = 1.371632\n",
      "Iteration  7300, loss = 1.371632\n",
      "Iteration  7400, loss = 1.371632\n",
      "Iteration  7500, loss = 1.371632\n",
      "Iteration  7600, loss = 1.371632\n",
      "Iteration  7700, loss = 1.371632\n",
      "Iteration  7800, loss = 1.371632\n",
      "Iteration  7900, loss = 1.371632\n",
      "Iteration  8000, loss = 1.371632\n",
      "Iteration  8100, loss = 1.371632\n",
      "Iteration  8200, loss = 1.371632\n",
      "Iteration  8300, loss = 1.371632\n",
      "Iteration  8400, loss = 1.371632\n",
      "Iteration  8500, loss = 1.371632\n",
      "Iteration  8600, loss = 1.371632\n",
      "Iteration  8700, loss = 1.371632\n",
      "Iteration  8800, loss = 1.371632\n",
      "Iteration  8900, loss = 1.371632\n",
      "Iteration  9000, loss = 1.371632\n",
      "Iteration  9100, loss = 1.371632\n",
      "Iteration  9200, loss = 1.371632\n",
      "Iteration  9300, loss = 1.371632\n",
      "Iteration  9400, loss = 1.371632\n",
      "Iteration  9500, loss = 1.371632\n",
      "Iteration  9600, loss = 1.371632\n",
      "Iteration  9700, loss = 1.371632\n",
      "Iteration  9800, loss = 1.371632\n",
      "Iteration  9900, loss = 1.371632\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3114848245079949 f1 score 0.09947503028671377 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.371632\n",
      "Iteration   200, loss = 1.371632\n",
      "Iteration   300, loss = 1.371632\n",
      "Iteration   400, loss = 1.371632\n",
      "Iteration   500, loss = 1.371632\n",
      "Iteration   600, loss = 1.371632\n",
      "Iteration   700, loss = 1.371632\n",
      "Iteration   800, loss = 1.371632\n",
      "Iteration   900, loss = 1.371632\n",
      "Iteration  1000, loss = 1.371632\n",
      "Iteration  1100, loss = 1.371632\n",
      "Iteration  1200, loss = 1.371632\n",
      "Iteration  1300, loss = 1.371632\n",
      "Iteration  1400, loss = 1.371632\n",
      "Iteration  1500, loss = 1.371632\n",
      "Iteration  1600, loss = 1.371632\n",
      "Iteration  1700, loss = 1.371632\n",
      "Iteration  1800, loss = 1.371632\n",
      "Iteration  1900, loss = 1.371632\n",
      "Iteration  2000, loss = 1.371632\n",
      "Iteration  2100, loss = 1.371632\n",
      "Iteration  2200, loss = 1.371632\n",
      "Iteration  2300, loss = 1.371632\n",
      "Iteration  2400, loss = 1.371632\n",
      "Iteration  2500, loss = 1.371632\n",
      "Iteration  2600, loss = 1.371632\n",
      "Iteration  2700, loss = 1.371632\n",
      "Iteration  2800, loss = 1.371632\n",
      "Iteration  2900, loss = 1.371632\n",
      "Iteration  3000, loss = 1.371632\n",
      "Iteration  3100, loss = 1.371632\n",
      "Iteration  3200, loss = 1.371632\n",
      "Iteration  3300, loss = 1.371632\n",
      "Iteration  3400, loss = 1.371632\n",
      "Iteration  3500, loss = 1.371632\n",
      "Iteration  3600, loss = 1.371632\n",
      "Iteration  3700, loss = 1.371632\n",
      "Iteration  3800, loss = 1.371632\n",
      "Iteration  3900, loss = 1.371632\n",
      "Iteration  4000, loss = 1.371632\n",
      "Iteration  4100, loss = 1.371632\n",
      "Iteration  4200, loss = 1.371632\n",
      "Iteration  4300, loss = 1.371632\n",
      "Iteration  4400, loss = 1.371632\n",
      "Iteration  4500, loss = 1.371632\n",
      "Iteration  4600, loss = 1.371632\n",
      "Iteration  4700, loss = 1.371632\n",
      "Iteration  4800, loss = 1.371632\n",
      "Iteration  4900, loss = 1.371632\n",
      "Iteration  5000, loss = 1.371632\n",
      "Iteration  5100, loss = 1.371632\n",
      "Iteration  5200, loss = 1.371632\n",
      "Iteration  5300, loss = 1.371632\n",
      "Iteration  5400, loss = 1.371632\n",
      "Iteration  5500, loss = 1.371632\n",
      "Iteration  5600, loss = 1.371632\n",
      "Iteration  5700, loss = 1.371632\n",
      "Iteration  5800, loss = 1.371632\n",
      "Iteration  5900, loss = 1.371632\n",
      "Iteration  6000, loss = 1.371632\n",
      "Iteration  6100, loss = 1.371632\n",
      "Iteration  6200, loss = 1.371632\n",
      "Iteration  6300, loss = 1.371632\n",
      "Iteration  6400, loss = 1.371632\n",
      "Iteration  6500, loss = 1.371632\n",
      "Iteration  6600, loss = 1.371632\n",
      "Iteration  6700, loss = 1.371632\n",
      "Iteration  6800, loss = 1.371632\n",
      "Iteration  6900, loss = 1.371632\n",
      "Iteration  7000, loss = 1.371632\n",
      "Iteration  7100, loss = 1.371632\n",
      "Iteration  7200, loss = 1.371632\n",
      "Iteration  7300, loss = 1.371632\n",
      "Iteration  7400, loss = 1.371632\n",
      "Iteration  7500, loss = 1.371632\n",
      "Iteration  7600, loss = 1.371632\n",
      "Iteration  7700, loss = 1.371632\n",
      "Iteration  7800, loss = 1.371632\n",
      "Iteration  7900, loss = 1.371632\n",
      "Iteration  8000, loss = 1.371632\n",
      "Iteration  8100, loss = 1.371632\n",
      "Iteration  8200, loss = 1.371632\n",
      "Iteration  8300, loss = 1.371632\n",
      "Iteration  8400, loss = 1.371632\n",
      "Iteration  8500, loss = 1.371632\n",
      "Iteration  8600, loss = 1.371632\n",
      "Iteration  8700, loss = 1.371632\n",
      "Iteration  8800, loss = 1.371632\n",
      "Iteration  8900, loss = 1.371632\n",
      "Iteration  9000, loss = 1.371632\n",
      "Iteration  9100, loss = 1.371632\n",
      "Iteration  9200, loss = 1.371632\n",
      "Iteration  9300, loss = 1.371632\n",
      "Iteration  9400, loss = 1.371632\n",
      "Iteration  9500, loss = 1.371632\n",
      "Iteration  9600, loss = 1.371632\n",
      "Iteration  9700, loss = 1.371632\n",
      "Iteration  9800, loss = 1.371632\n",
      "Iteration  9900, loss = 1.371632\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3114848245079949 f1 score 0.09947503028671377 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.371632\n",
      "Iteration   200, loss = 1.371632\n",
      "Iteration   300, loss = 1.371632\n",
      "Iteration   400, loss = 1.371632\n",
      "Iteration   500, loss = 1.371632\n",
      "Iteration   600, loss = 1.371632\n",
      "Iteration   700, loss = 1.371632\n",
      "Iteration   800, loss = 1.371632\n",
      "Iteration   900, loss = 1.371632\n",
      "Iteration  1000, loss = 1.371632\n",
      "Iteration  1100, loss = 1.371632\n",
      "Iteration  1200, loss = 1.371632\n",
      "Iteration  1300, loss = 1.371632\n",
      "Iteration  1400, loss = 1.371632\n",
      "Iteration  1500, loss = 1.371632\n",
      "Iteration  1600, loss = 1.371632\n",
      "Iteration  1700, loss = 1.371632\n",
      "Iteration  1800, loss = 1.371632\n",
      "Iteration  1900, loss = 1.371632\n",
      "Iteration  2000, loss = 1.371632\n",
      "Iteration  2100, loss = 1.371632\n",
      "Iteration  2200, loss = 1.371632\n",
      "Iteration  2300, loss = 1.371632\n",
      "Iteration  2400, loss = 1.371632\n",
      "Iteration  2500, loss = 1.371632\n",
      "Iteration  2600, loss = 1.371632\n",
      "Iteration  2700, loss = 1.371632\n",
      "Iteration  2800, loss = 1.371632\n",
      "Iteration  2900, loss = 1.371632\n",
      "Iteration  3000, loss = 1.371632\n",
      "Iteration  3100, loss = 1.371632\n",
      "Iteration  3200, loss = 1.371632\n",
      "Iteration  3300, loss = 1.371632\n",
      "Iteration  3400, loss = 1.371632\n",
      "Iteration  3500, loss = 1.371632\n",
      "Iteration  3600, loss = 1.371632\n",
      "Iteration  3700, loss = 1.371632\n",
      "Iteration  3800, loss = 1.371632\n",
      "Iteration  3900, loss = 1.371632\n",
      "Iteration  4000, loss = 1.371632\n",
      "Iteration  4100, loss = 1.371632\n",
      "Iteration  4200, loss = 1.371632\n",
      "Iteration  4300, loss = 1.371632\n",
      "Iteration  4400, loss = 1.371632\n",
      "Iteration  4500, loss = 1.371632\n",
      "Iteration  4600, loss = 1.371632\n",
      "Iteration  4700, loss = 1.371632\n",
      "Iteration  4800, loss = 1.371632\n",
      "Iteration  4900, loss = 1.371632\n",
      "Iteration  5000, loss = 1.371632\n",
      "Iteration  5100, loss = 1.371632\n",
      "Iteration  5200, loss = 1.371632\n",
      "Iteration  5300, loss = 1.371632\n",
      "Iteration  5400, loss = 1.371632\n",
      "Iteration  5500, loss = 1.371632\n",
      "Iteration  5600, loss = 1.371632\n",
      "Iteration  5700, loss = 1.371632\n",
      "Iteration  5800, loss = 1.371632\n",
      "Iteration  5900, loss = 1.371632\n",
      "Iteration  6000, loss = 1.371632\n",
      "Iteration  6100, loss = 1.371632\n",
      "Iteration  6200, loss = 1.371632\n",
      "Iteration  6300, loss = 1.371632\n",
      "Iteration  6400, loss = 1.371632\n",
      "Iteration  6500, loss = 1.371632\n",
      "Iteration  6600, loss = 1.371632\n",
      "Iteration  6700, loss = 1.371632\n",
      "Iteration  6800, loss = 1.371632\n",
      "Iteration  6900, loss = 1.371632\n",
      "Iteration  7000, loss = 1.371632\n",
      "Iteration  7100, loss = 1.371632\n",
      "Iteration  7200, loss = 1.371632\n",
      "Iteration  7300, loss = 1.371632\n",
      "Iteration  7400, loss = 1.371632\n",
      "Iteration  7500, loss = 1.371632\n",
      "Iteration  7600, loss = 1.371632\n",
      "Iteration  7700, loss = 1.371632\n",
      "Iteration  7800, loss = 1.371632\n",
      "Iteration  7900, loss = 1.371632\n",
      "Iteration  8000, loss = 1.371632\n",
      "Iteration  8100, loss = 1.371632\n",
      "Iteration  8200, loss = 1.371632\n",
      "Iteration  8300, loss = 1.371632\n",
      "Iteration  8400, loss = 1.371632\n",
      "Iteration  8500, loss = 1.371632\n",
      "Iteration  8600, loss = 1.371632\n",
      "Iteration  8700, loss = 1.371632\n",
      "Iteration  8800, loss = 1.371632\n",
      "Iteration  8900, loss = 1.371632\n",
      "Iteration  9000, loss = 1.371632\n",
      "Iteration  9100, loss = 1.371632\n",
      "Iteration  9200, loss = 1.371632\n",
      "Iteration  9300, loss = 1.371632\n",
      "Iteration  9400, loss = 1.371632\n",
      "Iteration  9500, loss = 1.371632\n",
      "Iteration  9600, loss = 1.371632\n",
      "Iteration  9700, loss = 1.371632\n",
      "Iteration  9800, loss = 1.371632\n",
      "Iteration  9900, loss = 1.371632\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3114848245079949 f1 score 0.09947503028671377 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 1.371632\n",
      "Iteration   200, loss = 1.371632\n",
      "Iteration   300, loss = 1.371632\n",
      "Iteration   400, loss = 1.371632\n",
      "Iteration   500, loss = 1.371632\n",
      "Iteration   600, loss = 1.371632\n",
      "Iteration   700, loss = 1.371632\n",
      "Iteration   800, loss = 1.371632\n",
      "Iteration   900, loss = 1.371632\n",
      "Iteration  1000, loss = 1.371632\n",
      "Iteration  1100, loss = 1.371632\n",
      "Iteration  1200, loss = 1.371632\n",
      "Iteration  1300, loss = 1.371632\n",
      "Iteration  1400, loss = 1.371632\n",
      "Iteration  1500, loss = 1.371632\n",
      "Iteration  1600, loss = 1.371632\n",
      "Iteration  1700, loss = 1.371632\n",
      "Iteration  1800, loss = 1.371632\n",
      "Iteration  1900, loss = 1.371632\n",
      "Iteration  2000, loss = 1.371632\n",
      "Iteration  2100, loss = 1.371632\n",
      "Iteration  2200, loss = 1.371632\n",
      "Iteration  2300, loss = 1.371632\n",
      "Iteration  2400, loss = 1.371632\n",
      "Iteration  2500, loss = 1.371632\n",
      "Iteration  2600, loss = 1.371632\n",
      "Iteration  2700, loss = 1.371632\n",
      "Iteration  2800, loss = 1.371632\n",
      "Iteration  2900, loss = 1.371632\n",
      "Iteration  3000, loss = 1.371632\n",
      "Iteration  3100, loss = 1.371632\n",
      "Iteration  3200, loss = 1.371632\n",
      "Iteration  3300, loss = 1.371632\n",
      "Iteration  3400, loss = 1.371632\n",
      "Iteration  3500, loss = 1.371632\n",
      "Iteration  3600, loss = 1.371632\n",
      "Iteration  3700, loss = 1.371632\n",
      "Iteration  3800, loss = 1.371632\n",
      "Iteration  3900, loss = 1.371632\n",
      "Iteration  4000, loss = 1.371632\n",
      "Iteration  4100, loss = 1.371632\n",
      "Iteration  4200, loss = 1.371632\n",
      "Iteration  4300, loss = 1.371632\n",
      "Iteration  4400, loss = 1.371632\n",
      "Iteration  4500, loss = 1.371632\n",
      "Iteration  4600, loss = 1.371632\n",
      "Iteration  4700, loss = 1.371632\n",
      "Iteration  4800, loss = 1.371632\n",
      "Iteration  4900, loss = 1.371632\n",
      "Iteration  5000, loss = 1.371632\n",
      "Iteration  5100, loss = 1.371632\n",
      "Iteration  5200, loss = 1.371632\n",
      "Iteration  5300, loss = 1.371632\n",
      "Iteration  5400, loss = 1.371632\n",
      "Iteration  5500, loss = 1.371632\n",
      "Iteration  5600, loss = 1.371632\n",
      "Iteration  5700, loss = 1.371632\n",
      "Iteration  5800, loss = 1.371632\n",
      "Iteration  5900, loss = 1.371632\n",
      "Iteration  6000, loss = 1.371632\n",
      "Iteration  6100, loss = 1.371632\n",
      "Iteration  6200, loss = 1.371632\n",
      "Iteration  6300, loss = 1.371632\n",
      "Iteration  6400, loss = 1.371632\n",
      "Iteration  6500, loss = 1.371632\n",
      "Iteration  6600, loss = 1.371632\n",
      "Iteration  6700, loss = 1.371632\n",
      "Iteration  6800, loss = 1.371632\n",
      "Iteration  6900, loss = 1.371632\n",
      "Iteration  7000, loss = 1.371632\n",
      "Iteration  7100, loss = 1.371632\n",
      "Iteration  7200, loss = 1.371632\n",
      "Iteration  7300, loss = 1.371632\n",
      "Iteration  7400, loss = 1.371632\n",
      "Iteration  7500, loss = 1.371632\n",
      "Iteration  7600, loss = 1.371632\n",
      "Iteration  7700, loss = 1.371632\n",
      "Iteration  7800, loss = 1.371632\n",
      "Iteration  7900, loss = 1.371632\n",
      "Iteration  8000, loss = 1.371632\n",
      "Iteration  8100, loss = 1.371632\n",
      "Iteration  8200, loss = 1.371632\n",
      "Iteration  8300, loss = 1.371632\n",
      "Iteration  8400, loss = 1.371632\n",
      "Iteration  8500, loss = 1.371632\n",
      "Iteration  8600, loss = 1.371632\n",
      "Iteration  8700, loss = 1.371632\n",
      "Iteration  8800, loss = 1.371632\n",
      "Iteration  8900, loss = 1.371632\n",
      "Iteration  9000, loss = 1.371632\n",
      "Iteration  9100, loss = 1.371632\n",
      "Iteration  9200, loss = 1.371632\n",
      "Iteration  9300, loss = 1.371632\n",
      "Iteration  9400, loss = 1.371632\n",
      "Iteration  9500, loss = 1.371632\n",
      "Iteration  9600, loss = 1.371632\n",
      "Iteration  9700, loss = 1.371632\n",
      "Iteration  9800, loss = 1.371632\n",
      "Iteration  9900, loss = 1.371632\n",
      " Accuracy: 79.61%\n",
      " F1 Score: 0.0995\n",
      "\n",
      "Validation loss: 1.3114848245079949 f1 score 0.09947503028671377 with data size of 46564\n",
      "For lambda: 1.0 best f1: 0.09969056908381495\n"
     ]
    }
   ],
   "source": [
    "# This cell takes a lot of time to run. Better to skip it and run the next one to load the stored results\n",
    "\n",
    "m = X_train_data.shape[0] // 5\n",
    "X_train_over, X_val_over = X_train_data[m:], X_train_data[:m]\n",
    "Y_train_over, Y_val_over = Y_train_data[m:], Y_train_data[:m]\n",
    "\n",
    "\n",
    "lambdas = [0., 1e-6, 1e-3, 1.]\n",
    "train_losses_lambdas, val_losses_lambdas, f1s_lambdas = [], [], []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "\n",
    "    def train_method(y, x):  \n",
    "        return logistic_regression_penalized_gradient_descent(y, x, gamma = 0.5, lambda_ =lambda_)\n",
    "    def evaluator(y, x, w):\n",
    "        return evaluate_logistic_model(y, x, w, threshold=0.7, lambda_ = lambda_) # we saw in Model_I that 0.7 was the best for this preprocess\n",
    "\n",
    "    train_losses, val_losses, f1s_datasize = over_under_fitting(\n",
    "        X_train_over, \n",
    "        X_val_over, \n",
    "        Y_train_over, \n",
    "        Y_val_over, \n",
    "        train_method = train_method, \n",
    "        evaluator = evaluator, preprocess=preprocessing, steps = 20)\n",
    "    train_losses_lambdas.append(train_losses)\n",
    "    val_losses_lambdas.append(val_losses)\n",
    "    f1s_lambdas.append(f1s_datasize)\n",
    "    print(\"For lambda:\", lambda_, \"best f1:\", max(f1s_datasize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f56c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47782293775991824, 0.47698732355355455, 0.4769797667913417, 0.4770039175573837, 0.47681266868960714, 0.4773146148510138, 0.47865607094187657, 0.4796717078395382, 0.4782240867822293, 0.47912594239435036, 0.47835353433693933, 0.479596962621177, 0.4779949204257517, 0.4765741103326543, 0.47627971060157254, 0.4765373725837642, 0.4765373725837642, 0.4765373725837642, 0.4765373725837642, 0.4765373725837642], [0.46913751205520937, 0.46864342411863963, 0.46933432814373377, 0.46957572959533184, 0.47013088621710947, 0.47271475825321124, 0.4726492327593902, 0.47231070965972555, 0.4732384067332979, 0.4731435062442052, 0.47239630488329915, 0.471653605361771, 0.4740681027608305, 0.4742306367302612, 0.4742400949416812, 0.47425435810150346, 0.47425435810150346, 0.47425435810150346, 0.47425435810150346, 0.47425435810150346], [0.4677932052993417, 0.46926186000038683, 0.469717432554358, 0.47062807892668707, 0.47090624003003345, 0.47217401655926633, 0.4722353018003547, 0.4725857994053359, 0.4742184435104195, 0.47452019017883595, 0.474419561942713, 0.4743834840048133, 0.47591261133867946, 0.4769676846776418, 0.4785735609837505, 0.4787405061957909, 0.4787405061957909, 0.4787405061957909, 0.4787405061957909, 0.4787405061957909], [1.48089964052398, 1.4816139302185982, 1.4877557325135584, 1.4917322584638923, 1.4796806159125095, 1.4746742359863618, 1.4745773888068077, 1.4786619137458084, 1.4938254001714941, 1.4924154570545487, 1.4958732615018007, 1.5031802597903456, 1.498092225473002, 1.4986601200944636, 1.5012937070632084, 1.5090588031170218, 1.5090588031170218, 1.5090588031170218, 1.5090588031170218, 1.5090588031170218]] [[0.4874435202686255, 0.4878356131434696, 0.4853181247979072, 0.48374045722021747, 0.4851587551659745, 0.48429493042715854, 0.48526459479699247, 0.48646705527952266, 0.488010278641259, 0.4887613152202043, 0.4906768206448792, 0.49142285106197076, 0.49041808556156025, 0.4883372675418509, 0.4888581119241422, 0.4881518971410055, 0.4881518971410055, 0.4881518971410055, 0.4881518971410055, 0.4881518971410055], [0.5013040401356746, 0.4991454862914758, 0.49829904980747075, 0.4970741085677811, 0.4963960622163562, 0.49418407360084016, 0.48996743386081004, 0.4895770864352618, 0.4885411258687079, 0.48850162579566575, 0.48614819702136003, 0.48541424063189603, 0.48565439187930043, 0.48800283896335417, 0.4879241618382999, 0.4887490605694057, 0.4887490605694057, 0.4887490605694057, 0.4887490605694057, 0.4887490605694057], [0.4975659857783748, 0.4964837955213607, 0.49639051949674273, 0.49460304909378294, 0.493137018390451, 0.49319467859538474, 0.49008101153598105, 0.49100327787991327, 0.4897509789251876, 0.49162885664459954, 0.49165061452913456, 0.4920635900101649, 0.49284007385461837, 0.4934755218567446, 0.49218357374453264, 0.49285419470044584, 0.49285419470044584, 0.49285419470044584, 0.49285419470044584, 0.49285419470044584], [1.3063475183939013, 1.3166309353059191, 1.3156831524113692, 1.316450377142647, 1.3052277282354074, 1.295325245563282, 1.3030556511244946, 1.3078287770162782, 1.3191735410985332, 1.309332219003748, 1.3093415497960634, 1.3088523848940936, 1.299719680666388, 1.2973170925333588, 1.3050343578390213, 1.3114848245079949, 1.3114848245079949, 1.3114848245079949, 1.3114848245079949, 1.3114848245079949]] [np.float64(0.09853348651753686), np.float64(0.09932614555256017), np.float64(0.09969056908381495), np.float64(0.0995694294940792), np.float64(0.09946091644204803), np.float64(0.09898717083051944), np.float64(0.09927834356241944), np.float64(0.0990632791967109), np.float64(0.09946236559139737), np.float64(0.09913125462994095), np.float64(0.09932705248990532), np.float64(0.0992058150491313), np.float64(0.09904864718979779), np.float64(0.09881209503239692), np.float64(0.09952861952861904), np.float64(0.09947503028671377), np.float64(0.09947503028671377), np.float64(0.09947503028671377), np.float64(0.09947503028671377), np.float64(0.09947503028671377)]\n"
     ]
    }
   ],
   "source": [
    "# code to save the results of the exploration \n",
    "\n",
    "\"\"\"\"\n",
    "print(train_losses_lambdas, val_losses_lambdas, f1s_datasize)\n",
    "\n",
    "l1 = np.array(train_losses_lambdas)\n",
    "l2 = np.array(val_losses_lambdas)\n",
    "l3 = np.array(f1s_lambdas)\n",
    "\n",
    "np.savez('LearningCurveArrays.npz', a=l1, b=l2, c=l3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to get the results loaded\n",
    "\n",
    "lambdas = [0., 1e-6, 1e-3, 1.]\n",
    "\n",
    "data = np.load('LearningCurveArrays.npz')\n",
    "l1_loaded = data['a']\n",
    "l2_loaded = data['b']\n",
    "l3_loaded = data['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e86fbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results for the losses\n",
    "\n",
    "N = X_train_over.shape[0]\n",
    "data_sizes = np.array([N / (len(l1_loaded[0]) - i) for i in range(len(l1_loaded[0]))])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(lambdas), figsize=(18, 4)) \n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "\n",
    "    axs[i].plot(data_sizes, l1_loaded[i], label='Train Loss')\n",
    "    axs[i].plot(data_sizes, l2_loaded[i], label='Validation Loss')\n",
    "    axs[i].set_title(f'Train vs Validation Loss. Lambda: {lambdas[i]}')\n",
    "    axs[i].set_ylabel('Loss')\n",
    "    axs[i].set_xlabel('Data Size')\n",
    "    axs[i].grid(True)\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e842bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for the F1 scores\n",
    "\n",
    "N = X_train_over.shape[0]\n",
    "data_sizes = np.array([N / (len(l1_loaded[0]) - i) for i in range(len(l1_loaded[0]))])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(lambdas), figsize=(18, 4)) \n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "\n",
    "    axs[i].plot(data_sizes, l3_loaded[i], label='F1 score')\n",
    "    axs[i].set_xlabel('Data Size')\n",
    "    axs[i].set_ylabel('F1 score')\n",
    "    axs[i].set_title(f'F1 score. Lambda: {lambdas[i]}')\n",
    "    axs[i].grid(True)\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fbcf868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "For lambda 0.0 best F1 score: 0.40887835899993713 in iteration 43751.333333333336\n",
      "For lambda 1e-06 best F1 score: 0.41022142281213125 in iteration 52501.6\n",
      "For lambda 0.001 best F1 score: 0.4094252586959227 in iteration 52501.6\n",
      "For lambda 1.0 best F1 score: 0.09969056908381495 in iteration 14583.777777777777\n"
     ]
    }
   ],
   "source": [
    "# Print a summary\n",
    "N = X_train_over.shape[0]\n",
    "data_sizes = np.array([N / (len(l1_loaded[0]) - i) for i in range(len(l1_loaded[0]))])\n",
    "\n",
    "\n",
    "print(\"Summary\")\n",
    "for i in range(len(lambdas)):\n",
    "    print(\"For lambda\", lambdas[i], \"best F1 score:\", np.max(l3_loaded[i]), \"in iteration\", data_sizes[np.argmax(l3_loaded[i])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
