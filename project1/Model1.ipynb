{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2167e8c7-57f2-477d-9e86-f5f9a707e962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from Data_cleaning import *\n",
    "from helpers import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e717cb-604e-4af1-a14f-1a465fdaa409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "<>:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "C:\\Users\\alumne\\AppData\\Local\\Temp\\ipykernel_624\\194566319.py:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "  x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n"
     ]
    }
   ],
   "source": [
    "# Load the data. Estimated time for Fox's computer: 19 minutes\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "x_train, used_features = remove_nan_features(x_train, threshold=0.3) #from know, only remove features with more than 30% of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4e67e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 144) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Data reduction for faster testing\n",
    "x_train = x_train[:10000]  # we take a subset of the data to make it faster\n",
    "y_train = y_train[:10000]  # we take a subset of the data to make it faster\n",
    "x_values = x_train[1000:]    # we take a subset of the data to make it faster\n",
    "y_values = y_train[1000:]    # we take a subset of the data to make it faster\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6224315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 1.220690\n",
      "Iteration  2000, loss = 1.220690\n",
      "Iteration  3000, loss = 1.220690\n",
      "Iteration  4000, loss = 1.220690\n",
      "Iteration  5000, loss = 1.220690\n",
      "Iteration  6000, loss = 1.220690\n",
      "Iteration  7000, loss = 1.220690\n",
      "Iteration  8000, loss = 1.220690\n",
      "Iteration  9000, loss = 1.220690\n",
      "Validation accuracy: 0.762\n",
      "Dispersion in validation set: 0.08666666666666667\n",
      "Dispersion in predictions: 0.18244444444444444\n"
     ]
    }
   ],
   "source": [
    "# Example of running logistic regression with penalization\n",
    "X_train, X_values, Y_train, Y_values = clean_data(x_train, x_values, y_train, y_values)\n",
    "loss, w = logistic_regression_penalized_gradient_descent(Y_train, X_train, lambda_=1.0, gamma=0.5)\n",
    "preds = predict_logistic(X_values, w)\n",
    "acc = np.mean(preds == Y_values)\n",
    "dispersion_pred = np.sum(preds) / preds.shape[0]\n",
    "dispersion_true = np.sum(Y_values) / Y_values.shape[0]\n",
    "print(\"Validation accuracy:\", acc)\n",
    "print(\"Dispersion in validation set:\", dispersion_true)\n",
    "print(\"Dispersion in predictions:\", dispersion_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5825431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1744, 144) (1744,)\n",
      "(145,)\n",
      "entered\n",
      "2\n",
      "(1744, 145) (145,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "w = np.array(w)\n",
    "print(w.shape)\n",
    "tvals, ses, pvals, H = logistic_tvalues(X_train, Y_train, w, lambda_=1.0, eps=1e-12, batch_size=20000, return_cov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "88f73b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_step_elimination_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m reamining_features, delta = \u001b[43mone_step_elimination_mask\u001b[49m(w, H) \n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of remaining features:\u001b[39m\u001b[33m\"\u001b[39m, np.sum(reamining_features), \u001b[33m\"\u001b[39m\u001b[33mout of\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(reamining_features) -\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# we don't consider the intercept\u001b[39;00m\n\u001b[32m      3\u001b[39m X_train_reduced = X_train[:, reamining_features[\u001b[32m1\u001b[39m:]] \u001b[38;5;66;03m# we don't consider the intercept\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'one_step_elimination_mask' is not defined"
     ]
    }
   ],
   "source": [
    "reamining_features, delta = one_step_elimination_mask(w, H) \n",
    "print(\"Number of remaining features:\", np.sum(reamining_features), \"out of\", len(reamining_features) -1) # we don't consider the intercept\n",
    "X_train_reduced = X_train[:, reamining_features[1:]] # we don't consider the intercept\n",
    "X_values_reduced = X_values[:, reamining_features[1:]]\n",
    "loss, w = logistic_regression_penalized_gradient_descent(Y_train, X_train_reduced, lambda_=1.0, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b16c5831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.3128888888888889\n",
      "Dispersion in validation set: 0.08666666666666667\n",
      "Dispersion in predictions: 0.7484444444444445\n"
     ]
    }
   ],
   "source": [
    "preds = predict_logistic(X_values_reduced, w)\n",
    "acc = np.mean(preds == Y_values)\n",
    "dispersion_pred = np.sum(preds) / preds.shape[0]\n",
    "dispersion_true = np.sum(Y_values) / Y_values.shape[0]\n",
    "print(\"Validation accuracy:\", acc)\n",
    "print(\"Dispersion in validation set:\", dispersion_true)\n",
    "print(\"Dispersion in predictions:\", dispersion_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a016a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.420010\n",
      "Iteration  2000, loss = 0.417973\n",
      "Iteration  3000, loss = 0.417095\n",
      "Iteration  4000, loss = 0.416621\n",
      "Iteration  5000, loss = 0.416323\n",
      "Iteration  6000, loss = 0.416114\n",
      "Iteration  7000, loss = 0.415956\n",
      "Iteration  8000, loss = 0.415829\n",
      "Iteration  9000, loss = 0.415722\n",
      "Training done. Score for batch 1 : 0.7255\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.430626\n",
      "Iteration  2000, loss = 0.429651\n",
      "Iteration  3000, loss = 0.429319\n",
      "Iteration  4000, loss = 0.429142\n",
      "Iteration  5000, loss = 0.429017\n",
      "Iteration  6000, loss = 0.428916\n",
      "Iteration  7000, loss = 0.428828\n",
      "Iteration  8000, loss = 0.428750\n",
      "Iteration  9000, loss = 0.428679\n",
      "Training done. Score for batch 2 : 0.746\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.423610\n",
      "Iteration  2000, loss = 0.422072\n",
      "Iteration  3000, loss = 0.421398\n",
      "Iteration  4000, loss = 0.420993\n",
      "Iteration  5000, loss = 0.420715\n",
      "Iteration  6000, loss = 0.420510\n",
      "Iteration  7000, loss = 0.420353\n",
      "Iteration  8000, loss = 0.420230\n",
      "Iteration  9000, loss = 0.420131\n",
      "Training done. Score for batch 3 : 0.767\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.426945\n",
      "Iteration  2000, loss = 0.424798\n",
      "Iteration  3000, loss = 0.423782\n",
      "Iteration  4000, loss = 0.423131\n",
      "Iteration  5000, loss = 0.422654\n",
      "Iteration  6000, loss = 0.422282\n",
      "Iteration  7000, loss = 0.421980\n",
      "Iteration  8000, loss = 0.421728\n",
      "Iteration  9000, loss = 0.421515\n",
      "Training done. Score for batch 4 : 0.7535\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.419840\n",
      "Iteration  2000, loss = 0.418146\n",
      "Iteration  3000, loss = 0.417541\n",
      "Iteration  4000, loss = 0.417228\n",
      "Iteration  5000, loss = 0.417030\n",
      "Iteration  6000, loss = 0.416886\n",
      "Iteration  7000, loss = 0.416772\n",
      "Iteration  8000, loss = 0.416677\n",
      "Iteration  9000, loss = 0.416595\n",
      "Training done. Score for batch 5 : 0.756\n",
      "\n",
      "Tested lambda=10^ -7  with accuracy= 0.7496\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.405077\n",
      "Iteration  2000, loss = 0.403003\n",
      "Iteration  3000, loss = 0.402023\n",
      "Iteration  4000, loss = 0.401445\n",
      "Iteration  5000, loss = 0.401052\n",
      "Iteration  6000, loss = 0.400758\n",
      "Iteration  7000, loss = 0.400521\n",
      "Iteration  8000, loss = 0.400322\n",
      "Iteration  9000, loss = 0.400149\n",
      "Training done. Score for batch 1 : 0.7245\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.424141\n",
      "Iteration  2000, loss = 0.422267\n",
      "Iteration  3000, loss = 0.421630\n",
      "Iteration  4000, loss = 0.421334\n",
      "Iteration  5000, loss = 0.421161\n",
      "Iteration  6000, loss = 0.421041\n",
      "Iteration  7000, loss = 0.420949\n",
      "Iteration  8000, loss = 0.420872\n",
      "Iteration  9000, loss = 0.420805\n",
      "Training done. Score for batch 2 : 0.75\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.423825\n",
      "Iteration  2000, loss = 0.421195\n",
      "Iteration  3000, loss = 0.420173\n",
      "Iteration  4000, loss = 0.419630\n",
      "Iteration  5000, loss = 0.419275\n",
      "Iteration  6000, loss = 0.419016\n",
      "Iteration  7000, loss = 0.418815\n",
      "Iteration  8000, loss = 0.418654\n",
      "Iteration  9000, loss = 0.418523\n",
      "Training done. Score for batch 3 : 0.7635\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.411351\n",
      "Iteration  2000, loss = 0.410127\n",
      "Iteration  3000, loss = 0.409686\n",
      "Iteration  4000, loss = 0.409476\n",
      "Iteration  5000, loss = 0.409352\n",
      "Iteration  6000, loss = 0.409270\n",
      "Iteration  7000, loss = 0.409209\n",
      "Iteration  8000, loss = 0.409162\n",
      "Iteration  9000, loss = 0.409122\n",
      "Training done. Score for batch 4 : 0.742\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.447449\n",
      "Iteration  2000, loss = 0.445907\n",
      "Iteration  3000, loss = 0.445060\n",
      "Iteration  4000, loss = 0.444500\n",
      "Iteration  5000, loss = 0.444099\n",
      "Iteration  6000, loss = 0.443797\n",
      "Iteration  7000, loss = 0.443561\n",
      "Iteration  8000, loss = 0.443371\n",
      "Iteration  9000, loss = 0.443213\n",
      "Training done. Score for batch 5 : 0.7475\n",
      "\n",
      "Tested lambda=10^ -6  with accuracy= 0.7455\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.397267\n",
      "Iteration  2000, loss = 0.395798\n",
      "Iteration  3000, loss = 0.395096\n",
      "Iteration  4000, loss = 0.394640\n",
      "Iteration  5000, loss = 0.394297\n",
      "Iteration  6000, loss = 0.394020\n",
      "Iteration  7000, loss = 0.393787\n",
      "Iteration  8000, loss = 0.393587\n",
      "Iteration  9000, loss = 0.393412\n",
      "Training done. Score for batch 1 : 0.73\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.414371\n",
      "Iteration  2000, loss = 0.412006\n",
      "Iteration  3000, loss = 0.410923\n",
      "Iteration  4000, loss = 0.410297\n",
      "Iteration  5000, loss = 0.409891\n",
      "Iteration  6000, loss = 0.409608\n",
      "Iteration  7000, loss = 0.409401\n",
      "Iteration  8000, loss = 0.409244\n",
      "Iteration  9000, loss = 0.409119\n",
      "Training done. Score for batch 2 : 0.7585\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.417976\n",
      "Iteration  2000, loss = 0.416034\n",
      "Iteration  3000, loss = 0.415071\n",
      "Iteration  4000, loss = 0.414438\n",
      "Iteration  5000, loss = 0.413961\n",
      "Iteration  6000, loss = 0.413580\n",
      "Iteration  7000, loss = 0.413263\n",
      "Iteration  8000, loss = 0.412994\n",
      "Iteration  9000, loss = 0.412763\n",
      "Training done. Score for batch 3 : 0.758\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.429308\n",
      "Iteration  2000, loss = 0.427892\n",
      "Iteration  3000, loss = 0.427266\n",
      "Iteration  4000, loss = 0.426901\n",
      "Iteration  5000, loss = 0.426656\n",
      "Iteration  6000, loss = 0.426478\n",
      "Iteration  7000, loss = 0.426340\n",
      "Iteration  8000, loss = 0.426228\n",
      "Iteration  9000, loss = 0.426136\n",
      "Training done. Score for batch 4 : 0.7485\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.412252\n",
      "Iteration  2000, loss = 0.410942\n",
      "Iteration  3000, loss = 0.410484\n",
      "Iteration  4000, loss = 0.410243\n",
      "Iteration  5000, loss = 0.410081\n",
      "Iteration  6000, loss = 0.409957\n",
      "Iteration  7000, loss = 0.409854\n",
      "Iteration  8000, loss = 0.409765\n",
      "Iteration  9000, loss = 0.409688\n",
      "Training done. Score for batch 5 : 0.734\n",
      "\n",
      "Tested lambda=10^ -5  with accuracy= 0.7458\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.418111\n",
      "Iteration  2000, loss = 0.416819\n",
      "Iteration  3000, loss = 0.416371\n",
      "Iteration  4000, loss = 0.416144\n",
      "Iteration  5000, loss = 0.416008\n",
      "Iteration  6000, loss = 0.415919\n",
      "Iteration  7000, loss = 0.415859\n",
      "Iteration  8000, loss = 0.415817\n",
      "Iteration  9000, loss = 0.415786\n",
      "Training done. Score for batch 1 : 0.7505\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.405329\n",
      "Iteration  2000, loss = 0.404150\n",
      "Iteration  3000, loss = 0.403730\n",
      "Iteration  4000, loss = 0.403528\n",
      "Iteration  5000, loss = 0.403416\n",
      "Iteration  6000, loss = 0.403347\n",
      "Iteration  7000, loss = 0.403302\n",
      "Iteration  8000, loss = 0.403271\n",
      "Iteration  9000, loss = 0.403250\n",
      "Training done. Score for batch 2 : 0.7335\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.420568\n",
      "Iteration  2000, loss = 0.418969\n",
      "Iteration  3000, loss = 0.418414\n",
      "Iteration  4000, loss = 0.418159\n",
      "Iteration  5000, loss = 0.418020\n",
      "Iteration  6000, loss = 0.417939\n",
      "Iteration  7000, loss = 0.417888\n",
      "Iteration  8000, loss = 0.417856\n",
      "Iteration  9000, loss = 0.417835\n",
      "Training done. Score for batch 3 : 0.7425\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.446082\n",
      "Iteration  2000, loss = 0.445234\n",
      "Iteration  3000, loss = 0.444910\n",
      "Iteration  4000, loss = 0.444754\n",
      "Iteration  5000, loss = 0.444668\n",
      "Iteration  6000, loss = 0.444616\n",
      "Iteration  7000, loss = 0.444584\n",
      "Iteration  8000, loss = 0.444562\n",
      "Iteration  9000, loss = 0.444547\n",
      "Converged at iteration 9711\n",
      "Training done. Score for batch 4 : 0.758\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.415355\n",
      "Iteration  2000, loss = 0.414062\n",
      "Iteration  3000, loss = 0.413556\n",
      "Iteration  4000, loss = 0.413310\n",
      "Iteration  5000, loss = 0.413175\n",
      "Iteration  6000, loss = 0.413096\n",
      "Iteration  7000, loss = 0.413046\n",
      "Iteration  8000, loss = 0.413014\n",
      "Iteration  9000, loss = 0.412992\n",
      "Training done. Score for batch 5 : 0.7395\n",
      "\n",
      "Tested lambda=10^ -4  with accuracy= 0.7448\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.434429\n",
      "Iteration  2000, loss = 0.434240\n",
      "Converged at iteration 2414\n",
      "Training done. Score for batch 1 : 0.7605\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.418377\n",
      "Iteration  2000, loss = 0.418202\n",
      "Converged at iteration 2372\n",
      "Training done. Score for batch 2 : 0.725\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.437069\n",
      "Iteration  2000, loss = 0.436974\n",
      "Converged at iteration 2099\n",
      "Training done. Score for batch 3 : 0.7605\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.429644\n",
      "Iteration  2000, loss = 0.429515\n",
      "Converged at iteration 2328\n",
      "Training done. Score for batch 4 : 0.729\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 0.411332\n",
      "Iteration  2000, loss = 0.411161\n",
      "Converged at iteration 2298\n",
      "Training done. Score for batch 5 : 0.7395\n",
      "\n",
      "Tested lambda=10^ -3  with accuracy= 0.7429\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 321\n",
      "Training done. Score for batch 1 : 0.7275\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 341\n",
      "Training done. Score for batch 2 : 0.736\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 350\n",
      "Training done. Score for batch 3 : 0.725\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 334\n",
      "Training done. Score for batch 4 : 0.7185\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 329\n",
      "Training done. Score for batch 5 : 0.734\n",
      "\n",
      "Tested lambda=10^ -2  with accuracy= 0.7282\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 45\n",
      "Training done. Score for batch 1 : 0.648\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 46\n",
      "Training done. Score for batch 2 : 0.69\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 45\n",
      "Training done. Score for batch 3 : 0.6675\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 46\n",
      "Training done. Score for batch 4 : 0.676\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Converged at iteration 45\n",
      "Training done. Score for batch 5 : 0.6715\n",
      "\n",
      "Tested lambda=10^ -1  with accuracy= 0.6706000000000001\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 1.271064\n",
      "Iteration  2000, loss = 1.271064\n",
      "Iteration  3000, loss = 1.271064\n",
      "Iteration  4000, loss = 1.271064\n",
      "Iteration  5000, loss = 1.271064\n",
      "Iteration  6000, loss = 1.271064\n",
      "Iteration  7000, loss = 1.271064\n",
      "Iteration  8000, loss = 1.271064\n",
      "Iteration  9000, loss = 1.271064\n",
      "Training done. Score for batch 1 : 0.769\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 1.209623\n",
      "Iteration  2000, loss = 1.209623\n",
      "Iteration  3000, loss = 1.209623\n",
      "Iteration  4000, loss = 1.209623\n",
      "Iteration  5000, loss = 1.209623\n",
      "Iteration  6000, loss = 1.209623\n",
      "Iteration  7000, loss = 1.209623\n",
      "Iteration  8000, loss = 1.209623\n",
      "Iteration  9000, loss = 1.209623\n",
      "Training done. Score for batch 2 : 0.753\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 1.128819\n",
      "Iteration  2000, loss = 1.128819\n",
      "Iteration  3000, loss = 1.128819\n",
      "Iteration  4000, loss = 1.128819\n",
      "Iteration  5000, loss = 1.128819\n",
      "Iteration  6000, loss = 1.128819\n",
      "Iteration  7000, loss = 1.128819\n",
      "Iteration  8000, loss = 1.128819\n",
      "Iteration  9000, loss = 1.128819\n",
      "Training done. Score for batch 3 : 0.772\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 1.082755\n",
      "Iteration  2000, loss = 1.082755\n",
      "Iteration  3000, loss = 1.082755\n",
      "Iteration  4000, loss = 1.082755\n",
      "Iteration  5000, loss = 1.082755\n",
      "Iteration  6000, loss = 1.082755\n",
      "Iteration  7000, loss = 1.082755\n",
      "Iteration  8000, loss = 1.082755\n",
      "Iteration  9000, loss = 1.082755\n",
      "Training done. Score for batch 4 : 0.761\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = 1.222713\n",
      "Iteration  2000, loss = 1.222713\n",
      "Iteration  3000, loss = 1.222713\n",
      "Iteration  4000, loss = 1.222713\n",
      "Iteration  5000, loss = 1.222713\n",
      "Iteration  6000, loss = 1.222713\n",
      "Iteration  7000, loss = 1.222713\n",
      "Iteration  8000, loss = 1.222713\n",
      "Iteration  9000, loss = 1.222713\n",
      "Training done. Score for batch 5 : 0.759\n",
      "\n",
      "Tested lambda=10^ 0  with accuracy= 0.7628\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:6: RuntimeWarning: overflow encountered in matmul\n",
      "  \n",
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:12: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  \n",
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:4: RuntimeWarning: overflow encountered in matmul\n",
      "  \n",
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:6: RuntimeWarning: overflow encountered in multiply\n",
      "  \n",
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:38: RuntimeWarning: overflow encountered in matmul\n",
      "  def compute_gradient_logistic(y, tx, w):\n",
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:7: RuntimeWarning: overflow encountered in multiply\n",
      "  def mse_loss(y, tx, w):\n",
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:4: RuntimeWarning: invalid value encountered in matmul\n",
      "  \n",
      "c:\\Users\\alumne\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:38: RuntimeWarning: invalid value encountered in matmul\n",
      "  def compute_gradient_logistic(y, tx, w):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 1 : 0.92\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 2 : 0.918\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 3 : 0.907\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 4 : 0.9115\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 5 : 0.9075\n",
      "\n",
      "Tested lambda=10^ 1  with accuracy= 0.9128000000000001\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 1 : 0.913\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 2 : 0.91\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 3 : 0.915\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 4 : 0.916\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 5 : 0.91\n",
      "\n",
      "Tested lambda=10^ 2  with accuracy= 0.9128000000000001\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 1 : 0.909\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 2 : 0.911\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 3 : 0.9095\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 4 : 0.9205\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 5 : 0.914\n",
      "\n",
      "Tested lambda=10^ 3  with accuracy= 0.9128000000000001\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 1 : 0.9165\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 2 : 0.912\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 3 : 0.9115\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 4 : 0.9185\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 5 : 0.9055\n",
      "\n",
      "Tested lambda=10^ 4  with accuracy= 0.9128000000000001\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 1 : 0.9115\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 2 : 0.92\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 3 : 0.906\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 4 : 0.909\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 5 : 0.9175\n",
      "\n",
      "Tested lambda=10^ 5  with accuracy= 0.9128000000000001\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 1 : 0.906\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 2 : 0.915\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 3 : 0.914\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 4 : 0.9175\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 5 : 0.9115\n",
      "\n",
      "Tested lambda=10^ 6  with accuracy= 0.9128000000000001\n",
      "Start cleaning batch 1 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 1 : 0.909\n",
      "\n",
      "Start cleaning batch 2 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 2 : 0.923\n",
      "\n",
      "Start cleaning batch 3 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 3 : 0.9145\n",
      "\n",
      "Start cleaning batch 4 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 4 : 0.911\n",
      "\n",
      "Start cleaning batch 5 out of 5\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Starting replacing NaNs using strategy: normal\n",
      "NaNs replaced.\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration  1000, loss = nan\n",
      "Iteration  2000, loss = nan\n",
      "Iteration  3000, loss = nan\n",
      "Iteration  4000, loss = nan\n",
      "Iteration  5000, loss = nan\n",
      "Iteration  6000, loss = nan\n",
      "Iteration  7000, loss = nan\n",
      "Iteration  8000, loss = nan\n",
      "Iteration  9000, loss = nan\n",
      "Training done. Score for batch 5 : 0.9065\n",
      "\n",
      "Tested lambda=10^ 7  with accuracy= 0.9128000000000001\n"
     ]
    }
   ],
   "source": [
    "# grid search to find the best lambda. Time estimated for Fox's computer: 47 minutes\n",
    "lambda_max, lambda_min = 7, -7 # defined as integers, but actually 1e-7, 1e7\n",
    "i, j = lambda_min, lambda_max\n",
    "Error_lambda = np.zeros(lambda_max - lambda_min + 1)\n",
    "\n",
    "for k in range(lambda_min, lambda_max + 1):\n",
    "    acc_k = kfold_logistic_ridge(x_train, y_train, k=5, gamma=0.5, lambda_=10**k, threshold=1e-8, random_state=None)\n",
    "    Error_lambda[k - lambda_min] = 1 - acc_k\n",
    "    print(\"Tested lambda=10^\", k, \" with accuracy=\", acc_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b010d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e03e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the output of the grid search\n",
    "plx = np.arange(lambda_min, lambda_max + 1, 1)\n",
    "ply = Error_lambda\n",
    "np.save(\"grid_search_lambda.npy\", (plx, ply))      # Save\n",
    "# plxh, plyh = np.load(\"grid_search_lambda.npy\")     # Load\n",
    "# print(plx, ply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ddf9aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2504 0.2545 0.2542 0.2552 0.2571 0.2718 0.3294 0.2372 0.0872 0.0872\n",
      " 0.0872 0.0872 0.0872 0.0872 0.0872]\n"
     ]
    }
   ],
   "source": [
    "#plot the error in terms of lambda\n",
    "plt.semilogy(plx, ply, 'o-')\n",
    "plt.xlabel('log10(lambda)')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error vs lambda for logistic regression with penalization')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(ply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features selection with t-values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
