{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2167e8c7-57f2-477d-9e86-f5f9a707e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from Data_cleaning import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e717cb-604e-4af1-a14f-1a465fdaa409",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78337828-02dd-4dc7-ab8d-8b1c97c4fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mod = x_train[:1000]\n",
    "y_train_mod = y_train[:1000]\n",
    "\n",
    "x_train_mod = remove_nan_features(x_train_mod)[0]\n",
    "x_train_mod = impute_missing_values(x_train_mod)[0]\n",
    "x_train_mod = select_random_features(x_train_mod, 15)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7a00174-e764-4314-9a4d-9fabd055cc61",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, w \u001b[38;5;241m=\u001b[39m logistic_regression_penalized_gradient_descent_demo(y_train_mod, x_train_mod)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss, w)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ML_proj1\\project1\\implementations.py:129\u001b[0m, in \u001b[0;36mlogistic_regression_penalized_gradient_descent_demo\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# start the logistic regression\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# get loss and update w.\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     loss, w \u001b[38;5;241m=\u001b[39m learning_by_penalized_gradient(y, tx, w, gamma, lambda_)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# log info\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "loss, w = logistic_regression_penalized_gradient_descent_demo(y_train_mod, x_train_mod)\n",
    "print(loss, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e7956-6b9b-4b28-b344-2a861b658085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
