{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94b28ef-299b-4b0d-bf31-8d6dfaa8e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from Data_cleaning import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61278433-65de-439c-aa76-b00cdcc59a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb773b1e-4032-4906-823a-61f13cd1180b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Turn y into 0s and 1s\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_tr_ \u001b[38;5;241m=\u001b[39m (y_train \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      3\u001b[0m y_tr \u001b[38;5;241m=\u001b[39m y_tr_[:\u001b[38;5;241m240000\u001b[39m]\n\u001b[0;32m      4\u001b[0m y_te \u001b[38;5;241m=\u001b[39m y_tr_[\u001b[38;5;241m240000\u001b[39m:\u001b[38;5;241m300000\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Turn y into 0s and 1s\n",
    "y_tr_ = (y_train + 1) / 2\n",
    "y_tr = y_tr_[:240000]\n",
    "y_te = y_tr_[240000:300000]\n",
    "print(y_tr.shape, y_te.shape, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27199848-d137-49f3-b452-56d98dd3ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_categorical_features(X, threshold=10):\n",
    "    \"\"\"\n",
    "    Removes categorical (low-cardinality) features from a numeric dataset.\n",
    "    A feature is dropped if it has fewer than `threshold` unique values.\n",
    "    \"\"\"\n",
    "    X_np = np.asarray(X)\n",
    "    n_samples, n_features = X_np.shape\n",
    "    keep_mask = np.array([\n",
    "        np.unique(X_np[:, j]).size >= threshold for j in range(n_features)\n",
    "    ])\n",
    "    X_num = X_np[:, keep_mask]\n",
    "    return X_num, keep_mask\n",
    "def anova_f_test(X, y):\n",
    "    \"\"\"\n",
    "    Compute ANOVA F-statistic for each feature using NumPy only.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (n_samples, n_features)\n",
    "        Feature matrix.\n",
    "    y : np.ndarray, shape (n_samples,)\n",
    "        Class labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    F_values : np.ndarray, shape (n_features,)\n",
    "        F-statistics for each feature.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    classes = np.unique(y)\n",
    "    k = len(classes)\n",
    "    \n",
    "    overall_means = np.nanmean(X, axis=0)  # handle NaNs safely\n",
    "    \n",
    "    # Initialize sums of squares\n",
    "    ssb = np.zeros(n_features)\n",
    "    ssw = np.zeros(n_features)\n",
    "    \n",
    "    for c in classes:\n",
    "        X_c = X[y == c]\n",
    "        n_c = X_c.shape[0]\n",
    "        mean_c = np.nanmean(X_c, axis=0)\n",
    "        \n",
    "        ssb += n_c * (mean_c - overall_means) ** 2\n",
    "        ssw += np.nansum((X_c - mean_c) ** 2, axis=0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    ssw = np.where(ssw == 0, np.nan, ssw)\n",
    "    \n",
    "    F = (ssb / (k - 1)) / (ssw / (n_samples - k))\n",
    "    \n",
    "    return F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "775c8def-5a8e-4f0b-8bbc-f09f68b9fd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 144) (240000,)\n"
     ]
    }
   ],
   "source": [
    "# --- CLEANING ---\n",
    "\"\"\"\n",
    "# 0. Remove categorical (low-cardinality) features\n",
    "x_num, cat_mask = remove_categorical_features(x_train, threshold=10)\n",
    "print(x_num.shape)\n",
    "\"\"\"\n",
    "# 1. Remove features with too many NaNs\n",
    "x_clean, keep_mask = remove_nan_features(x_train)\n",
    "x_clean_tr = x_clean[:240000]\n",
    "x_clean_te = x_clean[240000:300000]\n",
    "\n",
    "# 2. Impute remaining missing values\n",
    "# Compute feature means from the training data (ignore NaNs)\n",
    "train_means = np.nanmean(x_clean_tr, axis=0)\n",
    "train_stds = np.nanstd(x_clean_tr, axis = 0)\n",
    "# Replace NaNs in training data with training means\n",
    "inds_tr = np.where(np.isnan(x_clean_tr))\n",
    "x_clean_tr[inds_tr] = np.take(train_means, inds_tr[1])\n",
    "\n",
    "# Replace NaNs in test data with training means\n",
    "inds_te = np.where(np.isnan(x_clean_te))\n",
    "x_clean_te[inds_te] = np.take(train_means, inds_te[1])\n",
    "\"\"\"\n",
    "# Compute F-scores using only the training data\n",
    "F_scores = anova_f_test(x_clean_tr, y_tr)\n",
    "\n",
    "\n",
    "# Select top 30 features\n",
    "top_k = \n",
    "top_features_idx = np.argsort(F_scores)[-top_k:][::-1]\n",
    "\n",
    "# Apply the same feature selection to all sets\n",
    "x_anova_tr = x_clean_tr[:, top_features_idx]\n",
    "x_anova_te = x_clean_te[:, top_features_idx]\n",
    "\"\"\"\n",
    "# --- STANDARDIZATION ---\n",
    "x_tr_st = (x_clean_tr - train_means) / train_stds\n",
    "x_te_st = (x_clean_te - train_means) / train_stds\n",
    "\n",
    "\n",
    "print(x_tr_st.shape, y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9be1503-01c4-4bc5-b4dc-09653e15d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42262, 144) (42262,)\n"
     ]
    }
   ],
   "source": [
    "x_tr_ba, y_tr_ba = balance_data(x_tr_st, y_tr)\n",
    "print(x_tr_ba.shape, y_tr_ba.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c72aed5-6363-4fcc-ab1a-027e434a1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478041\n",
      "Iteration   200, loss = 0.477310\n",
      "Iteration   300, loss = 0.477114\n",
      "Iteration   400, loss = 0.477021\n",
      "Iteration   500, loss = 0.476967\n",
      "Iteration   600, loss = 0.476933\n",
      "Iteration   700, loss = 0.476910\n",
      "Iteration   800, loss = 0.476893\n",
      "Iteration   900, loss = 0.476881\n",
      "Iteration  1000, loss = 0.476872\n",
      "Iteration  1100, loss = 0.476864\n",
      "Iteration  1200, loss = 0.476858\n",
      "Iteration  1300, loss = 0.476854\n",
      "Iteration  1400, loss = 0.476850\n",
      "Iteration  1500, loss = 0.476846\n",
      "Iteration  1600, loss = 0.476844\n",
      "Iteration  1700, loss = 0.476841\n",
      "Iteration  1800, loss = 0.476839\n",
      "Iteration  1900, loss = 0.476838\n",
      "Iteration  2000, loss = 0.476836\n",
      "Iteration  2100, loss = 0.476835\n",
      "Iteration  2200, loss = 0.476834\n",
      "Converged at iteration 2224\n",
      "0.4768334366723658 [-9.44980758e-01  8.49136315e-03  5.70460452e-02 -2.24961552e-02\n",
      " -2.24670391e-02 -3.13413543e-04 -3.71663777e-02 -2.41743373e-02\n",
      " -1.54129311e-02 -1.54129311e-02  5.36113267e-01 -7.64795173e-02\n",
      " -2.21765685e-02 -8.14374668e-03  9.36134870e-03 -4.51684369e-02\n",
      "  1.11319569e-02 -2.02410757e-01 -1.98317895e-01 -2.12558886e-01\n",
      " -2.29850220e-01 -7.73984775e-02 -6.26672833e-02 -1.87306811e-02\n",
      " -3.05196146e-03 -4.02525154e-02  4.24058763e-02 -3.51003173e-02\n",
      " -3.46680589e-02 -1.04892922e-01 -3.80503453e-01 -6.35839511e-02\n",
      " -5.13898472e-02  4.71358349e-02 -4.52116841e-02  1.27733812e-01\n",
      " -2.87749365e-02  3.89405438e-02  5.34549159e-02 -2.71708584e-02\n",
      "  1.94806505e-02 -4.23787542e-02 -2.74744961e-02 -1.02259512e-02\n",
      " -5.99038387e-04 -3.66635361e-02  1.88749595e-02 -2.17379299e-02\n",
      " -7.94595868e-02  2.64513222e-02  8.12954010e-02  4.61258278e-03\n",
      " -1.01781519e-02  2.68995144e-02  3.61603763e-02 -1.63986411e-02\n",
      " -3.76068254e-03  5.26373973e-02  7.40642120e-03  5.37186888e-02\n",
      " -1.22991732e-02 -1.31180731e-01 -7.48350709e-02  6.12465914e-02\n",
      " -9.80076260e-03  9.41830292e-03 -2.57882448e-02 -6.37329173e-03\n",
      "  3.37082414e-02 -1.08143876e-02 -2.61920197e-02 -1.03956043e-02\n",
      " -7.60790924e-02  2.56782338e-02  1.32796397e-01  1.49265989e-01\n",
      "  2.39592570e-01  5.59003336e-02 -3.33129694e-03 -3.58052138e-02\n",
      " -9.75574993e-02 -5.03465449e-02  8.29863262e-02  1.83246509e-02\n",
      "  7.90219705e-02 -2.83906764e-02 -5.78239577e-02 -1.46084158e-02\n",
      "  3.82325478e-01 -1.70089326e-02  4.46053185e-01 -3.83078142e-02\n",
      " -1.66692337e-02 -3.41240842e-02  1.82330288e-02 -2.37612775e-02\n",
      "  3.14891824e-02 -1.79084824e-02 -9.86985200e-03  4.21056737e-02\n",
      " -5.56803321e-02 -1.48772944e-01  1.61825047e-01  1.48013437e-03\n",
      " -4.31578027e-02 -1.16071432e-02  9.71685518e-02 -7.27625047e-02\n",
      "  8.51495055e-03 -5.46334637e-02  5.35669837e-02  3.32198286e-02\n",
      "  6.98818268e-03  4.87059709e-02  7.94272177e-02 -2.77455939e-03\n",
      "  3.38100617e-02 -8.65719079e-03  3.17718727e-02 -4.64996100e-02\n",
      "  1.30560953e-03 -2.63565353e-02 -9.83099313e-03  2.33775629e-02\n",
      " -3.26577036e-02  7.08762004e-03 -4.55520946e-02 -8.31699524e-02\n",
      "  2.07766515e-02  3.20171166e-02  3.27447388e-02 -3.26798510e-02\n",
      " -1.13410594e-02 -4.55612425e-02  5.83156843e-04  3.50157448e-02\n",
      " -1.73624414e-02 -2.77927192e-02  8.42678147e-02 -2.47676803e-02\n",
      "  2.56725335e-02  2.10804434e-03  3.09298584e-02 -4.51315551e-03\n",
      "  6.98120964e-02]\n"
     ]
    }
   ],
   "source": [
    "loss, w = reg_logistic_regression(\n",
    "    y_tr_ba, x_tr_ba, max_iter=10000, gamma=0.5, lambda_=1e-3, threshold=1e-8\n",
    ")\n",
    "print(loss, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30cb0a9-c160-4995-bea8-b014620e59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_logistic(x, w, threshold=0.75, return_original_labels=True):\n",
    "\n",
    "    # add bias term\n",
    "    tx = np.c_[np.ones(x.shape[0]), x]\n",
    "    \n",
    "    # compute probabilities\n",
    "    probs = sigmoid(tx @ w)\n",
    "    \n",
    "    # threshold\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    \n",
    "    # convert to {-1, 1} if desired\n",
    "    if return_original_labels:\n",
    "        preds = 2 * preds - 1\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4146bc33-aec2-4495-afe3-320bfdab9284",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_te_st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict_labels_logistic(x_te_st, w, return_original_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m n_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mabs(y_te \u001b[38;5;241m-\u001b[39m y_pred))\n\u001b[0;32m      3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y_te \u001b[38;5;241m==\u001b[39m y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_te_st' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = predict_labels_logistic(x_te_st, w, return_original_labels=False)\n",
    "n_errors = np.sum(np.abs(y_te - y_pred))\n",
    "accuracy = np.mean(y_te == y_pred)\n",
    "\n",
    "print(\"Misclassified samples:\", n_errors)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(np.sum(y_pred), np.sum(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb8e2212-b66a-4e1a-8724-167a1a364c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Compute F1 score between true and predicted labels.\"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    if tp + fp == 0 or tp + fn == 0:\n",
    "        return 0.0\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02432b5d-cf87-4784-a406-53fe360812d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3829346392917687\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_te, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2457d9-6a9e-4b07-a71f-3142edbe5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
