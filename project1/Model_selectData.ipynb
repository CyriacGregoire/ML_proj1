{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94b28ef-299b-4b0d-bf31-8d6dfaa8e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from Data_cleaning import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61278433-65de-439c-aa76-b00cdcc59a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\cgreg\\AppData\\Local\\Temp\\ipykernel_23700\\4219252773.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb773b1e-4032-4906-823a-61f13cd1180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000,) (60000,) [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Turn y into 0s and 1s\n",
    "y_tr_ = (y_train + 1) / 2\n",
    "y_tr = y_tr_[:240000]\n",
    "y_te = y_tr_[240000:300000]\n",
    "print(y_tr.shape, y_te.shape, y_tr, y_te)\n",
    "#print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fc705db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[501. 510. 507. 505. 602.]\n",
      "[5.3000000e+01 1.1000000e+01 1.1162015e+07 1.1000000e+01 1.6000000e+01]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "j = 63\n",
    "\n",
    "my_features = [26,27,28,30,33,34,35,37,39,40,41,42,43,45,46,47,48,62,63,65]\n",
    "\n",
    "print(x_train[:,j][:5])\n",
    "print(x_train[0][:5])\n",
    "\n",
    "count = 0 \n",
    "for i in x_train[j]:\n",
    "    if i == 72:\n",
    "        count += 1\n",
    "\n",
    "print(count/len(x_train[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27199848-d137-49f3-b452-56d98dd3ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_categorical_features(X, threshold=10):\n",
    "    \"\"\"\n",
    "    Removes categorical (low-cardinality) features from a numeric dataset.\n",
    "    A feature is dropped if it has fewer than `threshold` unique values.\n",
    "    \"\"\"\n",
    "    X_np = np.asarray(X)\n",
    "    n_samples, n_features = X_np.shape\n",
    "    keep_mask = np.array([\n",
    "        np.unique(X_np[:, j]).size >= threshold for j in range(n_features)\n",
    "    ])\n",
    "    X_num = X_np[:, keep_mask]\n",
    "    return X_num, keep_mask\n",
    "\n",
    "\n",
    "def anova_f_test(X, y):\n",
    "    \"\"\"\n",
    "    Compute ANOVA F-statistic for each feature using NumPy only.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (n_samples, n_features)\n",
    "        Feature matrix.\n",
    "    y : np.ndarray, shape (n_samples,)\n",
    "        Class labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    F_values : np.ndarray, shape (n_features,)\n",
    "        F-statistics for each feature.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    classes = np.unique(y)\n",
    "    k = len(classes)\n",
    "    \n",
    "    overall_means = np.nanmean(X, axis=0)  # handle NaNs safely\n",
    "    \n",
    "    # Initialize sums of squares\n",
    "    ssb = np.zeros(n_features)\n",
    "    ssw = np.zeros(n_features)\n",
    "    \n",
    "    for c in classes:\n",
    "        X_c = X[y == c]\n",
    "        n_c = X_c.shape[0]\n",
    "        mean_c = np.nanmean(X_c, axis=0)\n",
    "        \n",
    "        ssb += n_c * (mean_c - overall_means) ** 2\n",
    "        ssw += np.nansum((X_c - mean_c) ** 2, axis=0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    ssw = np.where(ssw == 0, np.nan, ssw)\n",
    "    \n",
    "    F = (ssb / (k - 1)) / (ssw / (n_samples - k))\n",
    "    \n",
    "    return F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c059316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 76)\n",
      "(328135, 17)\n"
     ]
    }
   ],
   "source": [
    "# x_cat = remove_categorical_features(x_train, 30)\n",
    "# print(x_cat[0].shape)\n",
    "\n",
    "x_clean, keep_mask = remove_nan_features(x_train)\n",
    "\n",
    "x_clean_red = x_clean[:,my_features]\n",
    "print(x_clean_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "775c8def-5a8e-4f0b-8bbc-f09f68b9fd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 20) (240000,)\n",
      "21131.0\n"
     ]
    }
   ],
   "source": [
    "# --- CLEANING ---\n",
    "\"\"\"\n",
    "# 0. Remove categorical (low-cardinality) features\n",
    "x_num, cat_mask = remove_categorical_features(x_train, threshold=10)\n",
    "print(x_num.shape)\n",
    "\"\"\"\n",
    "# 1. Remove features with too many NaNs\n",
    "x_clean, keep_mask = remove_nan_features(x_train)\n",
    "\n",
    "x_clean_red = x_clean[:,my_features]\n",
    "\n",
    "x_clean_tr = x_clean_red[:240000]\n",
    "x_clean_te = x_clean_red[240000:300000]#x_test[:,keep_mask]\n",
    "\n",
    "\n",
    "# 2. Impute remaining missing values\n",
    "# Compute feature means from the training data (ignore NaNs)\n",
    "train_means = np.nanmean(x_clean_tr, axis=0)\n",
    "\n",
    "train_stds = np.nanstd(x_clean_tr, axis = 0)\n",
    "# Replace NaNs in training data with training means\n",
    "inds_tr = np.where(np.isnan(x_clean_tr))\n",
    "x_clean_tr[inds_tr] = np.take(train_means, inds_tr[1])\n",
    "\n",
    "# Replace NaNs in test data with training means\n",
    "inds_te = np.where(np.isnan(x_clean_te))\n",
    "x_clean_te[inds_te] = np.take(train_means, inds_te[1])\n",
    "\"\"\"\n",
    "# Compute F-scores using only the training data\n",
    "F_scores = anova_f_test(x_clean_tr, y_tr)\n",
    "\n",
    "\n",
    "# Select top 30 features\n",
    "top_k = \n",
    "top_features_idx = np.argsort(F_scores)[-top_k:][::-1]\n",
    "\n",
    "# Apply the same feature selection to all sets\n",
    "x_anova_tr = x_clean_tr[:, top_features_idx]\n",
    "x_anova_te = x_clean_te[:, top_features_idx]\n",
    "\"\"\"\n",
    "# --- STANDARDIZATION ---\n",
    "x_tr_st = (x_clean_tr - train_means) / train_stds\n",
    "x_te_st = (x_clean_te - train_means) / train_stds\n",
    "\n",
    "\n",
    "print(x_tr_st.shape, y_tr.shape)\n",
    "print(np.sum(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9be1503-01c4-4bc5-b4dc-09653e15d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42262, 20) (42262,)\n"
     ]
    }
   ],
   "source": [
    "x_tr_ba, y_tr_ba = balance_data(x_tr_st, y_tr)\n",
    "print(x_tr_ba.shape, y_tr_ba.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c72aed5-6363-4fcc-ab1a-027e434a1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.574768\n",
      "Converged at iteration 139\n",
      "0.5747665824968488 [-4.43339024e-01 -5.77445113e-02 -5.63651496e-02 -2.68320849e-01\n",
      " -1.72856438e-01 -2.20806375e-01  4.92635018e-01  2.75007593e-01\n",
      "  2.42236462e-01 -2.74857130e-02 -1.63839130e-01 -1.83058673e-01\n",
      " -6.59599399e-03 -3.90333734e-04 -2.15713799e-02 -1.16965944e-02\n",
      " -2.21465524e-01  5.70435969e-02 -8.26487917e-02  1.89059502e-02\n",
      " -7.97741145e-03]\n"
     ]
    }
   ],
   "source": [
    "loss, w = logistic_regression_penalized_gradient_descent_demo(\n",
    "    y_tr_ba, x_tr_ba, max_iter=10000, gamma=0.5, lambda_=1e-3, threshold=1e-8\n",
    ")\n",
    "print(loss, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f30cb0a9-c160-4995-bea8-b014620e59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_logistic(x, w, threshold=0.75, return_original_labels=True):\n",
    "\n",
    "    # add bias term\n",
    "    tx = np.c_[np.ones(x.shape[0]), x]\n",
    "    \n",
    "    # compute probabilities\n",
    "    probs = sigmoid(tx @ w)\n",
    "    \n",
    "    # threshold\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    \n",
    "    # convert to {-1, 1} if desired\n",
    "    if return_original_labels:\n",
    "        preds = 2 * preds - 1\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4146bc33-aec2-4495-afe3-320bfdab9284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 7307.0\n",
      "Accuracy: 0.878\n",
      "5067\n",
      "5376.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_labels_logistic(x_te_st, w, return_original_labels=False)\n",
    "n_errors = np.sum(np.abs(y_te - y_pred))\n",
    "accuracy = np.mean(y_te == y_pred)\n",
    "\n",
    "print(\"Misclassified samples:\", n_errors)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(np.sum(y_pred))\n",
    "print(np.sum(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5e2c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_csv_submission(test_ids, y_pred, 'submission_1510')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb8e2212-b66a-4e1a-8724-167a1a364c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Compute F1 score between true and predicted labels.\"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    if tp + fp == 0 or tp + fn == 0:\n",
    "        return 0.0\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02432b5d-cf87-4784-a406-53fe360812d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3002968495643014\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_te, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2457d9-6a9e-4b07-a71f-3142edbe5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
