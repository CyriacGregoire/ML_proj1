{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a00180",
   "metadata": {},
   "source": [
    "## Model description\n",
    "In this model we will apply the simplest approach to the problem: using the ridge logistic model, k-fold cross-validation to find the best lambda, and NaN elimination along with undersampling and balancing for data cleaning."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "6460b75f",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 42,
   "id": "6460b75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Implemented_functions import *\n",
    "from Data_cleaning import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe2045",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We will load all the data here. Different approaches to cleaning it may appear in the same script."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 43,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "44d0066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "<>:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
<<<<<<< HEAD
      "C:\\Users\\janfo\\AppData\\Local\\Temp\\ipykernel_12236\\4294577664.py:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
=======
      "C:\\Users\\janfo\\AppData\\Local\\Temp\\ipykernel_24176\\4294577664.py:1: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "  X_train_data_full, X_test_data, Y_train_data_full, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_data shape: (328135, 321)\n",
      "Y_train_data shape: (328135,)\n",
      "X_test_data shape: (109379, 321)\n"
     ]
    }
   ],
   "source": [
    "X_train_data_full, X_test_data, Y_train_data_full, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n",
    "print(\"X_train_data shape:\", X_train_data_full.shape)\n",
    "print(\"Y_train_data shape:\", Y_train_data_full.shape)\n",
    "print(\"X_test_data shape:\", X_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6748ac",
   "metadata": {},
   "source": [
    "Set y labels as 0 and 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 44,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "cbe25890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of -1 labels in Y_train_data: 299160\n",
      "Number of 1 labels in Y_train_data: 28975\n",
      "Number of -1 labels in Y_train_data_norm: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of -1 labels in Y_train_data:\", np.sum(Y_train_data_full == -1))\n",
    "print(\"Number of 1 labels in Y_train_data:\", np.sum(Y_train_data_full == 1))\n",
    "Y_train_data_norm_full = np.where(Y_train_data_full == -1, 0, Y_train_data_full)\n",
    "print(\"Number of -1 labels in Y_train_data_norm:\", np.sum(Y_train_data_norm_full == -1))\n",
    "\n",
    "X_train_data, Y_train_data = X_train_data_full, Y_train_data_norm_full"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 45,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "02cd74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Reduced X_train_data shape: (10000, 321)\n",
      "Reduced Y_train_data shape: (10000,)\n"
=======
      "Reduced X_train_data shape: (328135, 321)\n",
      "Reduced Y_train_data shape: (328135,)\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
     ]
    }
   ],
   "source": [
    "\"Run if needed to reduce dataset size for faster testing\"\n",
<<<<<<< HEAD
    "X_train_data, Y_train_data = X_train_data_full[:10000], Y_train_data_norm_full[:10000]\n",
=======
    "# X_train_data, Y_train_data = X_train_data_full[:10000], Y_train_data_norm_full[:10000]\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
    "print(\"Reduced X_train_data shape:\", X_train_data.shape)\n",
    "print(\"Reduced Y_train_data shape:\", Y_train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fa87c",
   "metadata": {},
   "source": [
    "# Need of standarization\n",
    "After removing the NaNs, the first step is to standardize the data. In future models, we’ll explore better techniques for this, but for now, let’s just compare it with non-standardized data."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 46,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "32d55827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic regression model without standardization\n",
      "Iteration     0, loss = 0.693147\n",
<<<<<<< HEAD
      "Iteration   100, loss = 808135222153990016.000000\n",
      "Iteration   200, loss = 808135222153990144.000000\n",
      "Iteration   300, loss = 808135222153990016.000000\n",
      "Iteration   400, loss = 808135222153990144.000000\n",
      "Iteration   500, loss = 808135222153990016.000000\n",
      "Iteration   600, loss = 808135222153990144.000000\n",
      "Iteration   700, loss = 808135222153990016.000000\n",
      "Iteration   800, loss = 808135222153990144.000000\n",
      "Iteration   900, loss = 808135222153990016.000000\n",
      "\n",
      "Training logistic regression model with standardization\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.728092\n",
      "Iteration   200, loss = 0.728092\n",
      "Iteration   300, loss = 0.728092\n",
      "Iteration   400, loss = 0.728092\n",
      "Iteration   500, loss = 0.728092\n",
      "Iteration   600, loss = 0.728092\n",
      "Iteration   700, loss = 0.728092\n",
      "Iteration   800, loss = 0.728092\n",
      "Iteration   900, loss = 0.728092\n"
=======
      "Iteration   100, loss = 804147560028671744.000000\n",
      "Iteration   200, loss = 804147560028671744.000000\n",
      "Iteration   300, loss = 804147560028671744.000000\n",
      "Iteration   400, loss = 804147560028671744.000000\n",
      "Iteration   500, loss = 804147560028671744.000000\n",
      "Iteration   600, loss = 804147560028671744.000000\n",
      "Iteration   700, loss = 804147560028671744.000000\n",
      "Iteration   800, loss = 804147560028671744.000000\n",
      "Iteration   900, loss = 804147560028671744.000000\n",
      "\n",
      "Training logistic regression model with standardization\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.737933\n",
      "Iteration   200, loss = 0.737933\n",
      "Iteration   300, loss = 0.737933\n",
      "Iteration   400, loss = 0.737933\n",
      "Iteration   500, loss = 0.737933\n",
      "Iteration   600, loss = 0.737933\n",
      "Iteration   700, loss = 0.737933\n",
      "Iteration   800, loss = 0.737933\n",
      "Iteration   900, loss = 0.737933\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
     ]
    }
   ],
   "source": [
    "x_train = impute_missing_values(X_train_data, strategy='mean')\n",
    "print(\"Training logistic regression model without standardization\")\n",
    "# Train logistic regression model without standardization\n",
    "loss, w = logistic_regression_penalized_gradient_descent(\n",
    "        Y_train_data, x_train, max_iter=1000, gamma=0.5, lambda_=0.5, threshold=1e-8)\n",
    "\n",
    "x_train, means, stds = standardize_features(x_train)\n",
    "# Train logistic regression model with standardization\n",
    "\n",
    "print(\"\\nTraining logistic regression model with standardization\")\n",
    "loss, w = logistic_regression_penalized_gradient_descent(\n",
    "        Y_train_data, x_train, max_iter=1000, gamma=0.5, lambda_=0.5, threshold=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348cc24b",
   "metadata": {},
   "source": [
    "So, when data isn’t standardized, feature scales differ widely, making the scalar product w·x huge and the sigmoid saturates. Standardizing keeps values in a reasonable range, stabilizing training and avoiding numerical issues. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4ef6a",
   "metadata": {},
   "source": [
    "# Impact of balance\n",
    "In this section, we will test the impact of balancing the data. Using k-fold validation and NaN substitution, we will compare the results of different balancing strategies. Note that we will not discuss methods for replacing NaN values in this section. To proceed, we will define two preprocessing functions."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 47,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "bdea1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_balanced_data(x_train, x_val, y_train, y_val):\n",
    "\n",
    "    # replace missing values with mean and standardize features\n",
    "    x_train = impute_missing_values(x_train, strategy='mean')\n",
    "    x_val = impute_missing_values(x_val, strategy='mean')\n",
    "    x_train, means, stds = standardize_features(x_train)\n",
    "    x_val = (x_val - means) / stds\n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "def balanced_data(x_train, x_val, y_train, y_val):\n",
    "    # replace missing values with mean and standardize features\n",
    "    x_train = impute_missing_values(x_train, strategy='mean')\n",
    "    x_val = impute_missing_values(x_val, strategy='mean')\n",
    "    x_train, means, stds = standardize_features(x_train)\n",
    "    x_val = (x_val - means) / stds\n",
    "    # balance data by undersampling, so that both classes have the same number of samples\n",
    "    x_train, y_train = balance_data(x_train, y_train, method='undersample')\n",
    "    return x_train, x_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 48,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "a0b63759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
<<<<<<< HEAD
      "Iteration     0, loss = 0.693147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janfo\\OneDrive\\Desktop\\universitat\\EPFL\\Machine Learning\\ML_proj1\\project1\\Data_cleaning.py:45: RuntimeWarning: Mean of empty slice\n",
      "  values = np.nanmean(X_imputed, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 91.75%\n",
      " F1 Score: 0.1791\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 58.65%\n",
      " F1 Score: 0.2570\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n"
=======
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.237830\n",
      "Iteration   200, loss = 0.236320\n",
      "Iteration   300, loss = 0.236106\n",
      "Iteration   400, loss = 0.236045\n",
      "Iteration   500, loss = 0.236019\n",
      "Iteration   600, loss = 0.236006\n",
      "Iteration   700, loss = 0.235998\n",
      "Iteration   800, loss = 0.235993\n",
      "Iteration   900, loss = 0.235990\n",
      "Iteration  1000, loss = 0.235988\n",
      "Converged at iteration 1092\n",
      " Accuracy: 91.17%\n",
      " F1 Score: 0.0219\n",
      "     from now, f1 score: 0.021940928270042164 accuracy: 0.911697929205967\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.237543\n",
      "Iteration   200, loss = 0.236034\n",
      "Iteration   300, loss = 0.235820\n",
      "Iteration   400, loss = 0.235758\n",
      "Iteration   500, loss = 0.235732\n",
      "Iteration   600, loss = 0.235718\n",
      "Iteration   700, loss = 0.235710\n",
      "Iteration   800, loss = 0.235705\n",
      "Iteration   900, loss = 0.235702\n",
      "Iteration  1000, loss = 0.235700\n",
      "Iteration  1100, loss = 0.235698\n",
      "Converged at iteration 1111\n",
      " Accuracy: 91.18%\n",
      " F1 Score: 0.0334\n",
      "     from now, f1 score: 0.03338340844600229 accuracy: 0.9117588797293796\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.238701\n",
      "Iteration   200, loss = 0.237221\n",
      "Iteration   300, loss = 0.237012\n",
      "Iteration   400, loss = 0.236952\n",
      "Iteration   500, loss = 0.236927\n",
      "Iteration   600, loss = 0.236914\n",
      "Iteration   700, loss = 0.236906\n",
      "Iteration   800, loss = 0.236901\n",
      "Iteration   900, loss = 0.236898\n",
      "Iteration  1000, loss = 0.236896\n",
      "Converged at iteration 1099\n",
      " Accuracy: 91.27%\n",
      " F1 Score: 0.0104\n",
      "     from now, f1 score: 0.010359116022099435 accuracy: 0.9126578999497158\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.237212\n",
      "Iteration   200, loss = 0.235713\n",
      "Iteration   300, loss = 0.235505\n",
      "Iteration   400, loss = 0.235447\n",
      "Iteration   500, loss = 0.235422\n",
      "Iteration   600, loss = 0.235409\n",
      "Iteration   700, loss = 0.235402\n",
      "Iteration   800, loss = 0.235397\n",
      "Iteration   900, loss = 0.235394\n",
      "Iteration  1000, loss = 0.235392\n",
      "Converged at iteration 1093\n",
      " Accuracy: 91.14%\n",
      " F1 Score: 0.0339\n",
      "     from now, f1 score: 0.033892673201528445 accuracy: 0.911393176588904\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.238661\n",
      "Iteration   200, loss = 0.237170\n",
      "Iteration   300, loss = 0.236957\n",
      "Iteration   400, loss = 0.236896\n",
      "Iteration   500, loss = 0.236869\n",
      "Iteration   600, loss = 0.236855\n",
      "Iteration   700, loss = 0.236846\n",
      "Iteration   800, loss = 0.236841\n",
      "Iteration   900, loss = 0.236837\n",
      "Iteration  1000, loss = 0.236835\n",
      "Iteration  1100, loss = 0.236834\n",
      "Converged at iteration 1136\n",
      " Accuracy: 91.52%\n",
      " F1 Score: 0.0595\n",
      "     from now, f1 score: 0.059469504983949914 accuracy: 0.9151721090404864\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476219\n",
      "Iteration   200, loss = 0.475579\n",
      "Iteration   300, loss = 0.475435\n",
      "Iteration   400, loss = 0.475378\n",
      "Iteration   500, loss = 0.475352\n",
      "Iteration   600, loss = 0.475338\n",
      "Iteration   700, loss = 0.475331\n",
      "Iteration   800, loss = 0.475326\n",
      "Iteration   900, loss = 0.475323\n",
      "Iteration  1000, loss = 0.475321\n",
      "Iteration  1100, loss = 0.475319\n",
      "Converged at iteration 1149\n",
      " Accuracy: 85.28%\n",
      " F1 Score: 0.4096\n",
      "     from now, f1 score: 0.40960762742940915 accuracy: 0.8528044859585232\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476243\n",
      "Iteration   200, loss = 0.475540\n",
      "Iteration   300, loss = 0.475363\n",
      "Iteration   400, loss = 0.475293\n",
      "Iteration   500, loss = 0.475260\n",
      "Iteration   600, loss = 0.475243\n",
      "Iteration   700, loss = 0.475234\n",
      "Iteration   800, loss = 0.475229\n",
      "Iteration   900, loss = 0.475225\n",
      "Iteration  1000, loss = 0.475223\n",
      "Iteration  1100, loss = 0.475221\n",
      "Converged at iteration 1185\n",
      " Accuracy: 77.96%\n",
      " F1 Score: 0.3812\n",
      "     from now, f1 score: 0.381209087408548 accuracy: 0.7796181449708199\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476633\n",
      "Iteration   200, loss = 0.475916\n",
      "Iteration   300, loss = 0.475727\n",
      "Iteration   400, loss = 0.475647\n",
      "Iteration   500, loss = 0.475608\n",
      "Iteration   600, loss = 0.475589\n",
      "Iteration   700, loss = 0.475578\n",
      "Iteration   800, loss = 0.475571\n",
      "Iteration   900, loss = 0.475567\n",
      "Iteration  1000, loss = 0.475565\n",
      "Iteration  1100, loss = 0.475563\n",
      "Iteration  1200, loss = 0.475562\n",
      "Converged at iteration 1201\n",
      " Accuracy: 89.74%\n",
      " F1 Score: 0.3861\n",
      "     from now, f1 score: 0.3860672927874527 accuracy: 0.8974050314657077\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.470298\n",
      "Iteration   200, loss = 0.469570\n",
      "Iteration   300, loss = 0.469389\n",
      "Iteration   400, loss = 0.469313\n",
      "Iteration   500, loss = 0.469277\n",
      "Iteration   600, loss = 0.469258\n",
      "Iteration   700, loss = 0.469247\n",
      "Iteration   800, loss = 0.469241\n",
      "Iteration   900, loss = 0.469237\n",
      "Iteration  1000, loss = 0.469234\n",
      "Iteration  1100, loss = 0.469232\n",
      "Iteration  1200, loss = 0.469231\n",
      "Converged at iteration 1232\n",
      " Accuracy: 85.04%\n",
      " F1 Score: 0.4112\n",
      "     from now, f1 score: 0.41120374257781994 accuracy: 0.8504121779145778\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473245\n",
      "Iteration   200, loss = 0.472628\n",
      "Iteration   300, loss = 0.472481\n",
      "Iteration   400, loss = 0.472417\n",
      "Iteration   500, loss = 0.472385\n",
      "Iteration   600, loss = 0.472368\n",
      "Iteration   700, loss = 0.472357\n",
      "Iteration   800, loss = 0.472351\n",
      "Iteration   900, loss = 0.472347\n",
      "Iteration  1000, loss = 0.472345\n",
      "Iteration  1100, loss = 0.472343\n",
      "Iteration  1200, loss = 0.472341\n",
      "Converged at iteration 1230\n",
      " Accuracy: 80.14%\n",
      " F1 Score: 0.3819\n",
      "     from now, f1 score: 0.3819233687405156 accuracy: 0.8013927194599784\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
     ]
    }
   ],
   "source": [
    "acc_no_bal, f1_no_bal = kfold_logistic_ridge(X_train_data, Y_train_data, no_balanced_data, k=5, gamma=0.5, lambda_=1e-3, alpha = 0.7)\n",
    "acc_bal, f1_bal = kfold_logistic_ridge(X_train_data, Y_train_data, balanced_data, k=5, gamma=0.5, lambda_=1e-3, alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 49,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "3631ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Without balancing accuracy: 0.9133000000000001 F1 Score: 0.03582089552238801\n",
      "With balancing accuracy: 0.8471 F1 Score: 0.05139263252470795\n"
=======
      "Without balancing accuracy: 0.9125359989028905 F1 Score: 0.031809126184724444\n",
      "With balancing accuracy: 0.8363265119539214 F1 Score: 0.3940022237887491\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
     ]
    }
   ],
   "source": [
    "print(\"Without balancing accuracy:\", acc_no_bal, \"F1 Score:\", f1_no_bal)\n",
    "print(\"With balancing accuracy:\", acc_bal, \"F1 Score:\", f1_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6fac6",
   "metadata": {},
   "source": [
    "As we see, F1 score increases with balancing. The downfall of accuracy must be considered carefully, so the not balanced model tends to predict the majority class, without understanding the resons of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063915c2",
   "metadata": {},
   "source": [
    "# NaN feature removal\n",
    "Now we want to test the following hypothesis: are features with many NaNs relevant? The easiest approach to assess this is by removing the features with a high number of NaNs and observing the impact. Data balancing will be applied, as we have already seen that it is beneficial. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 50,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "ab04c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_features(x_train, x_val, y_train, y_val):\n",
    "\n",
    "    # replace missing values with mean and standardize features\n",
    "    x_train = impute_missing_values(x_train, strategy='mean')\n",
    "    x_val = impute_missing_values(x_val, strategy='mean')\n",
    "    x_train, means, stds = standardize_features(x_train)\n",
    "    x_val = (x_val - means) / stds\n",
    "    # balance data by undersampling, so that both classes have the same number of samples\n",
    "    x_train, y_train = balance_data(x_train, y_train, method='undersample')\n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "def no_NaN_features(x_train, x_val, y_train, y_val, threshold=0.3):\n",
    "    \n",
    "    # remove features that contain NaN values in the training set\n",
    "    x_train, keep_mask = remove_nan_features(x_train, threshold=threshold) # we remove features with more than 30% NaN values\n",
    "    x_val = x_val[:, keep_mask]\n",
    "    # replace missing values with mean and standardize features\n",
    "    x_train = impute_missing_values(x_train, strategy='mean')\n",
    "    x_val = impute_missing_values(x_val, strategy='mean')\n",
    "    x_train, means, stds = standardize_features(x_train)\n",
    "    x_val = (x_val - means) / stds\n",
    "    # balance data by undersampling, so that both classes have the same number of samples\n",
    "    x_train, y_train = balance_data(x_train, y_train, method='undersample')\n",
    "    print(\"Number of removes features due to NaN values:\", np.sum(~keep_mask))\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 51,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "09905371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476219\n",
      "Iteration   200, loss = 0.475579\n",
      "Iteration   300, loss = 0.475435\n",
      "Iteration   400, loss = 0.475378\n",
      "Iteration   500, loss = 0.475352\n",
      "Iteration   600, loss = 0.475338\n",
      "Iteration   700, loss = 0.475331\n",
      "Iteration   800, loss = 0.475326\n",
      "Iteration   900, loss = 0.475323\n",
      "Iteration  1000, loss = 0.475321\n",
      "Iteration  1100, loss = 0.475319\n",
      "Converged at iteration 1149\n",
      " Accuracy: 85.28%\n",
      " F1 Score: 0.4096\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40960762742940915 accuracy: 0.8528044859585232\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476243\n",
      "Iteration   200, loss = 0.475540\n",
      "Iteration   300, loss = 0.475363\n",
      "Iteration   400, loss = 0.475293\n",
      "Iteration   500, loss = 0.475260\n",
      "Iteration   600, loss = 0.475243\n",
      "Iteration   700, loss = 0.475234\n",
      "Iteration   800, loss = 0.475229\n",
      "Iteration   900, loss = 0.475225\n",
      "Iteration  1000, loss = 0.475223\n",
      "Iteration  1100, loss = 0.475221\n",
      "Converged at iteration 1185\n",
      " Accuracy: 77.96%\n",
      " F1 Score: 0.3812\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.381209087408548 accuracy: 0.7796181449708199\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476633\n",
      "Iteration   200, loss = 0.475916\n",
      "Iteration   300, loss = 0.475727\n",
      "Iteration   400, loss = 0.475647\n",
      "Iteration   500, loss = 0.475608\n",
      "Iteration   600, loss = 0.475589\n",
      "Iteration   700, loss = 0.475578\n",
      "Iteration   800, loss = 0.475571\n",
      "Iteration   900, loss = 0.475567\n",
      "Iteration  1000, loss = 0.475565\n",
      "Iteration  1100, loss = 0.475563\n",
      "Iteration  1200, loss = 0.475562\n",
      "Converged at iteration 1201\n",
      " Accuracy: 89.74%\n",
      " F1 Score: 0.3861\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.3860672927874527 accuracy: 0.8974050314657077\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.470298\n",
      "Iteration   200, loss = 0.469570\n",
      "Iteration   300, loss = 0.469389\n",
      "Iteration   400, loss = 0.469313\n",
      "Iteration   500, loss = 0.469277\n",
      "Iteration   600, loss = 0.469258\n",
      "Iteration   700, loss = 0.469247\n",
      "Iteration   800, loss = 0.469241\n",
      "Iteration   900, loss = 0.469237\n",
      "Iteration  1000, loss = 0.469234\n",
      "Iteration  1100, loss = 0.469232\n",
      "Iteration  1200, loss = 0.469231\n",
      "Converged at iteration 1232\n",
      " Accuracy: 85.04%\n",
      " F1 Score: 0.4112\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.41120374257781994 accuracy: 0.8504121779145778\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473245\n",
      "Iteration   200, loss = 0.472628\n",
      "Iteration   300, loss = 0.472481\n",
      "Iteration   400, loss = 0.472417\n",
      "Iteration   500, loss = 0.472385\n",
      "Iteration   600, loss = 0.472368\n",
      "Iteration   700, loss = 0.472357\n",
      "Iteration   800, loss = 0.472351\n",
      "Iteration   900, loss = 0.472347\n",
      "Iteration  1000, loss = 0.472345\n",
      "Iteration  1100, loss = 0.472343\n",
      "Iteration  1200, loss = 0.472341\n",
      "Converged at iteration 1230\n",
      " Accuracy: 80.14%\n",
      " F1 Score: 0.3819\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.3819233687405156 accuracy: 0.8013927194599784\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 177\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480207\n",
      "Iteration   200, loss = 0.479701\n",
      "Iteration   300, loss = 0.479586\n",
      "Iteration   400, loss = 0.479540\n",
      "Iteration   500, loss = 0.479519\n",
      "Iteration   600, loss = 0.479508\n",
      "Iteration   700, loss = 0.479502\n",
      "Iteration   800, loss = 0.479498\n",
      "Iteration   900, loss = 0.479496\n",
      "Iteration  1000, loss = 0.479494\n",
      "Converged at iteration 1095\n",
      " Accuracy: 85.17%\n",
      " F1 Score: 0.4083\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40829481877888546 accuracy: 0.8517378517988023\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 177\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480584\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479826\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479766\n",
      "Converged at iteration 1194\n",
      " Accuracy: 85.29%\n",
      " F1 Score: 0.4087\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.4086983154670745 accuracy: 0.8529111493744953\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 177\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480762\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479903\n",
      "Converged at iteration 1095\n",
      " Accuracy: 85.33%\n",
      " F1 Score: 0.4098\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40978480779841775 accuracy: 0.8533073277766773\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 177\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474105\n",
      "Iteration   200, loss = 0.473509\n",
      "Iteration   300, loss = 0.473364\n",
      "Iteration   400, loss = 0.473305\n",
      "Iteration   500, loss = 0.473278\n",
      "Iteration   600, loss = 0.473265\n",
      "Iteration   700, loss = 0.473257\n",
      "Iteration   800, loss = 0.473253\n",
      "Iteration   900, loss = 0.473250\n",
      "Iteration  1000, loss = 0.473248\n",
      "Iteration  1100, loss = 0.473246\n",
      "Converged at iteration 1140\n",
      " Accuracy: 85.05%\n",
      " F1 Score: 0.4084\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.4084413626771174 accuracy: 0.8505036036996968\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 177\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477456\n",
      "Iteration   200, loss = 0.476967\n",
      "Iteration   300, loss = 0.476842\n",
      "Iteration   400, loss = 0.476788\n",
      "Iteration   500, loss = 0.476761\n",
      "Iteration   600, loss = 0.476747\n",
      "Iteration   700, loss = 0.476739\n",
      "Iteration   800, loss = 0.476734\n",
      "Iteration   900, loss = 0.476730\n",
      "Iteration  1000, loss = 0.476728\n",
      "Iteration  1100, loss = 0.476727\n",
      "Converged at iteration 1181\n",
      " Accuracy: 85.10%\n",
<<<<<<< HEAD
      " F1 Score: 0.4004\n"
=======
      " F1 Score: 0.4004\n",
      "     from now, f1 score: 0.40044152817808254 accuracy: 0.8510216831487041\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
     ]
    }
   ],
   "source": [
    "acc_NaN, f1_NaN = kfold_logistic_ridge(X_train_data, Y_train_data, NaN_features, k=5, gamma=0.5, lambda_=1e-3, alpha = 0.7)\n",
    "acc_no_NaN, f1_no_NaN = kfold_logistic_ridge(X_train_data, Y_train_data, no_NaN_features, k=5, gamma=0.5, lambda_=1e-3, alpha = 0.7)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": null,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "904ef622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With NaN features accuracy: 0.8363265119539214 F1 Score: 0.3940022237887491\n",
      "Without NaN features accuracy: 0.8518963231596752 F1 Score: 0.4071321665799156\n"
     ]
    }
   ],
   "source": [
    "print(\"With NaN features accuracy:\", acc_NaN, \"F1 Score:\", f1_NaN)\n",
<<<<<<< HEAD
    "print(\"Without NaN features accuracy:\", acc_no_NaN, \"F1 Score:\", f1_no_NaN)"
=======
    "print(\"Without NaN features accuracy:\", acc_no_NaN, \"F1 Score:\", f1_no_NaN) # > 30% NaN features removed"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9a824",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Removing NaN features seems to improve the model, as we’ve seen. Let’s try to tune the percentage of removed NaNs by looking at the histogram."
=======
    "In this last example, we were setting the removal threshold arbitrary at 30%. Since removing NaN features seems to improve the model, as we’ve seen, let’s try to tune the percentage of removed NaNs by looking at the NaNs histogram."
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 53,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "1678cce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
<<<<<<< HEAD
    "\n",
=======
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
    "# Compute percentage of NaNs per column\n",
    "nan_percentage = np.isnan(X_train_data).sum(axis=0) / X_train_data.shape[0] * 100\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(nan_percentage, bins=20, edgecolor='black')\n",
    "plt.title(\"Histogram of NaN Percentage per Column\")\n",
    "plt.xlabel(\"Percentage of NaN values (%)\")\n",
    "plt.ylabel(\"Number of Columns\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 54,
   "id": "39a05345",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"For 20% NaN threshold\"\n",
    "\n",
    "def no_NaN_20(x_train, x_val, y_train, y_val):\n",
    "    \n",
    "    return no_NaN_features(x_train, x_val, y_train, y_val, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "7f7db29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 85.18%\n",
      " F1 Score: 0.4084\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40839160839160793 accuracy: 0.8517530894296554\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 85.29%\n",
      " F1 Score: 0.4086\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.4086232239098476 accuracy: 0.8528654364819358\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 85.32%\n",
      " F1 Score: 0.4096\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40958685791344807 accuracy: 0.8532311396224115\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 85.05%\n",
      " F1 Score: 0.4083\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40834791000663445 accuracy: 0.8505340789614031\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 85.12%\n",
      " F1 Score: 0.4008\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40083430464388636 accuracy: 0.8511740594572356\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "\n",
      "With 20% NaN threshold accuracy: 0.8519115607905283 F1 Score: 0.40715678097308483\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\"For 20% NaN threshold\"\n",
    "\n",
    "def no_NaN_20(x_train, x_val, y_train, y_val):\n",
    "    \n",
    "    return no_NaN_features(x_train, x_val, y_train, y_val, threshold=0.2)\n",
    "\n",
=======
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
    "acc_20_NaN, f1_20_NaN = kfold_logistic_ridge(X_train_data, Y_train_data, no_NaN_20, k=5, gamma=0.5, lambda_=1e-3, alpha = 0.7)\n",
    "print(\"\\nWith 20% NaN threshold accuracy:\", acc_20_NaN, \"F1 Score:\", f1_20_NaN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": 56,
   "id": "83bebf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"For 75% NaN threshold\"\n",
    "\n",
    "def no_NaN_75(x_train, x_val, y_train, y_val):\n",
    "    \n",
    "    return no_NaN_features(x_train, x_val, y_train, y_val, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "621c984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 85.18%\n",
      " F1 Score: 0.4087\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.4087316064696578 accuracy: 0.8518292775839212\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 85.28%\n",
      " F1 Score: 0.4087\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.4087180115097338 accuracy: 0.8528349612202295\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 85.36%\n",
      " F1 Score: 0.4107\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.4106748466257664 accuracy: 0.8536273180245936\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 85.08%\n",
      " F1 Score: 0.4104\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.41035832580547976 accuracy: 0.8508083563167599\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 84.97%\n",
      " F1 Score: 0.3980\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.39799780246612093 accuracy: 0.8497264845261858\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "\n",
      "With 75% NaN threshold accuracy: 0.851765279534338 F1 Score: 0.4072961185753517\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\"For 75% NaN threshold\"\n",
    "\n",
    "def no_NaN_75(x_train, x_val, y_train, y_val):\n",
    "    \n",
    "    return no_NaN_features(x_train, x_val, y_train, y_val, threshold=0.75)\n",
    "\n",
=======
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
    "acc_75_NaN, f1_75_NaN = kfold_logistic_ridge(X_train_data, Y_train_data, no_NaN_75, k=5, gamma=0.5, lambda_=1e-3, alpha = 0.7)\n",
    "print(\"\\nWith 75% NaN threshold accuracy:\", acc_75_NaN, \"F1 Score:\", f1_75_NaN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 58,
   "id": "c47fd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"For 5% NaN threshold\"\n",
    "\n",
    "def no_NaN_5(x_train, x_val, y_train, y_val):\n",
    "    \n",
    "    return no_NaN_features(x_train, x_val, y_train, y_val, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "2b559af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 206\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.488448\n",
      "Iteration   200, loss = 0.488064\n",
      "Iteration   300, loss = 0.487994\n",
      "Iteration   400, loss = 0.487965\n",
      "Iteration   500, loss = 0.487950\n",
      "Iteration   600, loss = 0.487942\n",
      "Iteration   700, loss = 0.487937\n",
      "Iteration   800, loss = 0.487935\n",
      "Iteration   900, loss = 0.487933\n",
      "Iteration  1000, loss = 0.487931\n",
      "Converged at iteration 1014\n",
      " Accuracy: 85.03%\n",
      " F1 Score: 0.3991\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.3991437308868497 accuracy: 0.8503055144986058\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 206\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.489224\n",
      "Iteration   200, loss = 0.488876\n",
      "Iteration   300, loss = 0.488805\n",
      "Iteration   400, loss = 0.488773\n",
      "Iteration   500, loss = 0.488757\n",
      "Iteration   600, loss = 0.488747\n",
      "Iteration   700, loss = 0.488742\n",
      "Iteration   800, loss = 0.488738\n",
      "Iteration   900, loss = 0.488736\n",
      "Iteration  1000, loss = 0.488734\n",
      "Iteration  1100, loss = 0.488733\n",
      "Converged at iteration 1122\n",
      " Accuracy: 85.12%\n",
      " F1 Score: 0.4010\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.4009812940815696 accuracy: 0.8511740594572356\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 206\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.489241\n",
      "Iteration   200, loss = 0.488832\n",
      "Iteration   300, loss = 0.488739\n",
      "Iteration   400, loss = 0.488697\n",
      "Iteration   500, loss = 0.488676\n",
      "Iteration   600, loss = 0.488665\n",
      "Iteration   700, loss = 0.488658\n",
      "Iteration   800, loss = 0.488655\n",
      "Iteration   900, loss = 0.488652\n",
      "Iteration  1000, loss = 0.488651\n",
      "Converged at iteration 1072\n",
      " Accuracy: 85.17%\n",
      " F1 Score: 0.4020\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.40201560867694913 accuracy: 0.8517226141679491\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 206\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.482114\n",
      "Iteration   200, loss = 0.481676\n",
      "Iteration   300, loss = 0.481586\n",
      "Iteration   400, loss = 0.481547\n",
      "Iteration   500, loss = 0.481527\n",
      "Iteration   600, loss = 0.481517\n",
      "Iteration   700, loss = 0.481511\n",
      "Iteration   800, loss = 0.481507\n",
      "Iteration   900, loss = 0.481504\n",
      "Iteration  1000, loss = 0.481503\n",
      "Iteration  1100, loss = 0.481502\n",
      "Converged at iteration 1113\n",
      " Accuracy: 84.74%\n",
      " F1 Score: 0.3977\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.3976910588659728 accuracy: 0.8473646517439468\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 206\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.485181\n",
      "Iteration   200, loss = 0.484817\n",
      "Iteration   300, loss = 0.484740\n",
      "Iteration   400, loss = 0.484704\n",
      "Iteration   500, loss = 0.484685\n",
      "Iteration   600, loss = 0.484675\n",
      "Iteration   700, loss = 0.484668\n",
      "Iteration   800, loss = 0.484665\n",
      "Iteration   900, loss = 0.484662\n",
      "Iteration  1000, loss = 0.484660\n",
      "Converged at iteration 1090\n",
      " Accuracy: 84.80%\n",
      " F1 Score: 0.3903\n",
<<<<<<< HEAD
=======
      "     from now, f1 score: 0.3903213980202856 accuracy: 0.8479589193472199\n",
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
      "\n",
      "With 20% NaN threshold accuracy: 0.8497051518429914 F1 Score: 0.39803061810632534\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\"For 5% NaN threshold\"\n",
    "\n",
    "def no_NaN_5(x_train, x_val, y_train, y_val):\n",
    "    \n",
    "    return no_NaN_features(x_train, x_val, y_train, y_val, threshold=0.05)\n",
    "\n",
=======
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
    "acc_5_NaN, f1_5_NaN = kfold_logistic_ridge(X_train_data, Y_train_data, no_NaN_5, k=5, gamma=0.5, lambda_=1e-3, alpha = 0.7)\n",
    "print(\"\\nWith 20% NaN threshold accuracy:\", acc_5_NaN, \"F1 Score:\", f1_5_NaN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 60,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "8f154804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "With NaN features accuracy: 0.8363265119539214 F1 Score: 0.3940022237887491\n",
      "Without more than 5% NaN features accuracy: 0.8497051518429914 F1 Score: 0.39803061810632534\n",
      "Without more than 20% NaN threshold accuracy: 0.8519115607905283 F1 Score: 0.40715678097308483\n",
      "Without more than 30% NaN features accuracy: 0.8518963231596752 F1 Score: 0.4071321665799156\n",
      "Without more than 75% NaN threshold accuracy: 0.851765279534338 F1 Score: 0.4072961185753517\n"
=======
      "With NaN features. Accuracy: 0.8363265119539214 F1 Score: 0.3940022237887491\n",
      "Without more than 5% NaN features. Accuracy: 0.8497051518429914 F1 Score: 0.39803061810632534\n",
      "Without more than 20% NaN features. Accuracy: 0.8519115607905283 F1 Score: 0.40715678097308483\n",
      "Without more than 30% NaN features. Accuracy: 0.8518963231596752 F1 Score: 0.4071321665799156\n",
      "Without more than 75% NaN features. Accuracy: 0.851765279534338 F1 Score: 0.4072961185753517\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "print(\"With NaN features accuracy:\", acc_NaN, \"F1 Score:\", f1_NaN)\n",
    "print(\"Without more than 5% NaN features accuracy:\", acc_5_NaN, \"F1 Score:\", f1_5_NaN)\n",
    "print(\"Without more than 20% NaN threshold accuracy:\", acc_20_NaN, \"F1 Score:\", f1_20_NaN)\n",
    "print(\"Without more than 30% NaN features accuracy:\", acc_no_NaN, \"F1 Score:\", f1_no_NaN)\n",
    "print(\"Without more than 75% NaN threshold accuracy:\", acc_75_NaN, \"F1 Score:\", f1_75_NaN)"
=======
    "print(\"With NaN features. Accuracy:\", acc_NaN, \"F1 Score:\", f1_NaN)\n",
    "print(\"Without more than 5% NaN features. Accuracy:\", acc_5_NaN, \"F1 Score:\", f1_5_NaN)\n",
    "print(\"Without more than 20% NaN features. Accuracy:\", acc_20_NaN, \"F1 Score:\", f1_20_NaN)\n",
    "print(\"Without more than 30% NaN features. Accuracy:\", acc_no_NaN, \"F1 Score:\", f1_no_NaN)\n",
    "print(\"Without more than 75% NaN features. Accuracy:\", acc_75_NaN, \"F1 Score:\", f1_75_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8623a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentatge of removed feature columns when removing features with more than 5% NaN values 70.7165109034268\n",
      "Percentatge of removed feature columns when removing features with more than 20% NaN values 70.7165109034268\n",
      "Percentatge of removed feature columns when removing features with more than 75% NaN values 69.47040498442367\n"
     ]
    }
   ],
   "source": [
    "# Print the percentatge of features that are beeing removed in diferent data preprocessings\n",
    "print(\"Percentatge of removed feature columns when removing features with more than 5% NaN values\", np.mean(nan_percentage > 0.05) * 100)\n",
    "print(\"Percentatge of removed feature columns when removing features with more than 20% NaN values\", np.mean(nan_percentage > 0.2) * 100)\n",
    "print(\"Percentatge of removed feature columns when removing features with more than 75% NaN values\", np.mean(nan_percentage > 0.75) * 100)"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "51c0122d",
   "metadata": {},
   "source": [
    "As we see, it seems that the features with more than 20% of NaNs aren't improving our model. "
=======
   "id": "ddfc3851",
   "metadata": {},
   "source": [
    "As we see, it seems slightly better to take the 75% removal, but there is no big difference between the F1 scores or the number of eliminated features. Maybe some more intelligent feature elimination is teh key. "
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12fff07",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Effect of overfitting\n",
    "Now we will check if this is due to "
=======
    "## Effect of underfitting\n",
    "Now we will try to see if we are overfitting or underfitting by tracking the validation and the training loss for diferent sizes of the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc35cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix lamda first\n",
    "def train_method(y, x):  \n",
    "    return logistic_regression_penalized_gradient_descent(y, x, gamma = 0.5, lambda_ = 1e-3)\n",
    "def evaluator(y, x, w):\n",
    "    return evaluate_logistic_model(y, x, w, threshold=0.7, lambda_ = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27f47f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocess (262508, 321) (262508,)\n",
      "Number of removes features due to NaN values: 117\n",
      "After preprocess (46564, 204) (46564,)\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.469611\n",
      "Iteration   200, loss = 0.468522\n",
      "Iteration   300, loss = 0.468209\n",
      "Iteration   400, loss = 0.468066\n",
      "Iteration   500, loss = 0.467990\n",
      "Iteration   600, loss = 0.467946\n",
      "Iteration   700, loss = 0.467920\n",
      "Iteration   800, loss = 0.467903\n",
      "Iteration   900, loss = 0.467893\n",
      "Iteration  1000, loss = 0.467886\n",
      "Iteration  1100, loss = 0.467881\n",
      "Iteration  1200, loss = 0.467878\n",
      "Iteration  1300, loss = 0.467876\n",
      "Iteration  1400, loss = 0.467874\n",
      "Converged at iteration 1489\n",
      " Accuracy: 85.07%\n",
      " F1 Score: 0.4017\n",
      "\n",
      "Validation loss: 0.5010026290736113 f1 score 0.4016853932584265 with data size of 13125\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.471151\n",
      "Iteration   200, loss = 0.470084\n",
      "Iteration   300, loss = 0.469781\n",
      "Iteration   400, loss = 0.469644\n",
      "Iteration   500, loss = 0.469572\n",
      "Iteration   600, loss = 0.469530\n",
      "Iteration   700, loss = 0.469505\n",
      "Iteration   800, loss = 0.469489\n",
      "Iteration   900, loss = 0.469479\n",
      "Iteration  1000, loss = 0.469472\n",
      "Iteration  1100, loss = 0.469467\n",
      "Iteration  1200, loss = 0.469464\n",
      "Iteration  1300, loss = 0.469462\n",
      "Iteration  1400, loss = 0.469460\n",
      "Converged at iteration 1497\n",
      " Accuracy: 85.05%\n",
      " F1 Score: 0.4005\n",
      "\n",
      "Validation loss: 0.5002411309475795 f1 score 0.4005131651292072 with data size of 13816\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.471471\n",
      "Iteration   200, loss = 0.470437\n",
      "Iteration   300, loss = 0.470153\n",
      "Iteration   400, loss = 0.470026\n",
      "Iteration   500, loss = 0.469960\n",
      "Iteration   600, loss = 0.469923\n",
      "Iteration   700, loss = 0.469901\n",
      "Iteration   800, loss = 0.469887\n",
      "Iteration   900, loss = 0.469878\n",
      "Iteration  1000, loss = 0.469872\n",
      "Iteration  1100, loss = 0.469867\n",
      "Iteration  1200, loss = 0.469865\n",
      "Iteration  1300, loss = 0.469863\n",
      "Iteration  1400, loss = 0.469861\n",
      "Converged at iteration 1465\n",
      " Accuracy: 85.07%\n",
      " F1 Score: 0.4019\n",
      "\n",
      "Validation loss: 0.4999129771625355 f1 score 0.4018554687499995 with data size of 14583\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472919\n",
      "Iteration   200, loss = 0.471938\n",
      "Iteration   300, loss = 0.471667\n",
      "Iteration   400, loss = 0.471545\n",
      "Iteration   500, loss = 0.471483\n",
      "Iteration   600, loss = 0.471447\n",
      "Iteration   700, loss = 0.471426\n",
      "Iteration   800, loss = 0.471413\n",
      "Iteration   900, loss = 0.471404\n",
      "Iteration  1000, loss = 0.471398\n",
      "Iteration  1100, loss = 0.471394\n",
      "Iteration  1200, loss = 0.471392\n",
      "Iteration  1300, loss = 0.471390\n",
      "Iteration  1400, loss = 0.471388\n",
      "Converged at iteration 1453\n",
      " Accuracy: 85.20%\n",
      " F1 Score: 0.4031\n",
      "\n",
      "Validation loss: 0.49772515800750267 f1 score 0.40312269486107655 with data size of 15441\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473947\n",
      "Iteration   200, loss = 0.473008\n",
      "Iteration   300, loss = 0.472753\n",
      "Iteration   400, loss = 0.472641\n",
      "Iteration   500, loss = 0.472583\n",
      "Iteration   600, loss = 0.472551\n",
      "Iteration   700, loss = 0.472532\n",
      "Iteration   800, loss = 0.472521\n",
      "Iteration   900, loss = 0.472513\n",
      "Iteration  1000, loss = 0.472508\n",
      "Iteration  1100, loss = 0.472504\n",
      "Iteration  1200, loss = 0.472502\n",
      "Iteration  1300, loss = 0.472500\n",
      "Iteration  1400, loss = 0.472499\n",
      "Converged at iteration 1420\n",
      " Accuracy: 85.26%\n",
      " F1 Score: 0.4038\n",
      "\n",
      "Validation loss: 0.49732423017837174 f1 score 0.4038461538461534 with data size of 16406\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473905\n",
      "Iteration   200, loss = 0.472991\n",
      "Iteration   300, loss = 0.472742\n",
      "Iteration   400, loss = 0.472633\n",
      "Iteration   500, loss = 0.472577\n",
      "Iteration   600, loss = 0.472546\n",
      "Iteration   700, loss = 0.472528\n",
      "Iteration   800, loss = 0.472516\n",
      "Iteration   900, loss = 0.472508\n",
      "Iteration  1000, loss = 0.472503\n",
      "Iteration  1100, loss = 0.472500\n",
      "Iteration  1200, loss = 0.472497\n",
      "Iteration  1300, loss = 0.472495\n",
      "Iteration  1400, loss = 0.472494\n",
      "Converged at iteration 1423\n",
      " Accuracy: 85.27%\n",
      " F1 Score: 0.4040\n",
      "\n",
      "Validation loss: 0.49722328378040115 f1 score 0.40404289412054684 with data size of 17500\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474093\n",
      "Iteration   200, loss = 0.473199\n",
      "Iteration   300, loss = 0.472956\n",
      "Iteration   400, loss = 0.472849\n",
      "Iteration   500, loss = 0.472795\n",
      "Iteration   600, loss = 0.472765\n",
      "Iteration   700, loss = 0.472747\n",
      "Iteration   800, loss = 0.472736\n",
      "Iteration   900, loss = 0.472728\n",
      "Iteration  1000, loss = 0.472723\n",
      "Iteration  1100, loss = 0.472720\n",
      "Iteration  1200, loss = 0.472717\n",
      "Iteration  1300, loss = 0.472716\n",
      "Iteration  1400, loss = 0.472714\n",
      "Converged at iteration 1416\n",
      " Accuracy: 85.28%\n",
      " F1 Score: 0.4031\n",
      "\n",
      "Validation loss: 0.4963732002959759 f1 score 0.4030643766217714 with data size of 18750\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473976\n",
      "Iteration   200, loss = 0.473102\n",
      "Iteration   300, loss = 0.472868\n",
      "Iteration   400, loss = 0.472769\n",
      "Iteration   500, loss = 0.472721\n",
      "Iteration   600, loss = 0.472695\n",
      "Iteration   700, loss = 0.472680\n",
      "Iteration   800, loss = 0.472671\n",
      "Iteration   900, loss = 0.472665\n",
      "Iteration  1000, loss = 0.472661\n",
      "Iteration  1100, loss = 0.472659\n",
      "Iteration  1200, loss = 0.472657\n",
      "Iteration  1300, loss = 0.472655\n",
      "Converged at iteration 1336\n",
      " Accuracy: 85.37%\n",
      " F1 Score: 0.4045\n",
      "\n",
      "Validation loss: 0.4936889178586833 f1 score 0.40451388888888845 with data size of 20192\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475274\n",
      "Iteration   200, loss = 0.474461\n",
      "Iteration   300, loss = 0.474240\n",
      "Iteration   400, loss = 0.474145\n",
      "Iteration   500, loss = 0.474098\n",
      "Iteration   600, loss = 0.474072\n",
      "Iteration   700, loss = 0.474057\n",
      "Iteration   800, loss = 0.474048\n",
      "Iteration   900, loss = 0.474042\n",
      "Iteration  1000, loss = 0.474038\n",
      "Iteration  1100, loss = 0.474035\n",
      "Iteration  1200, loss = 0.474033\n",
      "Iteration  1300, loss = 0.474032\n",
      "Converged at iteration 1354\n",
      " Accuracy: 85.41%\n",
      " F1 Score: 0.4046\n",
      "\n",
      "Validation loss: 0.49355570493739165 f1 score 0.40460199004975084 with data size of 21875\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476556\n",
      "Iteration   200, loss = 0.475759\n",
      "Iteration   300, loss = 0.475526\n",
      "Iteration   400, loss = 0.475422\n",
      "Iteration   500, loss = 0.475368\n",
      "Iteration   600, loss = 0.475338\n",
      "Iteration   700, loss = 0.475321\n",
      "Iteration   800, loss = 0.475310\n",
      "Iteration   900, loss = 0.475303\n",
      "Iteration  1000, loss = 0.475298\n",
      "Iteration  1100, loss = 0.475295\n",
      "Iteration  1200, loss = 0.475293\n",
      "Iteration  1300, loss = 0.475291\n",
      "Converged at iteration 1391\n",
      " Accuracy: 85.37%\n",
      " F1 Score: 0.4045\n",
      "\n",
      "Validation loss: 0.4957604696577573 f1 score 0.4044665012406944 with data size of 23864\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476540\n",
      "Iteration   200, loss = 0.475742\n",
      "Iteration   300, loss = 0.475508\n",
      "Iteration   400, loss = 0.475401\n",
      "Iteration   500, loss = 0.475345\n",
      "Iteration   600, loss = 0.475314\n",
      "Iteration   700, loss = 0.475296\n",
      "Iteration   800, loss = 0.475285\n",
      "Iteration   900, loss = 0.475277\n",
      "Iteration  1000, loss = 0.475272\n",
      "Iteration  1100, loss = 0.475269\n",
      "Iteration  1200, loss = 0.475267\n",
      "Iteration  1300, loss = 0.475265\n",
      "Converged at iteration 1397\n",
      " Accuracy: 85.32%\n",
      " F1 Score: 0.4039\n",
      "\n",
      "Validation loss: 0.49538982097637935 f1 score 0.40391161725567826 with data size of 26250\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478248\n",
      "Iteration   200, loss = 0.477476\n",
      "Iteration   300, loss = 0.477244\n",
      "Iteration   400, loss = 0.477133\n",
      "Iteration   500, loss = 0.477075\n",
      "Iteration   600, loss = 0.477041\n",
      "Iteration   700, loss = 0.477021\n",
      "Iteration   800, loss = 0.477008\n",
      "Iteration   900, loss = 0.477000\n",
      "Iteration  1000, loss = 0.476994\n",
      "Iteration  1100, loss = 0.476990\n",
      "Iteration  1200, loss = 0.476988\n",
      "Iteration  1300, loss = 0.476986\n",
      "Iteration  1400, loss = 0.476985\n",
      "Converged at iteration 1431\n",
      " Accuracy: 85.42%\n",
      " F1 Score: 0.4062\n",
      "\n",
      "Validation loss: 0.4947342215521572 f1 score 0.40620732464307835 with data size of 29167\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477414\n",
      "Iteration   200, loss = 0.476672\n",
      "Iteration   300, loss = 0.476456\n",
      "Iteration   400, loss = 0.476354\n",
      "Iteration   500, loss = 0.476300\n",
      "Iteration   600, loss = 0.476269\n",
      "Iteration   700, loss = 0.476251\n",
      "Iteration   800, loss = 0.476239\n",
      "Iteration   900, loss = 0.476232\n",
      "Iteration  1000, loss = 0.476227\n",
      "Iteration  1100, loss = 0.476223\n",
      "Iteration  1200, loss = 0.476221\n",
      "Iteration  1300, loss = 0.476219\n",
      "Converged at iteration 1390\n",
      " Accuracy: 85.37%\n",
      " F1 Score: 0.4072\n",
      "\n",
      "Validation loss: 0.49573718343682543 f1 score 0.4072336748549557 with data size of 32813\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476406\n",
      "Iteration   200, loss = 0.475673\n",
      "Iteration   300, loss = 0.475465\n",
      "Iteration   400, loss = 0.475368\n",
      "Iteration   500, loss = 0.475318\n",
      "Iteration   600, loss = 0.475289\n",
      "Iteration   700, loss = 0.475272\n",
      "Iteration   800, loss = 0.475261\n",
      "Iteration   900, loss = 0.475254\n",
      "Iteration  1000, loss = 0.475250\n",
      "Iteration  1100, loss = 0.475247\n",
      "Iteration  1200, loss = 0.475245\n",
      "Iteration  1300, loss = 0.475243\n",
      "Converged at iteration 1365\n",
      " Accuracy: 85.32%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.4955658849248238 f1 score 0.40762373193974744 with data size of 37501\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.478575\n",
      "Iteration   200, loss = 0.477826\n",
      "Iteration   300, loss = 0.477615\n",
      "Iteration   400, loss = 0.477519\n",
      "Iteration   500, loss = 0.477469\n",
      "Iteration   600, loss = 0.477442\n",
      "Iteration   700, loss = 0.477426\n",
      "Iteration   800, loss = 0.477416\n",
      "Iteration   900, loss = 0.477410\n",
      "Iteration  1000, loss = 0.477405\n",
      "Iteration  1100, loss = 0.477403\n",
      "Iteration  1200, loss = 0.477401\n",
      "Iteration  1300, loss = 0.477400\n",
      "Converged at iteration 1330\n",
      " Accuracy: 85.41%\n",
      " F1 Score: 0.4070\n",
      "\n",
      "Validation loss: 0.49554150435428773 f1 score 0.40703362020927447 with data size of 43751\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477948\n",
      "Iteration   200, loss = 0.477213\n",
      "Iteration   300, loss = 0.477013\n",
      "Iteration   400, loss = 0.476923\n",
      "Iteration   500, loss = 0.476878\n",
      "Iteration   600, loss = 0.476854\n",
      "Iteration   700, loss = 0.476840\n",
      "Iteration   800, loss = 0.476831\n",
      "Iteration   900, loss = 0.476826\n",
      "Iteration  1000, loss = 0.476822\n",
      "Iteration  1100, loss = 0.476820\n",
      "Iteration  1200, loss = 0.476819\n",
      "Converged at iteration 1279\n",
      " Accuracy: 85.43%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.4945827345123014 f1 score 0.40763226366001687 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477948\n",
      "Iteration   200, loss = 0.477213\n",
      "Iteration   300, loss = 0.477013\n",
      "Iteration   400, loss = 0.476923\n",
      "Iteration   500, loss = 0.476878\n",
      "Iteration   600, loss = 0.476854\n",
      "Iteration   700, loss = 0.476840\n",
      "Iteration   800, loss = 0.476831\n",
      "Iteration   900, loss = 0.476826\n",
      "Iteration  1000, loss = 0.476822\n",
      "Iteration  1100, loss = 0.476820\n",
      "Iteration  1200, loss = 0.476819\n",
      "Converged at iteration 1279\n",
      " Accuracy: 85.43%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.4945827345123014 f1 score 0.40763226366001687 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477948\n",
      "Iteration   200, loss = 0.477213\n",
      "Iteration   300, loss = 0.477013\n",
      "Iteration   400, loss = 0.476923\n",
      "Iteration   500, loss = 0.476878\n",
      "Iteration   600, loss = 0.476854\n",
      "Iteration   700, loss = 0.476840\n",
      "Iteration   800, loss = 0.476831\n",
      "Iteration   900, loss = 0.476826\n",
      "Iteration  1000, loss = 0.476822\n",
      "Iteration  1100, loss = 0.476820\n",
      "Iteration  1200, loss = 0.476819\n",
      "Converged at iteration 1279\n",
      " Accuracy: 85.43%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.4945827345123014 f1 score 0.40763226366001687 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477948\n",
      "Iteration   200, loss = 0.477213\n",
      "Iteration   300, loss = 0.477013\n",
      "Iteration   400, loss = 0.476923\n",
      "Iteration   500, loss = 0.476878\n",
      "Iteration   600, loss = 0.476854\n",
      "Iteration   700, loss = 0.476840\n",
      "Iteration   800, loss = 0.476831\n",
      "Iteration   900, loss = 0.476826\n",
      "Iteration  1000, loss = 0.476822\n",
      "Iteration  1100, loss = 0.476820\n",
      "Iteration  1200, loss = 0.476819\n",
      "Converged at iteration 1279\n",
      " Accuracy: 85.43%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.4945827345123014 f1 score 0.40763226366001687 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477948\n",
      "Iteration   200, loss = 0.477213\n",
      "Iteration   300, loss = 0.477013\n",
      "Iteration   400, loss = 0.476923\n",
      "Iteration   500, loss = 0.476878\n",
      "Iteration   600, loss = 0.476854\n",
      "Iteration   700, loss = 0.476840\n",
      "Iteration   800, loss = 0.476831\n",
      "Iteration   900, loss = 0.476826\n",
      "Iteration  1000, loss = 0.476822\n",
      "Iteration  1100, loss = 0.476820\n",
      "Iteration  1200, loss = 0.476819\n",
      "Converged at iteration 1279\n",
      " Accuracy: 85.43%\n",
      " F1 Score: 0.4076\n",
      "\n",
      "Validation loss: 0.4945827345123014 f1 score 0.40763226366001687 with data size of 46564\n"
     ]
    }
   ],
   "source": [
    "# Try with the 75% NaN removal\n",
    "\n",
    "m = X_train_data.shape[0] // 5\n",
    "X_train_over, X_val_over = X_train_data[m:], X_train_data[:m]\n",
    "Y_train_over, Y_val_over = Y_train_data[m:], Y_train_data[:m]\n",
    "\n",
    "train_losses, val_losses, f1s_datasize = over_under_fitting(\n",
    "    X_train_over, \n",
    "    X_val_over, \n",
    "    Y_train_over, \n",
    "    Y_val_over, \n",
    "    train_method = train_method, \n",
    "    evaluator = evaluator, preprocess=no_NaN_75, steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "\n",
    "N = X_train_over.shape[0]\n",
    "\n",
    "data_sizes = np.array([N / (len(train_losses) - i) for i in range(len(train_losses))])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(data_sizes, train_losses, label='Train Loss')\n",
    "plt.plot(data_sizes, val_losses, label='Validation Loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss by Data Size. > 75% NaN features removed')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c5b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "\n",
      "Max F1 score 0.40763226366001687\n",
      "Min validation loss 0.49355570493739165\n"
     ]
    }
   ],
   "source": [
    "# And the F1 score\n",
    "\n",
    "N = X_train_over.shape[0]\n",
    "\n",
    "data_sizes = np.array([N / (len(train_losses) - i) for i in range(len(train_losses))])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(data_sizes, f1s_datasize, label='F1 scores')\n",
    "\n",
    "\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel('F1')\n",
    "plt.title('F1 score evolution. > 75% NaN features removed')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Summary:\\n\")\n",
    "print(\"Max F1 score\", np.max(f1s_datasize))\n",
    "print(\"Min validation loss\", np.min(val_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a15fe1",
   "metadata": {},
   "source": [
    "It seems that our model needs more flexibility because we are not getting rid of all the data (more than 50,000 datapoints don't improve the model). So, we are underfitting. Let's try to give more freedom to the training by removing less features in the preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7a2f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocess (262508, 321) (262508,)\n",
      "After preprocess (46564, 321) (46564,)\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.463652\n",
      "Iteration   200, loss = 0.462534\n",
      "Iteration   300, loss = 0.462218\n",
      "Iteration   400, loss = 0.462075\n",
      "Iteration   500, loss = 0.461999\n",
      "Iteration   600, loss = 0.461957\n",
      "Iteration   700, loss = 0.461931\n",
      "Iteration   800, loss = 0.461915\n",
      "Iteration   900, loss = 0.461905\n",
      "Iteration  1000, loss = 0.461898\n",
      "Iteration  1100, loss = 0.461894\n",
      "Iteration  1200, loss = 0.461891\n",
      "Iteration  1300, loss = 0.461889\n",
      "Iteration  1400, loss = 0.461887\n",
      "Converged at iteration 1476\n",
      " Accuracy: 80.04%\n",
      " F1 Score: 0.3807\n",
      "\n",
      "Validation loss: 0.635037667868616 f1 score 0.3807497754455629 with data size of 13125\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.465258\n",
      "Iteration   200, loss = 0.464176\n",
      "Iteration   300, loss = 0.463876\n",
      "Iteration   400, loss = 0.463741\n",
      "Iteration   500, loss = 0.463670\n",
      "Iteration   600, loss = 0.463630\n",
      "Iteration   700, loss = 0.463606\n",
      "Iteration   800, loss = 0.463591\n",
      "Iteration   900, loss = 0.463581\n",
      "Iteration  1000, loss = 0.463574\n",
      "Iteration  1100, loss = 0.463570\n",
      "Iteration  1200, loss = 0.463567\n",
      "Iteration  1300, loss = 0.463565\n",
      "Iteration  1400, loss = 0.463563\n",
      "Converged at iteration 1483\n",
      " Accuracy: 78.30%\n",
      " F1 Score: 0.3730\n",
      "\n",
      "Validation loss: 0.6800853080425278 f1 score 0.3729963008631315 with data size of 13816\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.466055\n",
      "Iteration   200, loss = 0.465006\n",
      "Iteration   300, loss = 0.464723\n",
      "Iteration   400, loss = 0.464599\n",
      "Iteration   500, loss = 0.464534\n",
      "Iteration   600, loss = 0.464498\n",
      "Iteration   700, loss = 0.464476\n",
      "Iteration   800, loss = 0.464463\n",
      "Iteration   900, loss = 0.464454\n",
      "Iteration  1000, loss = 0.464448\n",
      "Iteration  1100, loss = 0.464444\n",
      "Iteration  1200, loss = 0.464442\n",
      "Iteration  1300, loss = 0.464440\n",
      "Iteration  1400, loss = 0.464438\n",
      "Converged at iteration 1452\n",
      " Accuracy: 80.98%\n",
      " F1 Score: 0.3852\n",
      "\n",
      "Validation loss: 0.608893116919348 f1 score 0.3851837257413059 with data size of 14583\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.467223\n",
      "Iteration   200, loss = 0.466229\n",
      "Iteration   300, loss = 0.465959\n",
      "Iteration   400, loss = 0.465839\n",
      "Iteration   500, loss = 0.465778\n",
      "Iteration   600, loss = 0.465743\n",
      "Iteration   700, loss = 0.465723\n",
      "Iteration   800, loss = 0.465710\n",
      "Iteration   900, loss = 0.465702\n",
      "Iteration  1000, loss = 0.465696\n",
      "Iteration  1100, loss = 0.465692\n",
      "Iteration  1200, loss = 0.465690\n",
      "Iteration  1300, loss = 0.465688\n",
      "Iteration  1400, loss = 0.465687\n",
      "Converged at iteration 1437\n",
      " Accuracy: 79.70%\n",
      " F1 Score: 0.3782\n",
      "\n",
      "Validation loss: 0.6426903437256177 f1 score 0.3782320545132079 with data size of 15441\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.468219\n",
      "Iteration   200, loss = 0.467274\n",
      "Iteration   300, loss = 0.467022\n",
      "Iteration   400, loss = 0.466912\n",
      "Iteration   500, loss = 0.466855\n",
      "Iteration   600, loss = 0.466823\n",
      "Iteration   700, loss = 0.466804\n",
      "Iteration   800, loss = 0.466793\n",
      "Iteration   900, loss = 0.466785\n",
      "Iteration  1000, loss = 0.466780\n",
      "Iteration  1100, loss = 0.466777\n",
      "Iteration  1200, loss = 0.466774\n",
      "Iteration  1300, loss = 0.466773\n",
      "Iteration  1400, loss = 0.466771\n",
      "Converged at iteration 1417\n",
      " Accuracy: 78.80%\n",
      " F1 Score: 0.3750\n",
      "\n",
      "Validation loss: 0.6668593361975091 f1 score 0.3749550844412501 with data size of 16406\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.468497\n",
      "Iteration   200, loss = 0.467588\n",
      "Iteration   300, loss = 0.467345\n",
      "Iteration   400, loss = 0.467238\n",
      "Iteration   500, loss = 0.467183\n",
      "Iteration   600, loss = 0.467153\n",
      "Iteration   700, loss = 0.467134\n",
      "Iteration   800, loss = 0.467122\n",
      "Iteration   900, loss = 0.467115\n",
      "Iteration  1000, loss = 0.467110\n",
      "Iteration  1100, loss = 0.467106\n",
      "Iteration  1200, loss = 0.467104\n",
      "Iteration  1300, loss = 0.467102\n",
      "Iteration  1400, loss = 0.467100\n",
      "Converged at iteration 1428\n",
      " Accuracy: 78.46%\n",
      " F1 Score: 0.3740\n",
      "\n",
      "Validation loss: 0.6767158678442432 f1 score 0.37397581823818554 with data size of 17500\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.469490\n",
      "Iteration   200, loss = 0.468591\n",
      "Iteration   300, loss = 0.468350\n",
      "Iteration   400, loss = 0.468245\n",
      "Iteration   500, loss = 0.468191\n",
      "Iteration   600, loss = 0.468161\n",
      "Iteration   700, loss = 0.468143\n",
      "Iteration   800, loss = 0.468132\n",
      "Iteration   900, loss = 0.468124\n",
      "Iteration  1000, loss = 0.468119\n",
      "Iteration  1100, loss = 0.468116\n",
      "Iteration  1200, loss = 0.468114\n",
      "Iteration  1300, loss = 0.468112\n",
      "Iteration  1400, loss = 0.468111\n",
      "Converged at iteration 1416\n",
      " Accuracy: 82.15%\n",
      " F1 Score: 0.3914\n",
      "\n",
      "Validation loss: 0.5780578121956789 f1 score 0.3913540475943049 with data size of 18750\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.469365\n",
      "Iteration   200, loss = 0.468486\n",
      "Iteration   300, loss = 0.468253\n",
      "Iteration   400, loss = 0.468155\n",
      "Iteration   500, loss = 0.468107\n",
      "Iteration   600, loss = 0.468081\n",
      "Iteration   700, loss = 0.468066\n",
      "Iteration   800, loss = 0.468056\n",
      "Iteration   900, loss = 0.468051\n",
      "Iteration  1000, loss = 0.468047\n",
      "Iteration  1100, loss = 0.468044\n",
      "Iteration  1200, loss = 0.468042\n",
      "Iteration  1300, loss = 0.468041\n",
      "Converged at iteration 1337\n",
      " Accuracy: 79.53%\n",
      " F1 Score: 0.3806\n",
      "\n",
      "Validation loss: 0.6468160062040869 f1 score 0.3806011432786277 with data size of 20192\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.470785\n",
      "Iteration   200, loss = 0.469964\n",
      "Iteration   300, loss = 0.469747\n",
      "Iteration   400, loss = 0.469653\n",
      "Iteration   500, loss = 0.469605\n",
      "Iteration   600, loss = 0.469580\n",
      "Iteration   700, loss = 0.469564\n",
      "Iteration   800, loss = 0.469555\n",
      "Iteration   900, loss = 0.469549\n",
      "Iteration  1000, loss = 0.469545\n",
      "Iteration  1100, loss = 0.469542\n",
      "Iteration  1200, loss = 0.469540\n",
      "Iteration  1300, loss = 0.469539\n",
      "Converged at iteration 1359\n",
      " Accuracy: 81.11%\n",
      " F1 Score: 0.3880\n",
      "\n",
      "Validation loss: 0.6058454391007775 f1 score 0.3879535917057513 with data size of 21875\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472446\n",
      "Iteration   200, loss = 0.471650\n",
      "Iteration   300, loss = 0.471422\n",
      "Iteration   400, loss = 0.471318\n",
      "Iteration   500, loss = 0.471265\n",
      "Iteration   600, loss = 0.471236\n",
      "Iteration   700, loss = 0.471218\n",
      "Iteration   800, loss = 0.471208\n",
      "Iteration   900, loss = 0.471201\n",
      "Iteration  1000, loss = 0.471196\n",
      "Iteration  1100, loss = 0.471193\n",
      "Iteration  1200, loss = 0.471190\n",
      "Iteration  1300, loss = 0.471189\n",
      "Converged at iteration 1394\n",
      " Accuracy: 81.19%\n",
      " F1 Score: 0.3889\n",
      "\n",
      "Validation loss: 0.6048250911897394 f1 score 0.38885038122586363 with data size of 23864\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472556\n",
      "Iteration   200, loss = 0.471756\n",
      "Iteration   300, loss = 0.471524\n",
      "Iteration   400, loss = 0.471418\n",
      "Iteration   500, loss = 0.471363\n",
      "Iteration   600, loss = 0.471333\n",
      "Iteration   700, loss = 0.471314\n",
      "Iteration   800, loss = 0.471303\n",
      "Iteration   900, loss = 0.471296\n",
      "Iteration  1000, loss = 0.471291\n",
      "Iteration  1100, loss = 0.471287\n",
      "Iteration  1200, loss = 0.471285\n",
      "Iteration  1300, loss = 0.471283\n",
      "Iteration  1400, loss = 0.471282\n",
      "Converged at iteration 1402\n",
      " Accuracy: 87.73%\n",
      " F1 Score: 0.4065\n",
      "\n",
      "Validation loss: 0.4280754855538588 f1 score 0.40645731977001276 with data size of 26250\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474923\n",
      "Iteration   200, loss = 0.474153\n",
      "Iteration   300, loss = 0.473924\n",
      "Iteration   400, loss = 0.473816\n",
      "Iteration   500, loss = 0.473757\n",
      "Iteration   600, loss = 0.473724\n",
      "Iteration   700, loss = 0.473704\n",
      "Iteration   800, loss = 0.473691\n",
      "Iteration   900, loss = 0.473683\n",
      "Iteration  1000, loss = 0.473677\n",
      "Iteration  1100, loss = 0.473673\n",
      "Iteration  1200, loss = 0.473671\n",
      "Iteration  1300, loss = 0.473669\n",
      "Iteration  1400, loss = 0.473668\n",
      "Converged at iteration 1434\n",
      " Accuracy: 90.18%\n",
      " F1 Score: 0.3773\n",
      "\n",
      "Validation loss: 0.34549484634389144 f1 score 0.37734390102455 with data size of 29167\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474285\n",
      "Iteration   200, loss = 0.473539\n",
      "Iteration   300, loss = 0.473323\n",
      "Iteration   400, loss = 0.473221\n",
      "Iteration   500, loss = 0.473167\n",
      "Iteration   600, loss = 0.473136\n",
      "Iteration   700, loss = 0.473118\n",
      "Iteration   800, loss = 0.473106\n",
      "Iteration   900, loss = 0.473098\n",
      "Iteration  1000, loss = 0.473093\n",
      "Iteration  1100, loss = 0.473090\n",
      "Iteration  1200, loss = 0.473088\n",
      "Iteration  1300, loss = 0.473086\n",
      "Converged at iteration 1393\n",
      " Accuracy: 90.68%\n",
      " F1 Score: 0.3504\n",
      "\n",
      "Validation loss: 0.3204283923668009 f1 score 0.35035566408323554 with data size of 32813\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.473375\n",
      "Iteration   200, loss = 0.472637\n",
      "Iteration   300, loss = 0.472429\n",
      "Iteration   400, loss = 0.472332\n",
      "Iteration   500, loss = 0.472282\n",
      "Iteration   600, loss = 0.472253\n",
      "Iteration   700, loss = 0.472236\n",
      "Iteration   800, loss = 0.472226\n",
      "Iteration   900, loss = 0.472219\n",
      "Iteration  1000, loss = 0.472214\n",
      "Iteration  1100, loss = 0.472211\n",
      "Iteration  1200, loss = 0.472209\n",
      "Iteration  1300, loss = 0.472208\n",
      "Converged at iteration 1363\n",
      " Accuracy: 90.83%\n",
      " F1 Score: 0.3356\n",
      "\n",
      "Validation loss: 0.31046159703683 f1 score 0.3356149260322362 with data size of 37501\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475868\n",
      "Iteration   200, loss = 0.475114\n",
      "Iteration   300, loss = 0.474902\n",
      "Iteration   400, loss = 0.474805\n",
      "Iteration   500, loss = 0.474756\n",
      "Iteration   600, loss = 0.474728\n",
      "Iteration   700, loss = 0.474712\n",
      "Iteration   800, loss = 0.474702\n",
      "Iteration   900, loss = 0.474696\n",
      "Iteration  1000, loss = 0.474692\n",
      "Iteration  1100, loss = 0.474689\n",
      "Iteration  1200, loss = 0.474688\n",
      "Iteration  1300, loss = 0.474686\n",
      "Converged at iteration 1328\n",
      " Accuracy: 91.29%\n",
      " F1 Score: 0.2943\n",
      "\n",
      "Validation loss: 0.2855130005277349 f1 score 0.294255713403335 with data size of 43751\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475313\n",
      "Iteration   200, loss = 0.474572\n",
      "Iteration   300, loss = 0.474371\n",
      "Iteration   400, loss = 0.474281\n",
      "Iteration   500, loss = 0.474235\n",
      "Iteration   600, loss = 0.474211\n",
      "Iteration   700, loss = 0.474196\n",
      "Iteration   800, loss = 0.474188\n",
      "Iteration   900, loss = 0.474183\n",
      "Iteration  1000, loss = 0.474179\n",
      "Iteration  1100, loss = 0.474177\n",
      "Iteration  1200, loss = 0.474175\n",
      "Converged at iteration 1280\n",
      " Accuracy: 91.31%\n",
      " F1 Score: 0.2924\n",
      "\n",
      "Validation loss: 0.2844561699669442 f1 score 0.2924469800322457 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475313\n",
      "Iteration   200, loss = 0.474572\n",
      "Iteration   300, loss = 0.474371\n",
      "Iteration   400, loss = 0.474281\n",
      "Iteration   500, loss = 0.474235\n",
      "Iteration   600, loss = 0.474211\n",
      "Iteration   700, loss = 0.474196\n",
      "Iteration   800, loss = 0.474188\n",
      "Iteration   900, loss = 0.474183\n",
      "Iteration  1000, loss = 0.474179\n",
      "Iteration  1100, loss = 0.474177\n",
      "Iteration  1200, loss = 0.474175\n",
      "Converged at iteration 1280\n",
      " Accuracy: 91.31%\n",
      " F1 Score: 0.2924\n",
      "\n",
      "Validation loss: 0.2844561699669442 f1 score 0.2924469800322457 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475313\n",
      "Iteration   200, loss = 0.474572\n",
      "Iteration   300, loss = 0.474371\n",
      "Iteration   400, loss = 0.474281\n",
      "Iteration   500, loss = 0.474235\n",
      "Iteration   600, loss = 0.474211\n",
      "Iteration   700, loss = 0.474196\n",
      "Iteration   800, loss = 0.474188\n",
      "Iteration   900, loss = 0.474183\n",
      "Iteration  1000, loss = 0.474179\n",
      "Iteration  1100, loss = 0.474177\n",
      "Iteration  1200, loss = 0.474175\n",
      "Converged at iteration 1280\n",
      " Accuracy: 91.31%\n",
      " F1 Score: 0.2924\n",
      "\n",
      "Validation loss: 0.2844561699669442 f1 score 0.2924469800322457 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475313\n",
      "Iteration   200, loss = 0.474572\n",
      "Iteration   300, loss = 0.474371\n",
      "Iteration   400, loss = 0.474281\n",
      "Iteration   500, loss = 0.474235\n",
      "Iteration   600, loss = 0.474211\n",
      "Iteration   700, loss = 0.474196\n",
      "Iteration   800, loss = 0.474188\n",
      "Iteration   900, loss = 0.474183\n",
      "Iteration  1000, loss = 0.474179\n",
      "Iteration  1100, loss = 0.474177\n",
      "Iteration  1200, loss = 0.474175\n",
      "Converged at iteration 1280\n",
      " Accuracy: 91.31%\n",
      " F1 Score: 0.2924\n",
      "\n",
      "Validation loss: 0.2844561699669442 f1 score 0.2924469800322457 with data size of 46564\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.475313\n",
      "Iteration   200, loss = 0.474572\n",
      "Iteration   300, loss = 0.474371\n",
      "Iteration   400, loss = 0.474281\n",
      "Iteration   500, loss = 0.474235\n",
      "Iteration   600, loss = 0.474211\n",
      "Iteration   700, loss = 0.474196\n",
      "Iteration   800, loss = 0.474188\n",
      "Iteration   900, loss = 0.474183\n",
      "Iteration  1000, loss = 0.474179\n",
      "Iteration  1100, loss = 0.474177\n",
      "Iteration  1200, loss = 0.474175\n",
      "Converged at iteration 1280\n",
      " Accuracy: 91.31%\n",
      " F1 Score: 0.2924\n",
      "\n",
      "Validation loss: 0.2844561699669442 f1 score 0.2924469800322457 with data size of 46564\n"
     ]
    }
   ],
   "source": [
    "# Try without NaN removal\n",
    "\n",
    "\n",
    "train_losses, val_losses, f1s_datasize = over_under_fitting(\n",
    "    X_train_over, \n",
    "    X_val_over, \n",
    "    Y_train_over, \n",
    "    Y_val_over, \n",
    "    train_method = train_method, \n",
    "    evaluator = evaluator, preprocess=NaN_features, steps = 20) # Remember NaN_features() is just standardizing and balancing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd38e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "\n",
    "N = X_train_over.shape[0]\n",
    "\n",
    "data_sizes = np.array([N / (len(train_losses) - i) for i in range(len(train_losses))])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(data_sizes, train_losses, label='Train Loss')\n",
    "plt.plot(data_sizes, val_losses, label='Validation Loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss by Data Size. No NaN features removed')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "380c5efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "\n",
      "Max F1 score 0.40645731977001276\n",
      "Min validation loss 0.2844561699669442\n"
     ]
    }
   ],
   "source": [
    "# And the F1 score\n",
    "\n",
    "N = X_train_over.shape[0]\n",
    "\n",
    "data_sizes = np.array([N / (len(train_losses) - i) for i in range(len(train_losses))])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(data_sizes, f1s_datasize, label='F1 scores')\n",
    "\n",
    "\n",
    "plt.xlabel('Data Size')\n",
    "plt.ylabel('F1')\n",
    "plt.title('F1 score evolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Summary:\\n\")\n",
    "print(\"Max F1 score\", np.max(f1s_datasize))\n",
    "print(\"Min validation loss\", np.min(val_losses))"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08029fc",
   "metadata": {},
   "source": [
    "# Alpha choice\n",
    "Now we will use the previous section to compare the effect of the alpha threshold for the probability."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 67,
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   "id": "6ca4f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning batch 1 out of 5\n",
<<<<<<< HEAD
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 8.50%\n",
      " F1 Score: 0.1567\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 8.50%\n",
      " F1 Score: 0.1567\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 57.00%\n",
      " F1 Score: 0.2712\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 13.25%\n",
      " F1 Score: 0.1614\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 71.60%\n",
      " F1 Score: 0.3395\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 18.60%\n",
      " F1 Score: 0.1694\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 78.40%\n",
      " F1 Score: 0.3703\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 22.90%\n",
      " F1 Score: 0.1763\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 82.55%\n",
      " F1 Score: 0.3866\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 26.80%\n",
      " F1 Score: 0.1839\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 85.10%\n",
      " F1 Score: 0.4064\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 30.75%\n",
      " F1 Score: 0.1924\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 87.25%\n",
      " F1 Score: 0.4028\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 34.80%\n",
      " F1 Score: 0.2020\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n",
      "Iteration  1300, loss = 0.217529\n",
      "Iteration  1400, loss = 0.217525\n",
      "Iteration  1500, loss = 0.217521\n",
      "Iteration  1600, loss = 0.217519\n",
      "Iteration  1700, loss = 0.217517\n",
      "Iteration  1800, loss = 0.217515\n",
      "Converged at iteration 1873\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.216906\n",
      "Iteration   200, loss = 0.214285\n",
      "Iteration   300, loss = 0.213749\n",
      "Iteration   400, loss = 0.213540\n",
      "Iteration   500, loss = 0.213429\n",
      "Iteration   600, loss = 0.213362\n",
      "Iteration   700, loss = 0.213318\n",
      "Iteration   800, loss = 0.213289\n",
      "Iteration   900, loss = 0.213268\n",
      "Iteration  1000, loss = 0.213254\n",
      "Iteration  1100, loss = 0.213243\n",
      "Iteration  1200, loss = 0.213236\n",
      "Iteration  1300, loss = 0.213231\n",
      "Iteration  1400, loss = 0.213227\n",
      "Iteration  1500, loss = 0.213224\n",
      "Iteration  1600, loss = 0.213221\n",
      "Iteration  1700, loss = 0.213220\n",
      "Iteration  1800, loss = 0.213218\n",
      "Converged at iteration 1832\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218420\n",
      "Iteration   200, loss = 0.215899\n",
      "Iteration   300, loss = 0.215423\n",
      "Iteration   400, loss = 0.215247\n",
      "Iteration   500, loss = 0.215158\n",
      "Iteration   600, loss = 0.215105\n",
      "Iteration   700, loss = 0.215071\n",
      "Iteration   800, loss = 0.215048\n",
      "Iteration   900, loss = 0.215033\n",
      "Iteration  1000, loss = 0.215022\n",
      "Iteration  1100, loss = 0.215014\n",
      "Iteration  1200, loss = 0.215008\n",
      "Iteration  1300, loss = 0.215004\n",
      "Iteration  1400, loss = 0.215002\n",
      "Iteration  1500, loss = 0.214999\n",
      "Iteration  1600, loss = 0.214998\n",
      "Iteration  1700, loss = 0.214997\n",
      "Converged at iteration 1710\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.222193\n",
      "Iteration   200, loss = 0.219767\n",
      "Iteration   300, loss = 0.219275\n",
      "Iteration   400, loss = 0.219076\n",
      "Iteration   500, loss = 0.218966\n",
      "Iteration   600, loss = 0.218897\n",
      "Iteration   700, loss = 0.218850\n",
      "Iteration   800, loss = 0.218817\n",
      "Iteration   900, loss = 0.218794\n",
      "Iteration  1000, loss = 0.218778\n",
      "Iteration  1100, loss = 0.218766\n",
      "Iteration  1200, loss = 0.218757\n",
      "Iteration  1300, loss = 0.218750\n",
      "Iteration  1400, loss = 0.218745\n",
      "Iteration  1500, loss = 0.218742\n",
      "Iteration  1600, loss = 0.218739\n",
      "Iteration  1700, loss = 0.218737\n",
      "Iteration  1800, loss = 0.218735\n",
      "Iteration  1900, loss = 0.218734\n",
      "Converged at iteration 1910\n",
      " Accuracy: 88.35%\n",
      " F1 Score: 0.3753\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.218887\n",
      "Iteration   200, loss = 0.216287\n",
      "Iteration   300, loss = 0.215803\n",
      "Iteration   400, loss = 0.215630\n",
      "Iteration   500, loss = 0.215543\n",
      "Iteration   600, loss = 0.215492\n",
      "Iteration   700, loss = 0.215458\n",
      "Iteration   800, loss = 0.215434\n",
      "Iteration   900, loss = 0.215418\n",
      "Iteration  1000, loss = 0.215406\n",
      "Iteration  1100, loss = 0.215397\n",
      "Iteration  1200, loss = 0.215391\n",
      "Iteration  1300, loss = 0.215386\n",
      "Iteration  1400, loss = 0.215382\n",
      "Iteration  1500, loss = 0.215380\n",
      "Iteration  1600, loss = 0.215378\n",
      "Iteration  1700, loss = 0.215376\n",
      "Iteration  1800, loss = 0.215375\n",
      "Converged at iteration 1810\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.382847\n",
      "Iteration   200, loss = 0.377677\n",
      "Iteration   300, loss = 0.375503\n",
      "Iteration   400, loss = 0.374279\n",
      "Iteration   500, loss = 0.373522\n",
      "Iteration   600, loss = 0.373031\n",
      "Iteration   700, loss = 0.372701\n",
      "Iteration   800, loss = 0.372475\n",
      "Iteration   900, loss = 0.372318\n",
      "Iteration  1000, loss = 0.372206\n",
      "Iteration  1100, loss = 0.372126\n",
      "Iteration  1200, loss = 0.372068\n",
      "Iteration  1300, loss = 0.372026\n",
      "Iteration  1400, loss = 0.371995\n",
      "Iteration  1500, loss = 0.371972\n",
      "Iteration  1600, loss = 0.371955\n",
      "Iteration  1700, loss = 0.371942\n",
      "Iteration  1800, loss = 0.371933\n",
      "Iteration  1900, loss = 0.371926\n",
      "Iteration  2000, loss = 0.371920\n",
      "Iteration  2100, loss = 0.371916\n",
      "Iteration  2200, loss = 0.371913\n",
      "Iteration  2300, loss = 0.371911\n",
      "Iteration  2400, loss = 0.371909\n",
      "Iteration  2500, loss = 0.371907\n",
      "Converged at iteration 2581\n",
      " Accuracy: 91.40%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 2 out of 5\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.364363\n",
      "Iteration   200, loss = 0.357849\n",
      "Iteration   300, loss = 0.355491\n",
      "Iteration   400, loss = 0.354365\n",
      "Iteration   500, loss = 0.353749\n",
      "Iteration   600, loss = 0.353383\n",
      "Iteration   700, loss = 0.353152\n",
      "Iteration   800, loss = 0.353000\n",
      "Iteration   900, loss = 0.352897\n",
      "Iteration  1000, loss = 0.352825\n",
      "Iteration  1100, loss = 0.352774\n",
      "Iteration  1200, loss = 0.352737\n",
      "Iteration  1300, loss = 0.352710\n",
      "Iteration  1400, loss = 0.352691\n",
      "Iteration  1500, loss = 0.352676\n",
      "Iteration  1600, loss = 0.352665\n",
      "Iteration  1700, loss = 0.352656\n",
      "Iteration  1800, loss = 0.352650\n",
      "Iteration  1900, loss = 0.352645\n",
      "Iteration  2000, loss = 0.352641\n",
      "Iteration  2100, loss = 0.352638\n",
      "Iteration  2200, loss = 0.352636\n",
      "Iteration  2300, loss = 0.352634\n",
      "Iteration  2400, loss = 0.352633\n",
      "Converged at iteration 2462\n",
      " Accuracy: 90.65%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 3 out of 5\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.367902\n",
      "Iteration   200, loss = 0.363557\n",
      "Iteration   300, loss = 0.362158\n",
      "Iteration   400, loss = 0.361496\n",
      "Iteration   500, loss = 0.361131\n",
      "Iteration   600, loss = 0.360912\n",
      "Iteration   700, loss = 0.360772\n",
      "Iteration   800, loss = 0.360679\n",
      "Iteration   900, loss = 0.360615\n",
      "Iteration  1000, loss = 0.360570\n",
      "Iteration  1100, loss = 0.360538\n",
      "Iteration  1200, loss = 0.360515\n",
      "Iteration  1300, loss = 0.360497\n",
      "Iteration  1400, loss = 0.360485\n",
      "Iteration  1500, loss = 0.360475\n",
      "Iteration  1600, loss = 0.360468\n",
      "Iteration  1700, loss = 0.360463\n",
      "Iteration  1800, loss = 0.360459\n",
      "Iteration  1900, loss = 0.360456\n",
      "Iteration  2000, loss = 0.360454\n",
      "Iteration  2100, loss = 0.360452\n",
      "Iteration  2200, loss = 0.360451\n",
      "Converged at iteration 2257\n",
      " Accuracy: 91.15%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 4 out of 5\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.373653\n",
      "Iteration   200, loss = 0.367876\n",
      "Iteration   300, loss = 0.365844\n",
      "Iteration   400, loss = 0.364835\n",
      "Iteration   500, loss = 0.364256\n",
      "Iteration   600, loss = 0.363894\n",
      "Iteration   700, loss = 0.363655\n",
      "Iteration   800, loss = 0.363492\n",
      "Iteration   900, loss = 0.363378\n",
      "Iteration  1000, loss = 0.363295\n",
      "Iteration  1100, loss = 0.363236\n",
      "Iteration  1200, loss = 0.363192\n",
      "Iteration  1300, loss = 0.363160\n",
      "Iteration  1400, loss = 0.363135\n",
      "Iteration  1500, loss = 0.363117\n",
      "Iteration  1600, loss = 0.363104\n",
      "Iteration  1700, loss = 0.363093\n",
      "Iteration  1800, loss = 0.363085\n",
      "Iteration  1900, loss = 0.363079\n",
      "Iteration  2000, loss = 0.363075\n",
      "Iteration  2100, loss = 0.363071\n",
      "Iteration  2200, loss = 0.363068\n",
      "Iteration  2300, loss = 0.363066\n",
      "Iteration  2400, loss = 0.363065\n",
      "Iteration  2500, loss = 0.363063\n",
      "Converged at iteration 2536\n",
      " Accuracy: 38.20%\n",
      " F1 Score: 0.2097\n",
      "Start cleaning batch 5 out of 5\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.387809\n",
      "Iteration   200, loss = 0.382998\n",
      "Iteration   300, loss = 0.381450\n",
      "Iteration   400, loss = 0.380730\n",
      "Iteration   500, loss = 0.380329\n",
      "Iteration   600, loss = 0.380079\n",
      "Iteration   700, loss = 0.379912\n",
      "Iteration   800, loss = 0.379794\n",
      "Iteration   900, loss = 0.379710\n",
      "Iteration  1000, loss = 0.379648\n",
      "Iteration  1100, loss = 0.379602\n",
      "Iteration  1200, loss = 0.379567\n",
      "Iteration  1300, loss = 0.379540\n",
      "Iteration  1400, loss = 0.379520\n",
      "Iteration  1500, loss = 0.379505\n",
      "Iteration  1600, loss = 0.379493\n",
      "Iteration  1700, loss = 0.379484\n",
      "Iteration  1800, loss = 0.379477\n",
      "Iteration  1900, loss = 0.379472\n",
      "Iteration  2000, loss = 0.379468\n",
      "Iteration  2100, loss = 0.379465\n",
      "Iteration  2200, loss = 0.379462\n",
      "Iteration  2300, loss = 0.379460\n",
      "Iteration  2400, loss = 0.379459\n",
      "Iteration  2500, loss = 0.379457\n",
      "Converged at iteration 2521\n",
      " Accuracy: 91.70%\n",
      " F1 Score: 0.0000\n",
      "Start cleaning batch 1 out of 5\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.221028\n",
      "Iteration   200, loss = 0.218579\n",
      "Iteration   300, loss = 0.218082\n",
      "Iteration   400, loss = 0.217874\n",
      "Iteration   500, loss = 0.217757\n",
      "Iteration   600, loss = 0.217683\n",
      "Iteration   700, loss = 0.217633\n",
      "Iteration   800, loss = 0.217598\n",
      "Iteration   900, loss = 0.217574\n",
      "Iteration  1000, loss = 0.217557\n",
      "Iteration  1100, loss = 0.217545\n",
      "Iteration  1200, loss = 0.217536\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m acc_scores_bal = np.array([])\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m np.arange(\u001b[32m0\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m0.05\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     acc_no_bal, f1_no_bal = \u001b[43mkfold_logistic_ridge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_balanced_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     acc_bal, f1_bal = kfold_logistic_ridge(X_train_data, Y_train_data, balanced_data, k=\u001b[32m5\u001b[39m, gamma=\u001b[32m0.5\u001b[39m, lambda_=\u001b[32m1e-3\u001b[39m, alpha = alpha)\n\u001b[32m      9\u001b[39m     f1_scores_no_bal = np.append(f1_scores_no_bal, f1_no_bal)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janfo\\OneDrive\\Desktop\\universitat\\EPFL\\Machine Learning\\ML_proj1\\project1\\Implemented_functions.py:140\u001b[39m, in \u001b[36mkfold_logistic_ridge\u001b[39m\u001b[34m(X, y, process_data, k, gamma, lambda_, alpha, threshold, random_state)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCleaning of batch\u001b[39m\u001b[33m\"\u001b[39m, current_batch, \u001b[33m\"\u001b[39m\u001b[33mdone. Stating the model training.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# training the model and computing error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m loss, w = \u001b[43mlogistic_regression_penalized_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m acc, f1 = evaluate_logistic_model(y_val, X_val, w, threshold=alpha)\n\u001b[32m    142\u001b[39m accuracies.append(acc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janfo\\OneDrive\\Desktop\\universitat\\EPFL\\Machine Learning\\ML_proj1\\project1\\Implemented_functions.py:74\u001b[39m, in \u001b[36mlogistic_regression_penalized_gradient_descent\u001b[39m\u001b[34m(y, x, max_iter, gamma, lambda_, threshold)\u001b[39m\n\u001b[32m     71\u001b[39m w = np.zeros(tx.shape[\u001b[32m1\u001b[39m])\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     loss = \u001b[43mlogistic_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m + lambda_ * w.T\u001b[38;5;129m@w\u001b[39m\n\u001b[32m     75\u001b[39m     grad = compute_gradient_logistic(y, tx, w) + \u001b[32m2\u001b[39m* lambda_ * w  \n\u001b[32m     76\u001b[39m     w = w - gamma * grad\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janfo\\OneDrive\\Desktop\\universitat\\EPFL\\Machine Learning\\ML_proj1\\project1\\Implemented_functions.py:54\u001b[39m, in \u001b[36mlogistic_loss\u001b[39m\u001b[34m(y, tx, w)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Stable logistic loss computation.\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m eps = \u001b[32m1e-15\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m pred = \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m pred = np.clip(pred, eps, \u001b[32m1\u001b[39m - eps)\n\u001b[32m     56\u001b[39m loss = -np.mean(y * np.log(pred) + (\u001b[32m1\u001b[39m - y) * np.log(\u001b[32m1\u001b[39m - pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janfo\\OneDrive\\Desktop\\universitat\\EPFL\\Machine Learning\\ML_proj1\\project1\\Implemented_functions.py:7\u001b[39m, in \u001b[36msigmoid\u001b[39m\u001b[34m(z)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_accuracy, f1_score\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Logistic Regression Functions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msigmoid\u001b[39m(z):\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCompute the sigmoid function in a numerically stable way.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m     z = np.clip(z, -\u001b[32m500\u001b[39m, \u001b[32m500\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
=======
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 67.97%\n",
      " F1 Score: 0.3276\n",
      "     from now, f1 score: 0.3275856553312642 accuracy: 0.679720237097536\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 67.73%\n",
      " F1 Score: 0.3266\n",
      "     from now, f1 score: 0.32662405799866423 accuracy: 0.6773126914227376\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 67.61%\n",
      " F1 Score: 0.3221\n",
      "     from now, f1 score: 0.32207659683025575 accuracy: 0.6760632056927789\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 67.83%\n",
      " F1 Score: 0.3258\n",
      "     from now, f1 score: 0.3258398262868818 accuracy: 0.6783031374281927\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 67.74%\n",
      " F1 Score: 0.3188\n",
      "     from now, f1 score: 0.31875663674099786 accuracy: 0.6774041172078565\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 68.15%\n",
      " F1 Score: 0.3290\n",
      "     from now, f1 score: 0.3289570827849642 accuracy: 0.6814573270147958\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 67.84%\n",
      " F1 Score: 0.3267\n",
      "     from now, f1 score: 0.3266868719093951 accuracy: 0.6784098008441648\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 67.72%\n",
      " F1 Score: 0.3231\n",
      "     from now, f1 score: 0.32306512430497825 accuracy: 0.6772060280067655\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 67.99%\n",
      " F1 Score: 0.3268\n",
      "     from now, f1 score: 0.3268183274591474 accuracy: 0.6798573757752144\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 67.89%\n",
      " F1 Score: 0.3195\n",
      "     from now, f1 score: 0.31948077109367395 accuracy: 0.6788669297697594\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 71.40%\n",
      " F1 Score: 0.3454\n",
      "     from now, f1 score: 0.34544566885200134 accuracy: 0.7139896688862816\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 71.22%\n",
      " F1 Score: 0.3438\n",
      "     from now, f1 score: 0.3438357591968594 accuracy: 0.7121763908147561\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 71.12%\n",
      " F1 Score: 0.3395\n",
      "     from now, f1 score: 0.3394556163524201 accuracy: 0.7112011824401542\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 71.16%\n",
      " F1 Score: 0.3414\n",
      "     from now, f1 score: 0.34138363028953195 accuracy: 0.7116125984731894\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 71.26%\n",
      " F1 Score: 0.3355\n",
      "     from now, f1 score: 0.33552932887088216 accuracy: 0.7126030444786444\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 71.58%\n",
      " F1 Score: 0.3470\n",
      "     from now, f1 score: 0.3470102226578907 accuracy: 0.7157877093269538\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 71.38%\n",
      " F1 Score: 0.3448\n",
      "     from now, f1 score: 0.3447650280849872 accuracy: 0.7138220549468969\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 71.32%\n",
      " F1 Score: 0.3411\n",
      "     from now, f1 score: 0.3410689908642231 accuracy: 0.713151599189358\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 71.29%\n",
      " F1 Score: 0.3423\n",
      "     from now, f1 score: 0.3422807078781106 accuracy: 0.7128773218340012\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 71.41%\n",
      " F1 Score: 0.3362\n",
      "     from now, f1 score: 0.33616358876388563 accuracy: 0.7140810946714005\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 74.62%\n",
      " F1 Score: 0.3628\n",
      "     from now, f1 score: 0.36278785096779087 accuracy: 0.7461715452481448\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 74.60%\n",
      " F1 Score: 0.3628\n",
      "     from now, f1 score: 0.3627604664500092 accuracy: 0.7460344065704664\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 74.38%\n",
      " F1 Score: 0.3561\n",
      "     from now, f1 score: 0.35608149509803877 accuracy: 0.7437944748350527\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 74.34%\n",
      " F1 Score: 0.3583\n",
      "     from now, f1 score: 0.3583022174807586 accuracy: 0.7433678211711643\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 74.44%\n",
      " F1 Score: 0.3520\n",
      "     from now, f1 score: 0.35195487559882516 accuracy: 0.7444039800691788\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 74.67%\n",
      " F1 Score: 0.3626\n",
      "     from now, f1 score: 0.36256278516928 accuracy: 0.746674387066299\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 74.66%\n",
      " F1 Score: 0.3618\n",
      "     from now, f1 score: 0.36184336748397955 accuracy: 0.74658296128118\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 74.57%\n",
      " F1 Score: 0.3576\n",
      "     from now, f1 score: 0.35761844282800254 accuracy: 0.7456687034299907\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 74.48%\n",
      " F1 Score: 0.3591\n",
      "     from now, f1 score: 0.3590999540792893 accuracy: 0.7448001584713608\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 74.57%\n",
      " F1 Score: 0.3529\n",
      "     from now, f1 score: 0.35292749127568795 accuracy: 0.7457144163225502\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 77.45%\n",
      " F1 Score: 0.3752\n",
      "     from now, f1 score: 0.37519523829625523 accuracy: 0.7744678257424535\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 77.47%\n",
      " F1 Score: 0.3777\n",
      "     from now, f1 score: 0.3777459809780317 accuracy: 0.7746963902052509\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 77.60%\n",
      " F1 Score: 0.3742\n",
      "     from now, f1 score: 0.3741540033201375 accuracy: 0.7759611135660628\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 77.39%\n",
      " F1 Score: 0.3760\n",
      "     from now, f1 score: 0.37599360726752706 accuracy: 0.77391927103174\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 77.41%\n",
      " F1 Score: 0.3683\n",
      "     from now, f1 score: 0.36832239925023386 accuracy: 0.7740564097094184\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 77.59%\n",
      " F1 Score: 0.3772\n",
      "     from now, f1 score: 0.3771970691626779 accuracy: 0.7759306383043565\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 77.60%\n",
      " F1 Score: 0.3785\n",
      "     from now, f1 score: 0.37850408016574316 accuracy: 0.7760220640894754\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 77.70%\n",
      " F1 Score: 0.3750\n",
      "     from now, f1 score: 0.37504270584215876 accuracy: 0.7770125100949304\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 77.53%\n",
      " F1 Score: 0.3774\n",
      "     from now, f1 score: 0.37742221471693294 accuracy: 0.7752906578085239\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 77.40%\n",
      " F1 Score: 0.3680\n",
      "     from now, f1 score: 0.3679679509035114 accuracy: 0.7740259344477121\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 80.20%\n",
      " F1 Score: 0.3896\n",
      "     from now, f1 score: 0.3896067283747588 accuracy: 0.802047937586664\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 80.31%\n",
      " F1 Score: 0.3915\n",
      "     from now, f1 score: 0.3915234283023306 accuracy: 0.8031145717463849\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 80.43%\n",
      " F1 Score: 0.3889\n",
      "     from now, f1 score: 0.38888624577762937 accuracy: 0.8042726316912246\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 80.16%\n",
      " F1 Score: 0.3906\n",
      "     from now, f1 score: 0.39060233069686856 accuracy: 0.8015908086610694\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 80.15%\n",
      " F1 Score: 0.3830\n",
      "     from now, f1 score: 0.38304924242424204 accuracy: 0.801453669983391\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 80.24%\n",
      " F1 Score: 0.3892\n",
      "     from now, f1 score: 0.38918715267966425 accuracy: 0.8023679278345803\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 80.40%\n",
      " F1 Score: 0.3934\n",
      "     from now, f1 score: 0.3933977835416172 accuracy: 0.8039983543358679\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 80.46%\n",
      " F1 Score: 0.3902\n",
      "     from now, f1 score: 0.3902415826517021 accuracy: 0.8046230972008472\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 80.15%\n",
      " F1 Score: 0.3889\n",
      "     from now, f1 score: 0.3889097391630696 accuracy: 0.8015146205068036\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 80.17%\n",
      " F1 Score: 0.3828\n",
      "     from now, f1 score: 0.38283546704599297 accuracy: 0.8016669968153352\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 82.77%\n",
      " F1 Score: 0.4014\n",
      "     from now, f1 score: 0.40137675403759554 accuracy: 0.8277385832050833\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 82.88%\n",
      " F1 Score: 0.4015\n",
      "     from now, f1 score: 0.40149174214171507 accuracy: 0.8288204549956573\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 83.02%\n",
      " F1 Score: 0.4024\n",
      "     from now, f1 score: 0.40238146320532037 accuracy: 0.8302223170341475\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 82.69%\n",
      " F1 Score: 0.4006\n",
      "     from now, f1 score: 0.4006332453825853 accuracy: 0.826930988769866\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 82.67%\n",
      " F1 Score: 0.3922\n",
      "     from now, f1 score: 0.39217572550905844 accuracy: 0.8267024243070688\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 82.82%\n",
      " F1 Score: 0.4027\n",
      "     from now, f1 score: 0.402691675939172 accuracy: 0.8282261873923842\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 82.94%\n",
      " F1 Score: 0.4030\n",
      "     from now, f1 score: 0.40298666666666627 accuracy: 0.8294299602297834\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 83.08%\n",
      " F1 Score: 0.4037\n",
      "     from now, f1 score: 0.4037150373114292 accuracy: 0.830755634114008\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 82.76%\n",
      " F1 Score: 0.4015\n",
      "     from now, f1 score: 0.4015023275497245 accuracy: 0.8276014445274049\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 82.73%\n",
      " F1 Score: 0.3937\n",
      "     from now, f1 score: 0.3936864633493843 accuracy: 0.8273271671720481\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 85.18%\n",
      " F1 Score: 0.4084\n",
      "     from now, f1 score: 0.40839160839160793 accuracy: 0.8517530894296554\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 85.29%\n",
      " F1 Score: 0.4086\n",
      "     from now, f1 score: 0.4086232239098476 accuracy: 0.8528654364819358\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 85.32%\n",
      " F1 Score: 0.4096\n",
      "     from now, f1 score: 0.40958685791344807 accuracy: 0.8532311396224115\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 85.05%\n",
      " F1 Score: 0.4083\n",
      "     from now, f1 score: 0.40834791000663445 accuracy: 0.8505340789614031\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 85.12%\n",
      " F1 Score: 0.4008\n",
      "     from now, f1 score: 0.40083430464388636 accuracy: 0.8511740594572356\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 85.18%\n",
      " F1 Score: 0.4087\n",
      "     from now, f1 score: 0.4087316064696578 accuracy: 0.8518292775839212\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 85.28%\n",
      " F1 Score: 0.4087\n",
      "     from now, f1 score: 0.4087180115097338 accuracy: 0.8528349612202295\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 85.36%\n",
      " F1 Score: 0.4107\n",
      "     from now, f1 score: 0.4106748466257664 accuracy: 0.8536273180245936\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 85.08%\n",
      " F1 Score: 0.4104\n",
      "     from now, f1 score: 0.41035832580547976 accuracy: 0.8508083563167599\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 84.97%\n",
      " F1 Score: 0.3980\n",
      "     from now, f1 score: 0.39799780246612093 accuracy: 0.8497264845261858\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 87.37%\n",
      " F1 Score: 0.4073\n",
      "     from now, f1 score: 0.4072644072644067 accuracy: 0.8736800402273455\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 87.43%\n",
      " F1 Score: 0.4038\n",
      "     from now, f1 score: 0.4037572254335255 accuracy: 0.8742590701997653\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 87.56%\n",
      " F1 Score: 0.4131\n",
      "     from now, f1 score: 0.41308881697231165 accuracy: 0.8756456946074025\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 87.10%\n",
      " F1 Score: 0.4048\n",
      "     from now, f1 score: 0.4048070841239717 accuracy: 0.8709525043046307\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 87.35%\n",
      " F1 Score: 0.4028\n",
      "     from now, f1 score: 0.40282075268043416 accuracy: 0.8735429015496671\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 87.33%\n",
      " F1 Score: 0.4072\n",
      "     from now, f1 score: 0.40715660417706134 accuracy: 0.8732686241943103\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 87.34%\n",
      " F1 Score: 0.4021\n",
      "     from now, f1 score: 0.4020722406101593 accuracy: 0.8733752876102824\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 87.52%\n",
      " F1 Score: 0.4136\n",
      "     from now, f1 score: 0.4136054421768703 accuracy: 0.8752190409435141\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 87.10%\n",
      " F1 Score: 0.4066\n",
      "     from now, f1 score: 0.40664656804318816 accuracy: 0.8710439300897497\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 87.29%\n",
      " F1 Score: 0.4025\n",
      "     from now, f1 score: 0.40254904768724 accuracy: 0.8728572081612751\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 89.12%\n",
      " F1 Score: 0.3887\n",
      "     from now, f1 score: 0.38870346598202776 accuracy: 0.8911576028159142\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 89.13%\n",
      " F1 Score: 0.3793\n",
      "     from now, f1 score: 0.37925332869201933 accuracy: 0.8913099791244458\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 89.38%\n",
      " F1 Score: 0.3982\n",
      "     from now, f1 score: 0.39823925427239726 accuracy: 0.8937632376918037\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 88.84%\n",
      " F1 Score: 0.3835\n",
      "     from now, f1 score: 0.3835408953214401 accuracy: 0.8883691163697868\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 89.09%\n",
      " F1 Score: 0.3808\n",
      "     from now, f1 score: 0.3808041504539554 accuracy: 0.8908833254605574\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 89.12%\n",
      " F1 Score: 0.3915\n",
      "     from now, f1 score: 0.39151184591784505 accuracy: 0.8912033157084737\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 89.18%\n",
      " F1 Score: 0.3849\n",
      "     from now, f1 score: 0.3848553110379479 accuracy: 0.8918128209425998\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 89.36%\n",
      " F1 Score: 0.4007\n",
      "     from now, f1 score: 0.40065230452321643 accuracy: 0.893595623752419\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 88.82%\n",
      " F1 Score: 0.3879\n",
      "     from now, f1 score: 0.3878878878878873 accuracy: 0.888186264799549\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 89.09%\n",
      " F1 Score: 0.3831\n",
      "     from now, f1 score: 0.38311072813442437 accuracy: 0.8909138007222637\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480217\n",
      "Iteration   200, loss = 0.479708\n",
      "Iteration   300, loss = 0.479593\n",
      "Iteration   400, loss = 0.479547\n",
      "Iteration   500, loss = 0.479526\n",
      "Iteration   600, loss = 0.479515\n",
      "Iteration   700, loss = 0.479509\n",
      "Iteration   800, loss = 0.479505\n",
      "Iteration   900, loss = 0.479503\n",
      "Iteration  1000, loss = 0.479501\n",
      "Converged at iteration 1096\n",
      " Accuracy: 90.39%\n",
      " F1 Score: 0.3387\n",
      "     from now, f1 score: 0.3386809269162206 accuracy: 0.9038962622091518\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480586\n",
      "Iteration   200, loss = 0.480027\n",
      "Iteration   300, loss = 0.479884\n",
      "Iteration   400, loss = 0.479827\n",
      "Iteration   500, loss = 0.479800\n",
      "Iteration   600, loss = 0.479786\n",
      "Iteration   700, loss = 0.479778\n",
      "Iteration   800, loss = 0.479773\n",
      "Iteration   900, loss = 0.479770\n",
      "Iteration  1000, loss = 0.479768\n",
      "Iteration  1100, loss = 0.479767\n",
      "Converged at iteration 1194\n",
      " Accuracy: 90.42%\n",
      " F1 Score: 0.3264\n",
      "     from now, f1 score: 0.326368798885674 accuracy: 0.9042010148262148\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.480763\n",
      "Iteration   200, loss = 0.480175\n",
      "Iteration   300, loss = 0.480024\n",
      "Iteration   400, loss = 0.479962\n",
      "Iteration   500, loss = 0.479934\n",
      "Iteration   600, loss = 0.479920\n",
      "Iteration   700, loss = 0.479912\n",
      "Iteration   800, loss = 0.479908\n",
      "Iteration   900, loss = 0.479905\n",
      "Iteration  1000, loss = 0.479904\n",
      "Converged at iteration 1095\n",
      " Accuracy: 90.74%\n",
      " F1 Score: 0.3481\n",
      "     from now, f1 score: 0.34805918936307045 accuracy: 0.9073552044128179\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.474108\n",
      "Iteration   200, loss = 0.473511\n",
      "Iteration   300, loss = 0.473366\n",
      "Iteration   400, loss = 0.473307\n",
      "Iteration   500, loss = 0.473280\n",
      "Iteration   600, loss = 0.473267\n",
      "Iteration   700, loss = 0.473259\n",
      "Iteration   800, loss = 0.473255\n",
      "Iteration   900, loss = 0.473252\n",
      "Iteration  1000, loss = 0.473250\n",
      "Iteration  1100, loss = 0.473248\n",
      "Converged at iteration 1141\n",
      " Accuracy: 90.11%\n",
      " F1 Score: 0.3310\n",
      "     from now, f1 score: 0.3309634209170526 accuracy: 0.9010620628704649\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 178\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.477520\n",
      "Iteration   200, loss = 0.477025\n",
      "Iteration   300, loss = 0.476900\n",
      "Iteration   400, loss = 0.476846\n",
      "Iteration   500, loss = 0.476819\n",
      "Iteration   600, loss = 0.476805\n",
      "Iteration   700, loss = 0.476797\n",
      "Iteration   800, loss = 0.476791\n",
      "Iteration   900, loss = 0.476788\n",
      "Iteration  1000, loss = 0.476786\n",
      "Iteration  1100, loss = 0.476784\n",
      "Converged at iteration 1183\n",
      " Accuracy: 90.50%\n",
      " F1 Score: 0.3341\n",
      "     from now, f1 score: 0.3341166417432168 accuracy: 0.905008609261432\n",
      "Start cleaning batch 1 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 1 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479010\n",
      "Iteration   200, loss = 0.478374\n",
      "Iteration   300, loss = 0.478230\n",
      "Iteration   400, loss = 0.478174\n",
      "Iteration   500, loss = 0.478148\n",
      "Iteration   600, loss = 0.478135\n",
      "Iteration   700, loss = 0.478127\n",
      "Iteration   800, loss = 0.478123\n",
      "Iteration   900, loss = 0.478120\n",
      "Iteration  1000, loss = 0.478118\n",
      "Iteration  1100, loss = 0.478116\n",
      "Converged at iteration 1145\n",
      " Accuracy: 90.37%\n",
      " F1 Score: 0.3415\n",
      "     from now, f1 score: 0.34152948530943905 accuracy: 0.9036981730080607\n",
      "Start cleaning batch 2 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 2 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479331\n",
      "Iteration   200, loss = 0.478630\n",
      "Iteration   300, loss = 0.478455\n",
      "Iteration   400, loss = 0.478386\n",
      "Iteration   500, loss = 0.478355\n",
      "Iteration   600, loss = 0.478339\n",
      "Iteration   700, loss = 0.478330\n",
      "Iteration   800, loss = 0.478325\n",
      "Iteration   900, loss = 0.478322\n",
      "Iteration  1000, loss = 0.478319\n",
      "Iteration  1100, loss = 0.478318\n",
      "Converged at iteration 1183\n",
      " Accuracy: 90.41%\n",
      " F1 Score: 0.3320\n",
      "     from now, f1 score: 0.3319889620038204 accuracy: 0.9040943514102427\n",
      "Start cleaning batch 3 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 3 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.479527\n",
      "Iteration   200, loss = 0.478814\n",
      "Iteration   300, loss = 0.478629\n",
      "Iteration   400, loss = 0.478552\n",
      "Iteration   500, loss = 0.478515\n",
      "Iteration   600, loss = 0.478496\n",
      "Iteration   700, loss = 0.478486\n",
      "Iteration   800, loss = 0.478479\n",
      "Iteration   900, loss = 0.478475\n",
      "Iteration  1000, loss = 0.478473\n",
      "Iteration  1100, loss = 0.478471\n",
      "Iteration  1200, loss = 0.478470\n",
      "Converged at iteration 1200\n",
      " Accuracy: 90.70%\n",
      " F1 Score: 0.3508\n",
      "     from now, f1 score: 0.35075023943811806 accuracy: 0.9070352141649016\n",
      "Start cleaning batch 4 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 4 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.472990\n",
      "Iteration   200, loss = 0.472268\n",
      "Iteration   300, loss = 0.472091\n",
      "Iteration   400, loss = 0.472018\n",
      "Iteration   500, loss = 0.471983\n",
      "Iteration   600, loss = 0.471965\n",
      "Iteration   700, loss = 0.471954\n",
      "Iteration   800, loss = 0.471948\n",
      "Iteration   900, loss = 0.471944\n",
      "Iteration  1000, loss = 0.471941\n",
      "Iteration  1100, loss = 0.471939\n",
      "Iteration  1200, loss = 0.471938\n",
      "Converged at iteration 1231\n",
      " Accuracy: 90.12%\n",
      " F1 Score: 0.3360\n",
      "     from now, f1 score: 0.3359606919848495 accuracy: 0.9011534886555839\n",
      "Start cleaning batch 5 out of 5\n",
      "Number of removes features due to NaN values: 117\n",
      "Cleaning of batch 5 done. Stating the model training.\n",
      "Iteration     0, loss = 0.693147\n",
      "Iteration   100, loss = 0.476228\n",
      "Iteration   200, loss = 0.475617\n",
      "Iteration   300, loss = 0.475470\n",
      "Iteration   400, loss = 0.475407\n",
      "Iteration   500, loss = 0.475375\n",
      "Iteration   600, loss = 0.475358\n",
      "Iteration   700, loss = 0.475348\n",
      "Iteration   800, loss = 0.475342\n",
      "Iteration   900, loss = 0.475338\n",
      "Iteration  1000, loss = 0.475335\n",
      "Iteration  1100, loss = 0.475333\n",
      "Iteration  1200, loss = 0.475332\n",
      "Converged at iteration 1232\n",
      " Accuracy: 90.45%\n",
      " F1 Score: 0.3369\n",
      "     from now, f1 score: 0.3368955666067078 accuracy: 0.9045057674432779\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "f1_scores_no_bal = np.array([])\n",
    "f1_scores_bal = np.array([])\n",
    "acc_scores_no_bal = np.array([])\n",
    "acc_scores_bal = np.array([])\n",
    "\n",
    "for alpha in np.arange(0, 1.0, 0.05):\n",
    "    acc_no_bal, f1_no_bal = kfold_logistic_ridge(X_train_data, Y_train_data, no_balanced_data, k=5, gamma=0.5, lambda_=1e-3, alpha = alpha)\n",
    "    acc_bal, f1_bal = kfold_logistic_ridge(X_train_data, Y_train_data, balanced_data, k=5, gamma=0.5, lambda_=1e-3, alpha = alpha)\n",
    "    f1_scores_no_bal = np.append(f1_scores_no_bal, f1_no_bal)\n",
    "    f1_scores_bal = np.append(f1_scores_bal, f1_bal)    \n",
    "    acc_scores_no_bal = np.append(acc_scores_no_bal, acc_no_bal)\n",
    "    acc_scores_bal = np.append(acc_scores_bal, acc_bal)"
=======
    "f1s_20, f1s_75 = np.array([]), np.array([])\n",
    "alphas = np.arange(0.4, 0.9, 0.05)\n",
    "\n",
    "for alpha in alphas:\n",
    "    _, f1_20 = kfold_logistic_ridge(X_train_data, Y_train_data, no_NaN_20, k=5, gamma=0.5, lambda_=1e-3, alpha = alpha)\n",
    "    _, f1_75 = kfold_logistic_ridge(X_train_data, Y_train_data, no_NaN_75, k=5, gamma=0.5, lambda_=1e-3, alpha = alpha)\n",
    "    f1s_20 = np.append(f1s_20, f1_20)\n",
    "    f1s_75 = np.append(f1s_75, f1_75)\n"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "f0f8a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.arange(0, 1.0, 0.05)\n",
    "plt.plot(dx, f1_scores_no_bal, label='F1 Score No Balancing')\n",
    "plt.plot(dx, f1_scores_bal, label='F1 Score With Balancing')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Alpha for Balanced and Unbalanced Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dx, acc_scores_no_bal, label='Accuracy No Balancing')\n",
    "plt.plot(dx, acc_scores_bal, label='Accuracy With Balancing')   \n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Alpha for Balanced and Unbalanced Data')"
=======
   "execution_count": 70,
   "id": "eb46bf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max f1 value for 20% 0.40715678097308483 with alpha 0.7\n",
      "Max f1 value for 75% 0.4072961185753517 with alpha 0.7\n"
     ]
    }
   ],
   "source": [
    "# plot the results\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(alphas, f1s_20, marker='o', label=\"F1 removing features with more than 20% NaNs\")\n",
    "plt.plot(alphas, f1s_75, marker='s', label=\"F1 removing features with more than 75% NaNs\")\n",
    "\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Alpha')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Max f1 value for 20%\", np.max(f1s_20), \"with alpha\", alphas[np.argmax(f1s_20)])\n",
    "print(\"Max f1 value for 75%\", np.max(f1s_75), \"with alpha\", alphas[np.argmax(f1s_75)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03099aa2",
   "metadata": {},
   "source": [
    "As it's clear here, the alpha threshold (controls the probability to asigne 1 or 0 to the final prediction) has the same behaviour for different aproaches"
>>>>>>> f998db3cbf091b502b8d11a0ca999c3122c9b050
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
