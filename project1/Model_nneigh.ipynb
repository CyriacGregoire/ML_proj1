{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94b28ef-299b-4b0d-bf31-8d6dfaa8e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from Data_cleaning import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61278433-65de-439c-aa76-b00cdcc59a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\cgreg\\AppData\\Local\\Temp\\ipykernel_93724\\4219252773.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data\\dataset\\dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb773b1e-4032-4906-823a-61f13cd1180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000,) (60000,) [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Turn y into 0s and 1s\n",
    "y_tr_ = (y_train + 1) / 2\n",
    "y_tr = y_tr_[:240000]\n",
    "y_te = y_tr_[240000:300000]\n",
    "print(y_tr.shape, y_te.shape, y_tr, y_te)\n",
    "#print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3fc705db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 2. 2. 2.]\n",
      "[5.3000000e+01 1.1000000e+01 1.1162015e+07 1.1000000e+01 1.6000000e+01]\n",
      "0.003115264797507788\n"
     ]
    }
   ],
   "source": [
    "my_features = [26,27,28,30,33,34,35,37,39,40,41,42,43,45,46,47,48,62,63,65]\n",
    "j = 65 \n",
    "print(x_train[:,j][:5])\n",
    "print(x_train[0][:5])\n",
    "\n",
    "count = 0 \n",
    "for i in x_train[j]:\n",
    "    if i == 72:\n",
    "        count += 1\n",
    "\n",
    "print(count/len(x_train[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27199848-d137-49f3-b452-56d98dd3ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_categorical_features(X, threshold=10):\n",
    "    \"\"\"\n",
    "    Removes categorical (low-cardinality) features from a numeric dataset.\n",
    "    A feature is dropped if it has fewer than `threshold` unique values.\n",
    "    \"\"\"\n",
    "    X_np = np.asarray(X)\n",
    "    n_samples, n_features = X_np.shape\n",
    "    keep_mask = np.array([\n",
    "        np.unique(X_np[:, j]).size >= threshold for j in range(n_features)\n",
    "    ])\n",
    "    X_num = X_np[:, keep_mask]\n",
    "    return X_num, keep_mask\n",
    "\n",
    "\n",
    "def anova_f_test(X, y):\n",
    "    \"\"\"\n",
    "    Compute ANOVA F-statistic for each feature using NumPy only.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (n_samples, n_features)\n",
    "        Feature matrix.\n",
    "    y : np.ndarray, shape (n_samples,)\n",
    "        Class labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    F_values : np.ndarray, shape (n_features,)\n",
    "        F-statistics for each feature.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    classes = np.unique(y)\n",
    "    k = len(classes)\n",
    "    \n",
    "    overall_means = np.nanmean(X, axis=0)  # handle NaNs safely\n",
    "    \n",
    "    # Initialize sums of squares\n",
    "    ssb = np.zeros(n_features)\n",
    "    ssw = np.zeros(n_features)\n",
    "    \n",
    "    for c in classes:\n",
    "        X_c = X[y == c]\n",
    "        n_c = X_c.shape[0]\n",
    "        mean_c = np.nanmean(X_c, axis=0)\n",
    "        \n",
    "        ssb += n_c * (mean_c - overall_means) ** 2\n",
    "        ssw += np.nansum((X_c - mean_c) ** 2, axis=0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    ssw = np.where(ssw == 0, np.nan, ssw)\n",
    "    \n",
    "    F = (ssb / (k - 1)) / (ssw / (n_samples - k))\n",
    "    \n",
    "    return F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c059316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 76)\n"
     ]
    }
   ],
   "source": [
    "x_cat = remove_categorical_features(x_train, 30)\n",
    "print(x_cat[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "775c8def-5a8e-4f0b-8bbc-f09f68b9fd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 20) (240000,)\n",
      "21131.0\n"
     ]
    }
   ],
   "source": [
    "# --- CLEANING ---\n",
    "\"\"\"\n",
    "# 0. Remove categorical (low-cardinality) features\n",
    "x_num, cat_mask = remove_categorical_features(x_train, threshold=10)\n",
    "print(x_num.shape)\n",
    "\"\"\"\n",
    "# 1. Remove features with too many NaNs\n",
    "x_clean, keep_mask = remove_nan_features(x_train)\n",
    "\n",
    "x_clean_red = x_clean[:,my_features]\n",
    "\n",
    "x_clean_tr = x_clean_red[:240000]\n",
    "x_clean_te = x_clean_red[240000:300000]\n",
    "\n",
    "\n",
    "# 2. Impute remaining missing values\n",
    "# Compute feature means from the training data (ignore NaNs)\n",
    "train_means = np.nanmean(x_clean_tr, axis=0)\n",
    "\n",
    "train_stds = np.nanstd(x_clean_tr, axis = 0)\n",
    "# Replace NaNs in training data with training means\n",
    "inds_tr = np.where(np.isnan(x_clean_tr))\n",
    "x_clean_tr[inds_tr] = np.take(train_means, inds_tr[1])\n",
    "\n",
    "# Replace NaNs in test data with training means\n",
    "inds_te = np.where(np.isnan(x_clean_te))\n",
    "x_clean_te[inds_te] = np.take(train_means, inds_te[1])\n",
    "\"\"\"\n",
    "# Compute F-scores using only the training data\n",
    "F_scores = anova_f_test(x_clean_tr, y_tr)\n",
    "\n",
    "\n",
    "# Select top 30 features\n",
    "top_k = \n",
    "top_features_idx = np.argsort(F_scores)[-top_k:][::-1]\n",
    "\n",
    "# Apply the same feature selection to all sets\n",
    "x_anova_tr = x_clean_tr[:, top_features_idx]\n",
    "x_anova_te = x_clean_te[:, top_features_idx]\n",
    "\"\"\"\n",
    "# --- STANDARDIZATION ---\n",
    "x_tr_st = (x_clean_tr - train_means) / train_stds\n",
    "x_te_st = (x_clean_te - train_means) / train_stds\n",
    "\n",
    "\n",
    "print(x_tr_st.shape, y_tr.shape)\n",
    "print(np.sum(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "657fa748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour(x,tx,k):\n",
    "\n",
    "    k = min(k,len(tx))\n",
    "    dist = 10000*np.ones(k)\n",
    "    max_dist = 10000\n",
    "    NNeigh = [56]*k\n",
    "\n",
    "    for index , x_temp in enumerate(tx):\n",
    "        temp_dist = np.transpose(x_temp-x)@(x_temp-x)\n",
    "        if temp_dist < max_dist:\n",
    "            index_oldmax = np.where(dist == max_dist)[0][0]\n",
    "            dist[index_oldmax] = temp_dist\n",
    "            NNeigh[index_oldmax] = int(index)\n",
    "            max_dist = np.max(dist)\n",
    "\n",
    "    return NNeigh\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b34e6dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "x_nn = np.array([0,1])\n",
    "tx_nn = np.array([[0,2],[1,11],[1,2],[3,0]])\n",
    "\n",
    "res = nearest_neighbour(x_nn,tx_nn,3)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9be1503-01c4-4bc5-b4dc-09653e15d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42262, 20) (42262,)\n"
     ]
    }
   ],
   "source": [
    "x_tr_ba, y_tr_ba = balance_data(x_tr_st, y_tr)\n",
    "print(x_tr_ba.shape, y_tr_ba.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "083681b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23833, 164728] (240000, 20)\n"
     ]
    }
   ],
   "source": [
    "near_neigh = nearest_neighbour(x_te_st[0],x_tr_st,2)\n",
    "print(near_neigh,x_tr_st.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7cd4d506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1-int(0.6 < 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8723f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_nneigh(xte,tx,ytr,k):\n",
    "    classes = 2*np.ones(len(xte))\n",
    "    for i,x in enumerate(xte):\n",
    "        nneighs = nearest_neighbour(x,tx,k)\n",
    "        val = np.mean(ytr[nneighs])\n",
    "        classes[i] = 1-int(val < 0.5)\n",
    "    \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c4ac7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_nn = np.array([[0,1],[1,12]])\n",
    "tx_nn = np.array([[0,2],[1,11],[1,2],[3,0]])\n",
    "ytr = np.array([0,1,0,1])\n",
    "\n",
    "res = classify_nneigh(x_nn,tx_nn,ytr,3)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d2836ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = classify_nneigh(x_te_st[:1000],x_tr_st,y_tr,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13d5703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 107.0\n",
      "Accuracy: 0.893\n",
      "41.0\n",
      "80.0\n"
     ]
    }
   ],
   "source": [
    "l = 1000\n",
    "#print(y_pred_nn, y_te[:l],len(x_te_st))\n",
    "\n",
    "n_errors = np.sum(np.abs(y_te[:l] - y_pred_nn))\n",
    "accuracy = np.mean(y_te[:l] == y_pred_nn)\n",
    "\n",
    "print(\"Misclassified samples:\", n_errors)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(np.sum(y_pred_nn))\n",
    "print(np.sum(y_te[:l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_csv_submission(test_ids, y_pred, 'submission_1510')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb8e2212-b66a-4e1a-8724-167a1a364c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Compute F1 score between true and predicted labels.\"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    if tp + fp == 0 or tp + fn == 0:\n",
    "        return 0.0\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02432b5d-cf87-4784-a406-53fe360812d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11570247933884296\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_te[:l], y_pred_nn[:l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2457d9-6a9e-4b07-a71f-3142edbe5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
